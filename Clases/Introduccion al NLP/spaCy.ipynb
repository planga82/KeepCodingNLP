{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"spaCy.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [conda env:MythNLP]","language":"python","name":"conda-env-MythNLP-py"}},"cells":[{"metadata":{"id":"A6v8-nJNQGSv","colab_type":"text"},"cell_type":"markdown","source":["# Que es spaCy?\n","\n","spaCy es un ejemplo de un magnífico proyecto open-source para NLP. Aqui teneís el link [spaCy](https://spacy.io/)\n","\n","Que gracia tiene? Hay unas cuantas comparativas que dan ellos ([aquí](https://spacy.io/usage/facts-figures) las teneis), pero realmente lo mejor de la librería es su filosofia, que se adecua bastante a la filosofía KeepCoding, a una filosofía que aquellos que desarrollamos producto nos es muy familiar. Una forma de hacer. Es decir, si hay 5 o 6 algoritmos que solucionan un problema, te damos el problema solucionado con un algoritmo. Y solo uno. Y no tenemos que preocupar-nos por nada de los intringulis de este. Además es rápida. Es de las pocas librerías que esta implementada en Cython, y eso ayuda.\n","\n","![](https://i.imgur.com/nD7ut2U.jpg)\n","\n","Que features linguísticas nos ofrece spaCy?\n","\n","![](https://i.imgur.com/lGcL6lx.jpg)\n","\n","Es decir, de spaCy podremos sacar siempre que querramos tokens, Parts-of-Speech, el dependency parser, e incluso viene con un entity recognizer incorporado. Además tambien viene con word embeddings que veremos en unas sesiones más adelante.\n","\n","Ahora Veremos que son todas estas features, y que uso pueden tener.\n","\n","## Librerías e installs"]},{"metadata":{"id":"cnDX6BkKTE0e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install spacy"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZYWQQfxwTHp5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!python -m spacy download es_core_news_md"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-_tSK_gPVMV7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!python -m spacy download en_core_web_md"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BleE-o-YcxX6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import spacy\n","\n","nlp = spacy.load('es_core_news_md')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pOWU_OeHcxX8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from spacy import displacy # Solo usado para visualizar datos."],"execution_count":0,"outputs":[]},{"metadata":{"id":"wumHdT-rcxYb","colab_type":"text"},"cell_type":"markdown","source":["# Tokenizing\n","\n","Una de las técnicas más usadas en cualquier proceso de NLP es tokenizar. Hay distintos tipos de tokenización posible, pero básicamente usaremos palabras como tokens, almenos con spaCy. Más adelante veremos otros tipos de tokens que no son palabras, y que nos son muy útiles para solucionar algunos problemas.\n","\n","Ejemplo: "]},{"metadata":{"id":"kSE83cFiaN47","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZUL92omjcxYg","colab_type":"text"},"cell_type":"markdown","source":["## Part of Speech tagging\n","\n","### Que son? \n","\n","![](https://d1e4pidl3fu268.cloudfront.net/5e4905a9-5518-44a0-83ea-6286aa16ac9e/partsofspeech.crop_634x476_51,0.preview.png)\n","\n","### Más importante, para que nos sirven?\n","\n","Más adelante veremos que hay tareas en las que nos interesa saber si una palabra esta actuando de una manera u de otra, y es ahí donde querremos usar PoS. Por poner un ejemplo más práctico. Si estamos buscando nombres propios en una frase, y por lo que sea vamos a buscar en textos de internet, en los cuales los nombres propios no tienen porque empezar en Mayúscula, una forma de eliminar ruido, es buscando directamente sólo en esas palabras que esten taggeadas como Nombre. \n","\n","Las PoS tienen muchísimas utilidades, como por ejemplo, sabemos que un verbo puede definir una relación entre entidades.\n","\n","> David es profesor\n","\n","Podríamos hacer un algoritmo que mirara verbos entre otras entidades, como nombres o adjetivos, y que fuera el verbo quien decidiera que relación tienen esas entidades. Eso se suele hacer para crear bases de datos de grafos, donde cada nodo es una entidad, y entre entidades hay relaciones.\n","\n","![](https://i.imgur.com/sMQO1pX.jpg)\n","\n","Vamos a ver algún ejemplo con spacy.\n","\n","\n","\n"]},{"metadata":{"id":"qMS7kL-wcxYg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"1dMT0G3Umiw_","colab_type":"text"},"cell_type":"markdown","source":["## Entity Recognition\n","\n","Este es quizás uno de las aplicaciones más usadas para minear texto en web. Básicamente el objetivo trata de localizar en el texto posibles entidades que nos sean relevantes. Es decir, si estamos montando un servicio de viajes donde queremos ofrecer al usuario varias posiblidades en un viaje, pero queremos automatizar todo el proceso, podríamos empezar por scrapear todos los posts en alguna web que pueda contenter esta información y mirar de extraer información relevante. Que información sería relevante? Bueno, quizas nombres de ciudades. Quizás nombres de resutarantes. O de personas famosas que hayan nacido en un lugar. Toda esta información, son los Named Entity Recognizers, es decir sistemas de reconocimiento de nombres, quienes nos la proporcionan. spaCy tiene uno incorporado, y nosotrs montaremos otro en la siguiente sesión.\n","\n","De momento veremos que nos puede ofrecer spaCy. "]},{"metadata":{"id":"7vQS0IngcxYK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"C7oFuEgZcxYN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"c9wYIozPcxYR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"VwqQHATscxYU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"AKwX8V0gcxYj","colab_type":"text"},"cell_type":"markdown","source":["## Chunks de nombres\n","\n","Basicamente son trozos de la frase que solo contienen nombres. No los usaremos a menudo como features para clasificar, pero siempre los podemos tener presentes por si queremos extraer algun tipo de concepto de una frase. La diferencia con las demás features que estamos viendo, es que aquí sólo estamos partiendo las frases, no estamos asignando labels a ninguna parte. "]},{"metadata":{"id":"GBR_2f6DcxYk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"bCUc_WAgcxYo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0ZcV5TmVcxYs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"6pbBcxYrcxYv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"bc7omQD6cxY1","colab_type":"text"},"cell_type":"markdown","source":["# Árbol de dependencias (Dependency Parser)\n","\n","Los arboles de dependencia son fantásticos. Son aquellos olvidados de cuándo íbamos al colegio, el análisis morfosintáctico ese. En cualquier caso, los árboles de dependencias nos ofrecen una información muy interesante.\n","\n","Quizás a diferencia de anteriores que nos ofrecen features muy claras para montar clasificadores, estos nos ofrecen features parar relacionar palabras.\n","\n","Ahora veremos un ejemplo. No implementaremos de 0 como generar estos árboles, solo veremos ahora como podríamos usarlos. No los implementaremos porque actualmente spaCy por ejemplo, ya ofrece unos magníficos resultados, y no vale la pena, a menos que no seamos investigadores, a seguir desarrollando esto.\n","\n","Es muy interesante usar estos arboles, sobretodo en una época en dónde hacer keyword matching ya no es suficiente. Con esto podemos potenciar las búsquedas y asignar relaciones a los distintos conceptos que aparecen en una query.\n","\n","Veamos un ejemplo."]},{"metadata":{"id":"S4lctFPvcxYE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"AgF4-qJacxY2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from nltk import Tree\n","def __tok_format(tok):\n","    \"\"\"\n","    Used in print tree.\n","    No need to call from outside\n","    :param tok:\n","    :return:\n","    \"\"\"\n","    return \"_\".join([tok.orth_, tok.tag_])\n","\n","\n","def __to_nltk_tree(node):\n","    \"\"\"\n","    Used in print_tree\n","    No need to call from outside\n","    :param node:\n","    :return:\n","    \"\"\"\n","    if node.n_lefts + node.n_rights > 0:\n","        return Tree(__tok_format(node), [__to_nltk_tree(child) for child in node.children])\n","    else:\n","        return __tok_format(node)\n","\n","\n","def print_tree(doc):\n","    \"\"\"\n","    prints the dependency parsing tree using the nltk function\n","    :param doc: spacy doc, basically parsed sentences\n","    \"\"\"\n","    [__to_nltk_tree(sent.root).pretty_print() if len(sent) > 1 else print(sent) for sent in doc.sents]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NNcRbCPpcxY5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"f14dacf0-95da-41a1-ca6b-7952b47e76ac"},"cell_type":"code","source":["document = 'el barca juega contra el alaves'\n","doc_t = nlp(document)\n","print('text ---- dep relation ----- parent\\n')\n","print_tree(doc_t)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["text ---- dep relation ----- parent\n","\n","                  juega_VERB__Mood=                                   \n","                   Ind|Number=Sing|                                   \n","                   Person=3|Tense=                                    \n","                    Pres|VerbForm=                                    \n","                         Fin                                          \n","         _________________|________________                            \n"," barca_NOUN__Numb                   alaves_NOUN__Gen                  \n","     er=Sing                        der=Masc|Number=                  \n","        |                                 Sing                        \n","        |                  ________________|_________________          \n","el_DET__Definite=  contra_ADP__AdpT                  el_DET__Definite=\n"," Def|Gender=Masc|      ype=Prep                       Def|Gender=Masc|\n","   Number=Sing|                                         Number=Sing|  \n","   PronType=Art                                         PronType=Art  \n","\n"],"name":"stdout"}]},{"metadata":{"id":"jCHjOp_DVTQc","colab_type":"text"},"cell_type":"markdown","source":["# Lemmas\n","\n","Los lemmas son las formas base de las palabras. En muchos sistemas de búsqueda, lo normal era lemmatizar la query entrante, y luego tirar la búsqueda. La verdad es que con el tiempo y Deep Learning, ha surgido algo de debate sobre si es necesario, y sobre si mejora nuestros sistemas el hecho de lemmatizar o no. Nosotros usaremos el lemmatizer base de spaCy para esta función, y no implementaremos nada de ello, dado que la mayoría de lemmatizadores estan basados en sistemas de reglas altamente curados.\n","\n","Ejemplo: "]},{"metadata":{"id":"aSJXKhsXcxY8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"48ca53b2-1341-43bf-fc1b-5d5034e289e3"},"cell_type":"code","source":["[t.lemma_ for t in doc_t]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['el', 'barca', 'jugar', 'contra', 'el', 'alaves']"]},"metadata":{"tags":[]},"execution_count":23}]}]}