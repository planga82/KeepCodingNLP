{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de Intro.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"munV_VfriG5_","colab_type":"text"},"cell_type":"markdown","source":["# Supervised Learning para NLP.\n","\n","El objetivo de la clase de hoy es visitar distintos tipos de problema que nos podemos encontrar en NLP usando supervised Learning.\n","\n","Habreis visto imágenes similares, pero no tan espectaculares. \n","![](https://i.imgur.com/3inJ3wG.jpg)\n","\n","Supervised Learning es aquel conjunto de algoritmos que precisan de datos etiquetados para aprender. No importa la forma, el algoritmo de aprendizaje, o el de optimización. Si tus datos tienen etiquetas, puedes aplicar supervised learning.\n","\n","Si en la clase anterior vimos distintos tipos de features, y en Machine Learning y Deep Learning vimos distintos tipos de algoritmos para aplicar, tenemos todas las piezas y  ya estamos listos no? Acordaros, para resolver un problema de supervised learning, siempre buscaremos la misma setup.\n","\n","1.   Procesar datos. (Big Data) En python podeis usar generators. Si no habéis visto ni uno, avisadme ahora mismo y implementamos uno.\n","2.   Preparar Xs e Ys.\n","3.   Escoger algoritmo de entrenamiento.\n","4.   Entrenar\n","5.   ??????\n","6.   Profit\n","\n","## Que implementaremos desde 0?\n","\n","Bayes. Veremos Bayes, teoría sobre Naive Bayes algorithm y lo prepararemos todo desde 0. Los demás algoritmos entiendo que los habeís visto en Machine Learning y Deep Learning, y usaremos las librerías de sklearn y Keras como ya hemos visto previamente.\n","\n","## Objetivos de hoy\n","\n","* El gran objetivo de hoy, es ver ejemplos de problemas donde podemos aplicar supervised learning. Dejar claro pipelines más o menos estándares de procesado de texto, que algoritmos són más prototípicos en el caso de NLP y entrenar el máximo numero de modelos posibles con datasets reales.\n","\n","* Veremos problemas de clasificación de varios tipos, desde binarios (me gusta/no me gusta), es decir un sentiment analysis clásico y problemas multiclase, como por ejemplo...(me lo guardo para después). También veremos dos tipos de problemas de clasificación diferente. Veremos un tipo de problema que se llama Modelado d Lenguaje (Language Modeling), y veremos un clásico de NLP como Named Entity Recognition.\n","\n","* Sobretodo, sobretodo, el objetivo es que no quede duda de que, datos etiquetados = supervised learning, y que para poder entrenar, sólo y únicamente nos hace falta etiquetas, un algoritmo y algo de creatividad."]},{"metadata":{"id":"HfmAmLJFsHLr","colab_type":"text"},"cell_type":"markdown","source":["#### Generators"]},{"metadata":{"id":"pKxfUGeOlj5K","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"23Vk0_aLlwS9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3ZT-W9LzmZcF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"h7YDIPAamkBp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xm3c8QnQmonN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"td68St9om1hQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"UPa_KAsm0f5t","colab_type":"text"},"cell_type":"markdown","source":["# Antes de ir a cualquier parte -> Bayes\n","\n","[Bayes Royal Society](https://www.youtube.com/watch?v=-e8wOcaascM)\n","\n","\n","<div align=\"center\">\n","![Bayes](https://static1.squarespace.com/static/591e58f72994cab66b93f891/t/591f89a39c03e001d1e3b17e/1495241602853/bayes-rule-e1350930203949.png =600x)\n","</div>\n","\n","Cuando usamos Naive Bayes en NLP? Para casi todo se ha usado Bayes. Los primeros filtros de spam fueron naive bayes classifiers. Casi todos los primeros intentos de solucionar un problema en NLP se sustenta en Bayes.\n","\n","## Representación de un documento cualquiera en bayes.\n","\n","![](https://i.imgur.com/3gbPLQY.jpg)\n","\n","### Calculo de una clase con bayes.\n","\n","Clasificación con bayes. Probabilidad de que un documento sea de una clase, dado que es esa clase. Hay que representar el documento!\n","\n","![](https://i.imgur.com/MdJUKgg.jpg)\n","\n","Alguien puede comentar porque podemos eliminar facilmente el denominador?\n","\n","### Entreno -> Como estimamos los parametros?\n","\n","![](https://i.imgur.com/XGJmFwp.jpg)\n"]},{"metadata":{"id":"5z_46qNG0qt3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3S_hNZY11nEk","colab_type":"text"},"cell_type":"markdown","source":["Entrenaremos con unigrams por ahora."]},{"metadata":{"id":"wADhw22w1M3i","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["datos = [\n","    ('esto es un ejemplo de lo que podría ser un texto bien', 'ok'),\n","    ('esto es otro mal ', 'ko'),\n","    ('me gusta mucho la bien clase KeepCoding', 'ok'),\n","    ('Este profesor no se mal entera de nada !', 'ko'),\n","    ('Estoy aprendiendo muchísimo bien !', 'ok'),\n","    ('me cuesta mucho NLP mal', 'ko'),\n","    ('NLP es muy fácil si esta bien explicado', 'ok'),\n","    ('ya falta menos para que mal llegue el break', 'ko'),\n","    ('Suerte que el profesor nos va a mandar mucho trabajo bien !', 'ok'),\n","    ('No sé si tendré tiempo a terminar todo el trabajo mal', 'ko'),\n","        ]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bRJTD0H91w4b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"j3fJUqDW0hHw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0gTpOBXR4JTV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":72},"outputId":"b0e45ed1-db9e-48de-eece-2a85f20da1a1","executionInfo":{"status":"ok","timestamp":1530379144425,"user_tz":-120,"elapsed":686,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('bien', 5), ('es', 2), ('un', 2), ('que', 2), ('mucho', 2)]\n","[('mal', 5), ('el', 2), ('esto', 1), ('es', 1), ('otro', 1)]\n","{'ok': 44, 'ko': 39}\n"],"name":"stdout"}]},{"metadata":{"id":"Aa6u61W-6r5h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"3AZ-wqyq6tEU","colab_type":"text"},"cell_type":"markdown","source":["## Predicción\n","\n","¿Probamos con lo que hemos entrenado?\n","\n","Pero espera! Que es: la primera parte de la ecuación, como la usamos?\n","¿Qué es exactamente, P(d|c)?\n","\n","Que es un documento? Un conjunto de features verdad? Además, en este preciso instante es cuando os puedo explicar porque se le llama *Naive* Bayes.\n","\n","Se le llama así, porque este algoritmo nos obliga a asumir dos cosas muy importantes. Que las features del documento son independientes y que el orden no importa.\n","\n","Que implica esto? Si el orden no importa podemos usar modelos tipo Bolsas de Palabras (Bag of words).\n","\n","Que sea independiente, nos permite tratar cada feature con mucha facilidad, si no fuera así, tendríamos que estar calculando cuando afecta cada variable, no a la clasificación del documento, sino entre si.\n","\n","Acordaros que la assumpción de independencia nos permite relajar la carga computacional, sino sería intratable.\n","\n","### Dependencia \n","<div align=\"center\">\n","![](https://i.imgur.com/3ARmOZr.jpg =500x)\n","</div>\n","\n","### Independencia\n","<div align=\"center\">\n","![](https://i.imgur.com/JBn2GhN.jpg =500x)\n","</div>\n","\n","Aplicando la asumpción de independencia:\n","> P(d|c) = P(x_0|c) * ...P(x_i|c)\n","\n","Última cosa, que usaremos tanto en bayes o language modeling por ejemplo, si tenemos probabilidades muy pequeñas, lo mejor es trabajar en log space, y sumar. Es decir, vamos convirtiendo las probabilidades una a una en log space, sumamos, y luego pasamos de nuevo a probabilidad con la inversa."]},{"metadata":{"id":"tgstXuh7sW8m","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"RHdjlN_1sfzl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"4fC-ojbZspty","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"BPUCQ60H0lo0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"jnL4cpdc87Ih","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"wUKYsIxC8-KE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"oiiEM9XzBWGA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"10_LApWZ0JtD","colab_type":"text"},"cell_type":"markdown","source":["# Recordatorio clase previa\n","\n","## Pipeline clásico de NLP\n","\n","![](http://blog.aylien.com/wp-content/uploads/2016/07/nlp-language-dependence-small-1.png)\n","\n","1. Preprocesado de texto\n","    1. Limpiar: Caracteres raros, palabras \"raras\". *Normalizar el texto*\n","    2. stemmizar?\n","    3. lemmatizar?\n","    4. Definir vocabulario?\n","    5. Tokenizar\n","    6. Preparar Train/test/val sets\n","2. Entrenar\n","3. Testear"]},{"metadata":{"id":"odQZu5P50JtI","colab_type":"text"},"cell_type":"markdown","source":["### Librerias"]},{"metadata":{"id":"M09-vn-L0JtK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"H-BDusMUu3md","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"2PpRfEfS0JtT","colab_type":"text"},"cell_type":"markdown","source":["# Preprocesado de texto"]},{"metadata":{"id":"B8IrLF2n0JtU","colab_type":"text"},"cell_type":"markdown","source":["\n","datos = json.load('')\n","\n","datos = pickle.load('')\n","\n","datos = pymongo.find({}) ... \n","\n","Donde tengamos los datos almacenados, sql, lo que sea\n","\n","El Objectivo principal al finalizar el preprocesado de texto es tener tuplas (o un diccionario, cualquier cosa), que nos permitar representar los datos en formato (x, y, **kwargs). kwargs puede ser cualquier cosa que nos interese para printar por ejemplo, pero al final, x, y como en todos los problemas de supervised learning. No hay ninguna diferencia con imagen o con cualquier otro tipo de datos.\n"]},{"metadata":{"id":"Z8gGJ_H50JtV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["datos = [\n","    ('esto es un ejemplo de lo que podría ser un texto bien', 'ok'),\n","    ('esto es otro mal ', 'ko'),\n","    ('me gusta mucho la bien clase KeepCoding', 'ok'),\n","    ('Este profesor no se mal entera de nada !', 'ko'),\n","    ('Estoy aprendiendo muchísimo bien !', 'ok'),\n","    ('me cuesta mucho NLP mal', 'ko'),\n","    ('NLP es muy fácil si esta bien explicado', 'ok'),\n","    ('ya falta menos para que mal llegue el break', 'ko'),\n","    ('Suerte que el profesor nos va a mandar mucho trabajo bien !', 'ok'),\n","    ('No sé si tendré tiempo a terminar todo el trabajo mal', 'ko'),\n","        ]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1cvD1kdj0JtZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"6ds5pq1n0Jth","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"7zliqctj0Jt1","colab_type":"text"},"cell_type":"markdown","source":["## Preparar train/test/val\n","\n","### Manual"]},{"metadata":{"id":"F1MSNXDr0Jt3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"n4Vmm_-80Jt-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"DPpminFE0JuC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"jzgjS2Ky0JuJ","colab_type":"text"},"cell_type":"markdown","source":["**Alguien nota algun problema con este metodo?**\n","\n","**Las particiones son equivalentes, mantienen las clases?**"]},{"metadata":{"id":"qM9dtITw0JuJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"IDGBTSgH0JuN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"wpO--18-0JuQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"4MaKV88A0JuS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"uZA8hduM0JuU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"t973MTiT0JuZ","colab_type":"text"},"cell_type":"markdown","source":["# Entrenar"]},{"metadata":{"id":"84-kdb8i0Jua","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"mjrdin7A0Juf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"o0ik6xLU0Juc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"1g72i7vi0Juh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ozK-j9Op0Juj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"hHwOIfgC0Jum","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# pipeline.steps[0][1].vocabulary_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bCSde3eb0Jus","colab_type":"text"},"cell_type":"markdown","source":["# Testear"]},{"metadata":{"id":"KWQddVW10Jut","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ElPSedAF0Juw","colab_type":"text"},"cell_type":"markdown","source":["# Jugar / Deploy"]},{"metadata":{"id":"1vCIn2dT0Juw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["predict_sentences = [\n","    'que bien hay clase',\n","    'que mal hay clase',\n","    'que mal el profesor',\n","    'que mal dataset construyo',\n","    'que bien hoy no vemos el futbol'\n","]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oT_D8VD30Juy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}