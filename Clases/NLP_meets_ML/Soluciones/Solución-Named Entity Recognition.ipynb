{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Named Entity Recognition.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"u44VncnK25ce","colab_type":"text"},"cell_type":"markdown","source":["# What is Named Entity Recognition ? \n","\n","Es un problema de *Sequence Labeling*.  A diferencia de obtener una clase para todo un texto, cada token del texto debe ser taggeado.\n","\n","### Algo de teoría breve\n","\n","#### Sequence Labeling & Structured Output\n","\n","Al ser un proceso de etiquetar sequencias, que puede ser mejor, etiquetar toda la sequencia de golpe, o ir palabra a palabra?\n","\n","Bueno, con lo que hemos visto hasta ahora, tanto en Machine Learning, como en Deep Learning, no hay manera de etiquetar todo de golpe, porque normalmente tenemos datasets tal que las *ys* dependen unicamente de un set de features representado por *x*. En NLP muchos de estos problemas no tienen sentido, tal y como hemos visto en Language Modeling, hay casos en los que la palabra actual depende, tanto de lo que hemos dicho(pasado), como de lo que vamos a decir (futuro). De hecho, cuando vamos a hablar o escribir, *normalmente y no todos* pensamos que vamos a decir, es decir, hacemos una predicción de aquello futuro, y luego vamos articulando esa idea (pasado). Para estos casos, hay modelos probabilísticos como los modelos markovianos de variables latentes (Hidden Markov Models [HMM](https://en.wikipedia.org/wiki/Hidden_Markov_model)), que quedan fuera del temario del curso, o Conditional Random Fields ([CRF](https://en.wikipedia.org/wiki/Conditional_random_field)) como su alternativa más usada para problemas de este estilo. \n","\n","Este último, y solo a modo de que os suene, cae en la categoría de *structured prediction* ([wiki](https://en.wikipedia.org/wiki/Structured_prediction)). Structured prediction no es ni más ni menos que lo que nosotros querríamos para este tipo de productos, es decir, en lugar de que *y* este condicionada sólo a una serie de *features x*, este condicionado a todo el output. Y que todo este entrelazado, que por ejemplo un tag posterior, pueda afectar a uno anterior y viceversa.\n","\n","![](https://i.imgur.com/ukAr3Uh.jpg)\n","\n","Entonces si no vemos esto dentro del curso, hemos terminado la clase porque no podemos resolver el problema. Bueno no del todo.\n","\n","Como siempre, hay alternativas, que quizás no cumplen con todos los requisitos que querriamos pero dan resultados correctos, sobretodo para ver baselines.\n","\n","Entonces, si no podemos predecir algo en base al tiempo, haremos que el tiempo sea una feature. Es decir, en una feature meteremos tambien las features de *t-n* hasta *t+n*. Es decir, que la feature *x_n* estará compuesta por los la concatenación de elementos de features pasadas, y features futuras, y haremos que el clasificador tenga suficiente información en cada pareja *x,y*. Veremos en breves como se componen estas features.\n","\n","![](https://i.imgur.com/Wail7yI.jpg =400x)\n","![](https://i.imgur.com/irjqooW.jpg =400x)\n","\n","De esta forma, conseguimos crear features \"independientes\" del tiempo y podremos entrenar como siempre.\n","\n","### Named Entity Recognition\n","\n","El Objectivo es asignar doble-tag uno para cada clase, persona, organizacion, lo que queramos, y el otro es el conocido como BIO.\n","\n","*   Begin: Inicio de una entidad\n","*   Inside: Dentro de una entidad\n","*   Outside: No es una entida\n","\n","Actualmente y bastantes taggers correctos, pero en general, hay que adaptarlo al dominio. Un caso muy claro, es el de esos taggers, como el que veremos que se basa entre otras features, en si una palabra esta en mayúsculas. En un dominio más casual, como twitter, o cualquier otro ambito del tipo de internet.\n","\n","![](https://i.imgur.com/a8Zregf.jpg)\n","\n","Cual es la idea para entrenar? Para todo un texto usamos n-grams fomo features normalmente, entre otras. Aqui la idea es palabra por palabra poder decidir que tag tiene. Se definen una seria de features, que no son n-grams. Ahoar veremos un subset de estas features. Para lo demas, sera como cualquier otro modelo. Representar como input las features, tener preparado para cada input, un output, escoger clasificador y función de objetivo y a entrenar!"]},{"metadata":{"id":"N-KeMUIV9hJm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import csv\n","from tqdm import tqdm\n","import spacy\n","nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner', 'textcat'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2RoM1a4Q9hJw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":229},"outputId":"699e1ebf-2da1-4740-c406-3fa6f60f07db","executionInfo":{"status":"error","timestamp":1530439988190,"user_tz":-120,"elapsed":2535,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["#collab opening\n","\n","dataset = []\n","\n","with open('ner_dataset.csv', encoding='mac_roman',) as f:\n","    dataset_ner = csv.reader(f)\n","    next(dataset_ner, None)  \n","    sentence = []    \n","    for row in dataset_ner: # .encode('utf-8').strip()\n","        if row[0] != '':\n","            dataset.append(sentence)\n","            sentence = [(row[1],row[2], row[3])]\n","        else:\n","            sentence.append((row[1],row[2], row[3]))\n","dataset.remove([])\n","len(dataset)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e60e3c15276d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner_dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mac_roman'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdataset_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ner_dataset.csv'"]}]},{"metadata":{"id":"Lx_T1drH9hJ_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"8105466d-4ead-44fa-a244-d976c8e352b5"},"cell_type":"code","source":["dataset[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Thousands', 'NNS', 'O'),\n"," ('of', 'IN', 'O'),\n"," ('demonstrators', 'NNS', 'O'),\n"," ('have', 'VBP', 'O'),\n"," ('marched', 'VBN', 'O'),\n"," ('through', 'IN', 'O'),\n"," ('London', 'NNP', 'B-geo'),\n"," ('to', 'TO', 'O'),\n"," ('protest', 'VB', 'O'),\n"," ('the', 'DT', 'O'),\n"," ('war', 'NN', 'O'),\n"," ('in', 'IN', 'O'),\n"," ('Iraq', 'NNP', 'B-geo'),\n"," ('and', 'CC', 'O'),\n"," ('demand', 'VB', 'O'),\n"," ('the', 'DT', 'O'),\n"," ('withdrawal', 'NN', 'O'),\n"," ('of', 'IN', 'O'),\n"," ('British', 'JJ', 'B-gpe'),\n"," ('troops', 'NNS', 'O'),\n"," ('from', 'IN', 'O'),\n"," ('that', 'DT', 'O'),\n"," ('country', 'NN', 'O'),\n"," ('.', '.', 'O')]"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"Kcm1ATh39hKG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"0bf53192-c0ae-4fa3-d11d-139d9111934c"},"cell_type":"code","source":["classes = list(set([c for sentence in dataset for (_, _, c) in sentence]))\n","classes"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B-org',\n"," 'I-per',\n"," 'B-geo',\n"," 'I-org',\n"," 'I-nat',\n"," 'B-eve',\n"," 'B-gpe',\n"," 'B-nat',\n"," 'I-tim',\n"," 'I-eve',\n"," 'I-art',\n"," 'O',\n"," 'I-geo',\n"," 'B-per',\n"," 'B-art',\n"," 'I-gpe',\n"," 'B-tim']"]},"metadata":{"tags":[]},"execution_count":143}]},{"metadata":{"id":"2E9G9xlu9hKM","colab_type":"text"},"cell_type":"markdown","source":["# Building sets of features\n","\n","Hasta ahora, hemos usado como features solo una minúscula parte del potencial linguístico que tienen los textos. Para este ejercicio entrenaremos con nuevas features, algunas muy obvias, otras quizas no tanto. En la imagen se pueden ver features para crear un Part of Speech tagger, nosotros lo adaptaremos a un Named Entity Recognizer.\n","\n","![alt text](https://i.imgur.com/1SAC0TU.jpg =500x)\n","\n","From Neural Network Methods for NLP by Yoav Goldberg\n","\n","\n","Acordemonos que las features hay que adaptarlas no solo al problema, sino al dataset. El problema nos puede dar un estimado de que features usar, pero como siempre, nosotros podemos generar, quitar o combinar features como queramos. Por ejemplo, en el case de Entity Recognizers, que una palabra este en mayúsculas quizás es muy relevante, pero si estamos en un contexto de internet, donde la gente no sigue una convención fija de escriptura, es menos relevante.\n","\n","Para que veais un ejemplo de la complejidad de la tarea.\n","\n","\n","\n","\n","> Mal\n","![](https://i.imgur.com/wCOsdsk.png)\n","![](https://i.imgur.com/EO89nLZ.png)\n","\n","> Bien\n","![](https://i.imgur.com/amsQr9T.png)"]},{"metadata":{"id":"Vx0vlHmR9hKN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import re\n"," \n","def shape(word):\n","    word_shape = 'other'\n","    if re.match('[0-9]+(\\.[0-9]*)?|[0-9]*\\.[0-9]+$', word):\n","        word_shape = 'number'\n","    elif re.match('\\W+$', word):\n","        word_shape = 'punct'\n","    elif re.match('[A-Z][a-z]+$', word):\n","        word_shape = 'capitalized'\n","    elif re.match('[A-Z]+$', word):\n","        word_shape = 'uppercase'\n","    elif re.match('[a-z]+$', word):\n","        word_shape = 'lowercase'\n","    elif re.match('[A-Z][a-z]+[A-Z][a-z]+[A-Za-z]*$', word):\n","        word_shape = 'camelcase'\n","    elif re.match('[A-Za-z]+$', word):\n","        word_shape = 'mixedcase'\n","    elif re.match('__.+__$', word):\n","        word_shape = 'wildcard'\n","    elif re.match('[A-Za-z0-9]+\\.$', word):\n","        word_shape = 'ending-dot'\n","    elif re.match('[A-Za-z0-9]+\\.[A-Za-z0-9\\.]+\\.$', word):\n","        word_shape = 'abbreviation'\n","    elif re.match('[A-Za-z0-9]+\\-[A-Za-z0-9\\-]+.*$', word):\n","        word_shape = 'contains-hyphen'\n"," \n","    return word_shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FQNXFv7Q9hKR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def ner_features(tokens, index, history):\n","    \"\"\"\n","    `tokens`  = a POS-tagged sentence [(w1, t1), ...]\n","    `index`   = the index of the token we want to extract features for\n","    `history` = the previous predicted IOB tags\n","    \"\"\"\n","    # Pad the sequence with placeholders\n","    tokens = [('__START2__', '__START2__','__START2__' ), ('__START1__', '__START1__', '__START1__')] + list(tokens) + [('__END1__', '__END1__', '__END1__'), ('__END2__', '__END2__', '__END2__')]\n","    history = ['__START2__', '__START1__'] + list(history)\n","    # shift the index with 2, to accommodate the padding\n","    index += 2\n","    word, pos, lemma = tokens[index]\n","    prevword, prevpos, prevlemma = tokens[index - 1]\n","    prevprevword, prevprevpos, prevprevlemma = tokens[index - 2]\n","    nextword, nextpos, nextlemma = tokens[index + 1]\n","    nextnextword, nextnextpos, nextnextlemma = tokens[index + 2]\n","    previob = history[-1]\n","    prevpreviob = history[-2]\n"," \n","    feat_dict = {\n","        'word': word,\n","        'lemma': lemma,\n","        'pos': pos,\n","        'shape': shape(word),\n"," \n","        'next-word': nextword,\n","        'next-pos': nextpos,\n","        'next-lemma': nextlemma,\n","        'next-shape': shape(nextword),\n"," \n","        'next-next-word': nextnextword,\n","        'next-next-pos': nextnextpos,\n","        'next-next-lemma': nextnextlemma,\n","        'next-next-shape': shape(nextnextword),\n"," \n","        'prev-word': prevword,\n","        'prev-pos': prevpos,\n","        'prev-lemma': prevlemma,\n","        'prev-iob': previob,\n","        'prev-shape': shape(prevword),\n"," \n","        'prev-prev-word': prevprevword,\n","        'prev-prev-pos': prevprevpos,\n","        'prev-prev-lemma': prevprevlemma,\n","        'prev-prev-iob': prevpreviob,\n","        'prev-prev-shape': shape(prevprevword),\n","    }\n"," \n","    return feat_dict\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"-dOgKKNt9hKV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def to_dataset(parsed_sentences, feature_detector):\n","        \"\"\"\n","        Transform a list of tagged sentences into a scikit-learn compatible POS dataset\n","        :param parsed_sentences:\n","        :param feature_detector:\n","        :return:\n","        \"\"\"\n","        X, y = [], []\n","        for parsed in tqdm(parsed_sentences):\n","            words, tags, iob_tags = zip(*parsed)\n","            lemmas = [t.lemma_ for t in nlp(\" \".join(words))]\n","            for index in range(len(parsed)):\n","                tagged = zip(words, tags, lemmas)\n","                X.append(feature_detector(tagged, index, history=iob_tags[:index]))\n","                y.append(iob_tags[index])\n","        return X, y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z5DAtmBy9hKb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"55b55432-2e28-44ee-c3aa-37f4b7ac0581"},"cell_type":"code","source":["X, y = to_dataset(dataset[0:5000], ner_features)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 5000/5000 [01:06<00:00, 75.08it/s]\n"],"name":"stderr"}]},{"metadata":{"id":"xcw9CQ_W9hKh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import itertools\n","def get_minibatch(parsed_sentences, feature_detector, batch_size=500):\n","    batch = list(itertools.islice(parsed_sentences, batch_size))\n","    X, y = to_dataset(batch, feature_detector)\n","    return X, y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GcnPdKsU9hKk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"ecd1b00f-2e69-451a-cb24-cbacfafdad74"},"cell_type":"code","source":["X[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'lemma': 'thousand',\n"," 'next-lemma': 'of',\n"," 'next-next-lemma': 'demonstrator',\n"," 'next-next-pos': 'NNS',\n"," 'next-next-shape': 'lowercase',\n"," 'next-next-word': 'demonstrators',\n"," 'next-pos': 'IN',\n"," 'next-shape': 'lowercase',\n"," 'next-word': 'of',\n"," 'pos': 'NNS',\n"," 'prev-iob': '__START1__',\n"," 'prev-lemma': '__START1__',\n"," 'prev-pos': '__START1__',\n"," 'prev-prev-iob': '__START2__',\n"," 'prev-prev-lemma': '__START2__',\n"," 'prev-prev-pos': '__START2__',\n"," 'prev-prev-shape': 'wildcard',\n"," 'prev-prev-word': '__START2__',\n"," 'prev-shape': 'wildcard',\n"," 'prev-word': '__START1__',\n"," 'shape': 'capitalized',\n"," 'word': 'Thousands'}"]},"metadata":{"tags":[]},"execution_count":120}]},{"metadata":{"id":"ygfXsXZC9hKp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.linear_model import Perceptron\n","from sklearn.feature_extraction import DictVectorizer\n","from sklearn.pipeline import Pipeline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lmf8isZV9hKt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["vectorizer = DictVectorizer(sparse=False)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xR2NmxaF9hKz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["ner_clf = Pipeline([\n","    ('vectorizer', vectorizer),\n","    ('classifier', Perceptron(verbose=10, n_jobs=-1, n_iter=5))\n","])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fv9rP4Tl9hK5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"3651b8c8-da70-4f9d-a1dc-55f39a5418e4"},"cell_type":"code","source":["X, y = get_minibatch(dataset, ner_features, 500)\n","vectorizer.fit(X)\n","while len(X):\n","    X = vectorizer.transform(X)\n","    clf.partial_fit(X, y, classes)\n","    X, y = get_minibatch(dataset, ner_features, 500)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [00:06<00:00, 75.05it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1-- Epoch 1\n","\n","-- Epoch 1-- Epoch 1\n","\n","Norm: 16.91, NNZs: 231, Bias: -4.000000, T: 10976, Avg. loss: 0.009293\n","Total training time: 0.53 seconds.\n","-- Epoch 1\n","Norm: 54.09, NNZs: 1445, Bias: -9.000000, T: 10976, Avg. loss: 0.134384\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n","Norm: 62.13, NNZs: 1837, Bias: -9.000000, T: 10976, Avg. loss: 0.165179\n","Total training time: 0.61 seconds.\n","-- Epoch 1\n","Norm: 25.38, NNZs: 480, Bias: -3.000000, T: 10976, Avg. loss: 0.025784\n","Total training time: 0.62 seconds.\n","-- Epoch 1\n","Norm: 14.70, NNZs: 150, Bias: -3.000000, T: 10976, Avg. loss: 0.003371\n","Total training time: 0.56 seconds.\n","-- Epoch 1\n","Norm: 52.57, NNZs: 1439, Bias: -10.000000, T: 10976, Avg. loss: 0.114705\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 45.89, NNZs: 1130, Bias: -6.000000, T: 10976, Avg. loss: 0.070062\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n","Norm: 48.79, NNZs: 1070, Bias: -6.000000, T: 10976, Avg. loss: 0.065962\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 25.14, NNZs: 387, Bias: -4.000000, T: 10976, Avg. loss: 0.010295\n","Total training time: 0.56 seconds.\n","-- Epoch 1\n","Norm: 18.44, NNZs: 228, Bias: -4.000000, T: 10976, Avg. loss: 0.004738\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 25.57, NNZs: 375, Bias: -5.000000, T: 10976, Avg. loss: 0.014122\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n","Norm: 24.25, NNZs: 376, Bias: -5.000000, T: 10976, Avg. loss: 0.010842\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n","[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    1.8s remaining:    0.8s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.001549\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 39.34, NNZs: 796, Bias: -8.000000, T: 10976, Avg. loss: 0.031341\n","Total training time: 0.56 seconds.\n","Norm: 31.18, NNZs: 497, Bias: -6.000000, T: 10976, Avg. loss: 0.008564\n","Total training time: 0.64 seconds.\n","Norm: 19.03, NNZs: 243, Bias: -4.000000, T: 10976, Avg. loss: 0.005831\n","Total training time: 0.56 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.3s remaining:    0.5s\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.7s finished\n","  2%|▏         | 10/500 [00:00<00:05, 93.87it/s]"],"name":"stderr"},{"output_type":"stream","text":["Norm: 57.95, NNZs: 1466, Bias: 1.000000, T: 10976, Avg. loss: 0.091108\n","Total training time: 0.41 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:06<00:00, 82.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1-- Epoch 1-- Epoch 1-- Epoch 1\n","\n","\n","\n","Norm: 23.92, NNZs: 302, Bias: -5.000000, T: 10976, Avg. loss: 0.002278\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 76.85, NNZs: 2195, Bias: -11.000000, T: 10976, Avg. loss: 0.070517\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n","Norm: 66.54, NNZs: 1776, Bias: -11.000000, T: 10976, Avg. loss: 0.053389\n","Total training time: 0.57 seconds.Norm: 33.76, NNZs: 612, Bias: -5.000000, T: 10976, Avg. loss: 0.008109\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","\n","-- Epoch 1\n","Norm: 54.95, NNZs: 1374, Bias: -8.000000, T: 10976, Avg. loss: 0.022048\n","Total training time: 0.56 seconds.\n","-- Epoch 1\n","Norm: 66.86, NNZs: 1743, Bias: -10.000000, T: 10976, Avg. loss: 0.043823\n","Total training time: 0.61 seconds.\n","-- Epoch 1\n","Norm: 58.67, NNZs: 1259, Bias: -6.000000, T: 10976, Avg. loss: 0.020773\n","Total training time: 0.60 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 16.25, NNZs: 164, Bias: -4.000000, T: 10976, Avg. loss: 0.000638\n","Total training time: 0.81 seconds.\n","-- Epoch 1\n","Norm: 31.02, NNZs: 477, Bias: -7.000000, T: 10976, Avg. loss: 0.003735\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 20.45, NNZs: 256, Bias: -4.000000, T: 10976, Avg. loss: 0.000638\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 27.71, NNZs: 456, Bias: -5.000000, T: 10976, Avg. loss: 0.000729\n","Total training time: 0.63 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 27.09, NNZs: 424, Bias: -5.000000, T: 10976, Avg. loss: 0.003827\n","Total training time: 0.67 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    2.0s remaining:    0.8s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 45.01, NNZs: 953, Bias: -8.000000, T: 10976, Avg. loss: 0.007562\n","Total training time: 0.63 seconds.\n","Norm: 34.67, NNZs: 576, Bias: -7.000000, T: 10976, Avg. loss: 0.002551\n","Total training time: 0.64 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.4s remaining:    0.5s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 19.60, NNZs: 253, Bias: -4.000000, T: 10976, Avg. loss: 0.001093\n","Total training time: 0.54 seconds.\n","Norm: 69.94, NNZs: 1813, Bias: 1.000000, T: 10976, Avg. loss: 0.045372\n","Total training time: 0.46 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.8s finished\n","100%|██████████| 500/500 [00:06<00:00, 78.26it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1-- Epoch 1\n","-- Epoch 1\n","-- Epoch 1\n","\n","Norm: 37.71, NNZs: 677, Bias: -5.000000, T: 10976, Avg. loss: 0.006013\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n","Norm: 25.38, NNZs: 302, Bias: -5.000000, T: 10976, Avg. loss: 0.000911\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 84.38, NNZs: 2349, Bias: -11.000000, T: 10976, Avg. loss: 0.034803\n","Total training time: 0.60 seconds.\n","-- Epoch 1\n","Norm: 75.49, NNZs: 1926, Bias: -10.000000, T: 10976, Avg. loss: 0.036352\n","Total training time: 0.61 seconds.\n","-- Epoch 1\n","Norm: 16.25, NNZs: 164, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.56 seconds.\n","-- Epoch 1\n","Norm: 75.01, NNZs: 1879, Bias: -10.000000, T: 10976, Avg. loss: 0.022777\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n","Norm: 62.27, NNZs: 1351, Bias: -6.000000, T: 10976, Avg. loss: 0.009475\n","Total training time: 0.62 seconds.\n","-- Epoch 1\n","Norm: 61.25, NNZs: 1514, Bias: -9.000000, T: 10976, Avg. loss: 0.008837\n","Total training time: 0.64 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 21.31, NNZs: 269, Bias: -4.000000, T: 10976, Avg. loss: 0.000456\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 27.71, NNZs: 456, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 33.88, NNZs: 527, Bias: -7.000000, T: 10976, Avg. loss: 0.002004\n","Total training time: 0.60 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n","[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    1.9s remaining:    0.8s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 29.05, NNZs: 457, Bias: -5.000000, T: 10976, Avg. loss: 0.001276\n","Total training time: 0.62 seconds.\n","-- Epoch 1\n","Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n","Norm: 47.87, NNZs: 1020, Bias: -8.000000, T: 10976, Avg. loss: 0.002551\n","Total training time: 0.60 seconds.\n","Norm: 35.72, NNZs: 609, Bias: -7.000000, T: 10976, Avg. loss: 0.000820\n","Total training time: 0.51 seconds.\n","Norm: 19.60, NNZs: 253, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.3s remaining:    0.5s\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.7s finished\n","  2%|▏         | 9/500 [00:00<00:05, 87.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["Norm: 77.81, NNZs: 2011, Bias: 2.000000, T: 10976, Avg. loss: 0.019224\n","Total training time: 0.43 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:06<00:00, 74.51it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1-- Epoch 1-- Epoch 1-- Epoch 1\n","\n","\n","\n","Norm: 25.38, NNZs: 302, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.53 seconds.\n","-- Epoch 1\n","Norm: 81.41, NNZs: 2023, Bias: -12.000000, T: 10976, Avg. loss: 0.020590\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 40.84, NNZs: 707, Bias: -5.000000, T: 10976, Avg. loss: 0.001367\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n","Norm: 90.72, NNZs: 2467, Bias: -10.000000, T: 10976, Avg. loss: 0.022686\n","Total training time: 0.65 seconds.\n","-- Epoch 1\n","Norm: 16.25, NNZs: 164, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 81.10, NNZs: 1981, Bias: -11.000000, T: 10976, Avg. loss: 0.017493\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 63.89, NNZs: 1552, Bias: -9.000000, T: 10976, Avg. loss: 0.005922\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 65.92, NNZs: 1417, Bias: -6.000000, T: 10976, Avg. loss: 0.003827\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 27.71, NNZs: 456, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 21.31, NNZs: 269, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.60 seconds.\n","-- Epoch 1\n","Norm: 29.90, NNZs: 467, Bias: -6.000000, T: 10976, Avg. loss: 0.000364\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 34.47, NNZs: 527, Bias: -7.000000, T: 10976, Avg. loss: 0.000273\n","Total training time: 0.63 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n","[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    1.8s remaining:    0.7s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 36.36, NNZs: 624, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 48.74, NNZs: 1034, Bias: -9.000000, T: 10976, Avg. loss: 0.000638\n","Total training time: 0.67 seconds.\n","Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.72 seconds.\n","Norm: 19.60, NNZs: 253, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.4s remaining:    0.5s\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.7s finished\n","  2%|▏         | 9/500 [00:00<00:05, 86.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["Norm: 82.79, NNZs: 2109, Bias: 3.000000, T: 10976, Avg. loss: 0.012573\n","Total training time: 0.38 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:06<00:00, 76.72it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1-- Epoch 1\n","\n","-- Epoch 1-- Epoch 1\n","\n","Norm: 42.17, NNZs: 720, Bias: -5.000000, T: 10976, Avg. loss: 0.001276\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 86.08, NNZs: 2065, Bias: -11.000000, T: 10976, Avg. loss: 0.010477\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 96.50, NNZs: 2582, Bias: -11.000000, T: 10976, Avg. loss: 0.017857\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 25.38, NNZs: 302, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.61 seconds.\n","-- Epoch 1\n","Norm: 16.25, NNZs: 164, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 84.82, NNZs: 2039, Bias: -11.000000, T: 10976, Avg. loss: 0.009657\n","Total training time: 0.53 seconds.\n","-- Epoch 1\n","Norm: 65.21, NNZs: 1575, Bias: -9.000000, T: 10976, Avg. loss: 0.002733\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 68.09, NNZs: 1445, Bias: -6.000000, T: 10976, Avg. loss: 0.003553\n","Total training time: 0.60 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 27.71, NNZs: 456, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 21.31, NNZs: 269, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n","Norm: 34.47, NNZs: 527, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 29.90, NNZs: 467, Bias: -6.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n","[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    1.8s remaining:    0.8s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.60 seconds.\n","-- Epoch 1\n","Norm: 50.06, NNZs: 1049, Bias: -9.000000, T: 10976, Avg. loss: 0.000364\n","Total training time: 0.59 seconds.\n","Norm: 36.36, NNZs: 624, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","Norm: 19.60, NNZs: 253, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.59 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.3s remaining:    0.5s\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.7s finished\n","  2%|▏         | 11/500 [00:00<00:04, 106.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["Norm: 86.83, NNZs: 2164, Bias: 2.000000, T: 10976, Avg. loss: 0.007744\n","Total training time: 0.42 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:05<00:00, 87.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1\n","-- Epoch 1-- Epoch 1\n","\n","-- Epoch 1\n","Norm: 100.57, NNZs: 2653, Bias: -12.000000, T: 10976, Avg. loss: 0.013757\n","Total training time: 0.62 seconds.\n","-- Epoch 1\n","Norm: 44.02, NNZs: 741, Bias: -4.000000, T: 10976, Avg. loss: 0.000456\n","Total training time: 0.72 seconds.\n","-- Epoch 1\n","Norm: 25.38, NNZs: 302, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Norm: 89.16, NNZs: 2130, Bias: -12.000000, T: 10976, Avg. loss: 0.006833Total training time: 0.75 seconds.\n","\n","Total training time: 0.75 seconds.\n","-- Epoch 1\n","-- Epoch 1\n","Norm: 16.25, NNZs: 164, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.53 seconds.\n","-- Epoch 1\n","Norm: 88.36, NNZs: 2077, Bias: -11.000000, T: 10976, Avg. loss: 0.003462\n","Total training time: 0.61 seconds.\n","-- Epoch 1\n","Norm: 70.09, NNZs: 1468, Bias: -6.000000, T: 10976, Avg. loss: 0.002095\n","Total training time: 0.60 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.2s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 67.35, NNZs: 1615, Bias: -9.000000, T: 10976, Avg. loss: 0.001731\n","Total training time: 0.73 seconds.\n","-- Epoch 1\n","Norm: 27.71, NNZs: 456, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 21.31, NNZs: 269, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.9s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 34.47, NNZs: 527, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.63 seconds.\n","-- Epoch 1\n","Norm: 29.90, NNZs: 467, Bias: -6.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.68 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    2.2s remaining:    0.9s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 50.06, NNZs: 1049, Bias: -9.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.59 seconds.\n","Norm: 36.36, NNZs: 624, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.61 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.5s remaining:    0.5s\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.7s finished\n","  0%|          | 0/500 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Norm: 19.60, NNZs: 253, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.53 seconds.\n","Norm: 88.52, NNZs: 2185, Bias: 3.000000, T: 10976, Avg. loss: 0.004100\n","Total training time: 0.49 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:05<00:00, 87.83it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1-- Epoch 1\n","-- Epoch 1-- Epoch 1\n","\n","\n","Norm: 103.63, NNZs: 2702, Bias: -11.000000, T: 10976, Avg. loss: 0.009202\n","Total training time: 0.56 seconds.\n","-- Epoch 1\n","Norm: 25.38, NNZs: 302, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.62 seconds.\n","-- Epoch 1\n","Norm: 92.39, NNZs: 2163, Bias: -12.000000, T: 10976, Avg. loss: 0.006833\n","Total training time: 0.63 seconds.\n","-- Epoch 1\n","Norm: 44.29, NNZs: 761, Bias: -6.000000, T: 10976, Avg. loss: 0.000091\n","Total training time: 0.69 seconds.\n","-- Epoch 1\n","Norm: 16.25, NNZs: 164, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 90.56, NNZs: 2108, Bias: -11.000000, T: 10976, Avg. loss: 0.005102\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 68.95, NNZs: 1641, Bias: -10.000000, T: 10976, Avg. loss: 0.002824\n","Total training time: 0.60 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 70.41, NNZs: 1484, Bias: -7.000000, T: 10976, Avg. loss: 0.000456\n","Total training time: 0.64 seconds.\n","-- Epoch 1\n","Norm: 27.71, NNZs: 456, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.67 seconds.\n","-- Epoch 1\n","Norm: 21.31, NNZs: 269, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n","Norm: 34.47, NNZs: 527, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.63 seconds.\n","-- Epoch 1\n","Norm: 29.90, NNZs: 467, Bias: -6.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.62 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.8s\n","[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    2.0s remaining:    0.8s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 50.06, NNZs: 1049, Bias: -9.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.56 seconds.\n","-- Epoch 1\n","Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.62 seconds.\n","Norm: 36.36, NNZs: 624, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.59 seconds.\n","Norm: 19.60, NNZs: 253, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.57 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.4s remaining:    0.5s\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.8s finished\n","  2%|▏         | 10/500 [00:00<00:05, 96.60it/s]"],"name":"stderr"},{"output_type":"stream","text":["Norm: 89.58, NNZs: 2214, Bias: 2.000000, T: 10976, Avg. loss: 0.003189\n","Total training time: 0.45 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:05<00:00, 96.66it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1\n","-- Epoch 1\n","-- Epoch 1-- Epoch 1\n","\n","Norm: 106.16, NNZs: 2740, Bias: -12.000000, T: 10976, Avg. loss: 0.005193\n","Total training time: 0.56 seconds.\n","-- Epoch 1\n","Norm: 94.38, NNZs: 2169, Bias: -11.000000, T: 10976, Avg. loss: 0.004009\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 25.38, NNZs: 302, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.Norm: 44.74, NNZs: 773, Bias: -6.000000, T: 10976, Avg. loss: 0.000273\n","\n","Total training time: 0.58 seconds.-- Epoch 1\n","\n","-- Epoch 1\n","Norm: 16.25, NNZs: 164, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.56 seconds.\n","-- Epoch 1Norm: 92.04, NNZs: 2139, Bias: -12.000000, T: 10976, Avg. loss: 0.002369\n","Total training time: 0.54 seconds.\n","\n","-- Epoch 1\n","Norm: 70.20, NNZs: 1637, Bias: -9.000000, T: 10976, Avg. loss: 0.000273\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n","Norm: 70.41, NNZs: 1484, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 34.47, NNZs: 527, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 21.31, NNZs: 269, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.61 seconds.\n","-- Epoch 1\n","Norm: 29.90, NNZs: 467, Bias: -6.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 27.71, NNZs: 456, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.64 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n","[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    1.8s remaining:    0.7s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n","Norm: 36.36, NNZs: 624, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n","Norm: 50.06, NNZs: 1049, Bias: -9.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.62 seconds.\n","Norm: 19.60, NNZs: 253, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.61 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.3s remaining:    0.5s\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.7s finished\n","  2%|▏         | 8/500 [00:00<00:06, 75.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["Norm: 90.52, NNZs: 2247, Bias: 2.000000, T: 10976, Avg. loss: 0.000638\n","Total training time: 0.40 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:05<00:00, 85.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["-- Epoch 1-- Epoch 1\n","\n","-- Epoch 1\n","-- Epoch 1\n","Norm: 45.17, NNZs: 778, Bias: -6.000000, T: 10976, Avg. loss: 0.000364\n","Total training time: 0.56 seconds.\n","-- Epoch 1Norm: 25.38, NNZs: 302, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.56 seconds.\n","\n","-- Epoch 1\n","Norm: 108.89, NNZs: 2803, Bias: -13.000000, T: 10976, Avg. loss: 0.006651\n","Total training time: 0.57 seconds.\n","-- Epoch 1\n","Norm: 96.11, NNZs: 2197, Bias: -12.000000, T: 10976, Avg. loss: 0.001731\n","Total training time: 0.59 seconds.\n","-- Epoch 1\n","Norm: 70.81, NNZs: 1658, Bias: -10.000000, T: 10976, Avg. loss: 0.000456\n","Total training time: 0.52 seconds.\n","-- Epoch 1\n","Norm: 16.25, NNZs: 164, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n","Norm: 93.47, NNZs: 2158, Bias: -11.000000, T: 10976, Avg. loss: 0.002642\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 70.41, NNZs: 1484, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 21.31, NNZs: 269, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.55 seconds.\n","-- Epoch 1\n","Norm: 27.71, NNZs: 456, Bias: -5.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","Norm: 34.47, NNZs: 527, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.61 seconds.Norm: 29.90, NNZs: 467, Bias: -6.000000, T: 10976, Avg. loss: 0.000000\n","\n","Total training time: 0.58 seconds.\n","-- Epoch 1\n","-- Epoch 1\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n","[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    1.8s remaining:    0.7s\n"],"name":"stderr"},{"output_type":"stream","text":["Norm: 50.06, NNZs: 1049, Bias: -9.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.54 seconds.\n","-- Epoch 1\n","Norm: 10.86, NNZs: 97, Bias: -3.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.79 seconds.\n","Norm: 36.36, NNZs: 624, Bias: -7.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.73 seconds.\n","Norm: 19.60, NNZs: 253, Bias: -4.000000, T: 10976, Avg. loss: 0.000000\n","Total training time: 0.78 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    2.5s remaining:    0.5s\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.7s finished\n","  1%|          | 5/500 [00:00<00:10, 48.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Norm: 91.52, NNZs: 2278, Bias: 3.000000, T: 10976, Avg. loss: 0.000911\n","Total training time: 0.50 seconds.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 500/500 [00:06<00:00, 72.00it/s]\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-145-685d4c2f6277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mner_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/MythNLP/lib/python3.5/site-packages/sklearn/feature_extraction/dict_vectorizer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m                         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                         \u001b[0mXa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"YxRUfIIS9hLC","colab_type":"text"},"cell_type":"markdown","source":["add results visualization"]}]}