{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unsupervised Learning.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1KYAx17NDJSgA1IETdrjbRdrW0Bw4Hsb3","timestamp":1530783736511}],"collapsed_sections":["ritA2sAX2Sfl","k0Fqi4_32g0c","aoSkOA2NqDy0"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"3DngqjBY1oiC","colab_type":"text"},"cell_type":"markdown","source":["# 1. Intro a la clase"]},{"metadata":{"id":"B90jRY2RNgcX","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","## Brief difference between Supervised and Unsupervised Learning.\n","\n","![Supervised vs Unsupervised](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/Images/supervised_unsupervised.png \"Supervised vs Unsupervised\")\n","\n","Seguro que ya se ha dado en Machine Learning, sólo para estar todos en la misma página. En Supervised Learning tenemos etiquetas. Es decir, queremos \"separar\". Cuando empezamos a plantear un modelo para supervised learning, lo único que tenemos claríssimo es el formato del output. Podemos discutir que features usamos, que modelo se adapta mejor, que función de optimización, si usamos regularización, etc etc, pero lo único que no podemos discutir, es que estamos escogiendo entre perros y gatos, porque solo podemos escoger entre perros y gatos. Si luego en producción alguien quiere predecir girafas, muy buena suerte, y ya podéis empezar a descargaros fotos de girafas.\n","\n","En unsupervised learning, hay menos discusión de modelos, pero en cambio, no tenemos ni idea de como es el la distribución de clases. Con lo cuál el problema es muchísimo más grande. En definitiva, en unsupervised learning, el *auténtico machine learning* le damos datos a la máquina, y ya se espabilará, y de verdad, porque no le vamos a decir ni cuando se está equivocando, para que nos devuelva información útil. \n","\n","NLP no se escapa de usar unsupervised learning.\n","\n","![](https://i.imgur.com/jbc5S9a.jpg)\n","\n","Por cierto, en la última clase, que vimos modelado del lenguaje, tiene \"etiquetas\" y ni así se libra del debate supervised vs unsupervised. (Esto es de hace 20 días en twitter), ni los mismos expertos se ponen de acuerdo.\n","\n","En definitiva, que podemos aplicar también unsupervised learning a NLP, y ahora veremos cómo, y que usos podemos darle.\n","\n","\n"]},{"metadata":{"id":"8pjmpz7yNgcW","colab_type":"text"},"cell_type":"markdown","source":["# Unsupervised Learning in NLP\n","\n","Que pasa cuando no tenemos acceso a labels en NLP? Unsupervised Learning. Hay varios modelos y varios objectivos en aplicar técnicas de unsupervised Learning en NLP. El objetivo más común es *Topic Modeling*.  Como lo conseguimos? Uno de los algoritmos más comunes es el conocido como Latent Dirichlet Allocation (LDA) [Paper](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf). (Como nota interesante, el paper esta escrito por 3 de las personas más influyenentes en el mundo de la inteligencia artificial, no solo Machine Learning o Deep Learning). Quizás el más conocido es Andrew NG, muy conocido por el curso de intro al Machine Learning en Coursera. Pero si os interesa estadística y el modelado bayesiano de datos, Blei y Jordan son dos figuras claves para entender el panorama actual.\n","\n","Dicho esto, hay otros algoritmos muy populares como la factorizacion de matrices no negativas (Non-Negative Matrix Factorization *NNF*) o otros incluso SVD  (singular value decomposition). Estos metodos no los veremos, pero quizás en álgebra habéis visto como funcionaban.\n","\n","## 1. Cuál es el objetivo de Topic Modeling?\n","\n","Imaginaros que quereis hacer un algoritmo que os recomiende tweets, y no teneis claro si podeis montar un algoritmo supervisado porque no teneis taggeados datos con los clásicos like/dislike o ratios. Sin esto, no podéis entrenar un algoritmo supervisado. Además tampoco tenéis ninguna relación usuario-items donde se podría aplicar *Collaborative Filtering [(post con breve explicación)](https://medium.com/@cfpinela/recommender-systems-user-based-and-item-based-collaborative-filtering-5d5f375a127f)* pero queremos tener algo que sea capaz de dar con tweets similares. Como lo hacemos? Topic Modeling al rescate. La idea de detrás del topic modeling es fácil: un documento esta formado por n-topics, y cada topic esta formado por una distribución de palabras. Y entonces podriamos representar tweets con topics similares y recomendarlos, por ejemplo, no solo unicamente basado en palabras.\n","\n","\n","##### Extra info\n","\n","[LDA medium post](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n","[Buena explicación de LDA](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/)\n","\n","\n","## 2. Word Embeddings\n","\n","Otra de las aplicaciones que veremos hoy, y que va a ser clave en el desarrollo e introducción clave del Deep Learning en NLP, son los words embeddings. Entended que como muchos aspectos del deep learning, son algoritmos que vienen de muy atrás, y que con alguna modificación tienen una mejora enorme, con lo que se convierten en 100% aplicables. Hoy en día, el 100% de los algoritmos que se usan en NLP, usan word embeddings. Estan en todas partes. En vuestro telefono, en vuestros recomendadores, en la respuesta automatica del correo, vaya, que cada cosa que tecleeis, seguro usa word embeddings. De hecho, se hay estudios y papers donde usan técnicas muy similares a las usadas para word embeddings que se usan para mil cosas. Os gustan los emojis? Se han aplicado. [Emojis](http://sempub.taln.upf.edu/tw/emojis/), para emojis aplicados y ver su semantismo dependiendo del color del emoji? [Aquí](http://www.aclweb.org/anthology/S18-2011). Para casos muy interesantes como el análisis de Bases de datos de grafo? [Pues tambien](https://github.com/D2KLab/entity2vec) En fin, que para lo que querais tenéis embeddings. En NLP nos centraremos en los word embeddings, que ya tenemos suficiente con eso. \n","\n","Lo veremos mejor en las siguientes notebooks, pero muy muy MUY en resumen, en lugar de representar el texto con una id que representa un token, es decir... dibujo mejor.\n","\n","![](https://i.imgur.com/4jHoUVz.png)\n","\n","Aquí si veremos factorización de matrices para generar-los, y tambien nuestra primera red neuronal."]},{"metadata":{"id":"ke60aFk4NgcY","colab_type":"text"},"cell_type":"markdown","source":["# 2. Topic Modeling\n","### 2.1 LDA"]},{"metadata":{"id":"0iFwxriuNgcY","colab_type":"text"},"cell_type":"markdown","source":["La siguiente imagen da un claro ejemplo de que es lo que queremos conseguir, no muy bien como lo haremos, pero si cual es el objetivo.\n","\n","![Topic Modeling](http://chdoig.github.io/pytexas2015-topic-modeling/images/topic-modeling-2.png \"Topic Modeling\")\n","\n","Antes de empezar con la implementación, un poquito de teoría (veremos muy poca), pero consideraciones previas. \n","\n","Topic modeling no se escapa de algunos de los problemas que hemos encontrado previamente en fases de preproceso y elección de features.\n","\n","\n","*   Fijaremos el vocabulario antes de empezar. Con lo cual tendremos el mismo problema que tenemos hasta la fecha cuando usamos palabras como features, todo lo que no este dentro al empezar, esta fuera. (Igual que cuando especificamos un proyecto en el trabajo, que todo lo que no se ha dicho no se hace.)\n","*   Seguiremos con la representación de bag-of-words que hemos usado hasta la saciedad hasta la fecha.\n","\n","Es importante decir que LDA es un modelo generativo, igual que lo es un naive Bayes classifier, tal y como vimos en el problema de Language Modeling. No entraremos en las matemátias pero básicamente, un modelo *generativo* nos permite una vez entrenado, crear samples de x, es decir \"inputs similares\" a los usados para entrenar el modelo, por el contrario, un modelo *discriminativo* solo nos permite dado un input, dar un output, una etiqueta.\n","\n","Que es la cajita esa negra?\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Latent_Dirichlet_allocation.svg/250px-Latent_Dirichlet_allocation.svg.png)\n","\n","La cajita negra es estas cajitas, que representan el algoritmo con todos sus parametros.\n","\n","El primer parámetro y el más signitifactivo a escoger es T. T es el numero de topics que queremos. Hemos dicho que no tenemos etiquetas, así que no sabemos cuántas tenemos. Así pues, escogeremos un numero T que nos parezca. Este determinara lo que terminara aprendiendo el modelo. si escogemos T=2, al final tendremos por cada documento una distribución de 2 topics, y cada palabra tendrá una distribución sobre estos 2 topics. Más adelante veremos como escoger un T de forma algo más óptima, pero no nos libraremos del prueba y error.\n","\n","![](http://mcburton.net/blog/joy-of-tm/images/image02.png)\n","\n","![](https://datawarrior.files.wordpress.com/2016/04/proj3_lda20structure.png?w=640)\n","\n","Quizás estos dos dibujos ayuden un poco más, ahora explicaremos un poco la fase de aprendizaje de este algoritmo.\n","\n","\n","\n","> Para cada documento, asignar una palabra a un topic at random.\n","\n","> Loop:\n","\n","> > Para cada topic calcular\n","\n","> > > *p(t|D=d) =* palabras en el documento asignadas al topic t\n","\n","> > > *p(w|T=t) =* La proporcion de asignaciones a t, que provienen de la palabra w. Es decir, de todas las palabras que son del topic t, cuantas vienen de w.\n","\n","> >  Recalcular el topic de w, siendo tal que *P(t|d) x P(w|t)*\n","\n","Dicho esto, vamos a implementar y ver que pasa.\n","\n","![](https://i.imgur.com/vD6fRri.jpg)\n","\n","Visto con emojis, que es lo que obtenemos?\n","\n","![](https://cdn-images-1.medium.com/max/1400/1*7ompnTE6eiH_3CitGvtveQ.png)\n","\n","#### Casos de uso reales\n","\n","[User Behaviour](http://www.cs.columbia.edu/~blei/talks/Blei_User_Behavior.pdf)\n","\n","#### Documentación extra\n","\n","[Intro to LDA](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/)\n","\n","[Emoji LDA](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)"]},{"metadata":{"id":"ritA2sAX2Sfl","colab_type":"text"},"cell_type":"markdown","source":["## 2. Librerías"]},{"metadata":{"id":"_noskQJ_ZxAD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install gensim\n","!pip install pyLDAvis\n","!pip install spacy\n","!python -m spacy download en_core_web_sm\n","!pip install stop_words"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MLxHtBgwNgcZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import gensim\n","from os.path import join\n","import csv\n","import spacy\n","from stop_words import get_stop_words\n","from string import punctuation\n","import re\n","import numpy as np\n","import pyLDAvis.gensim\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import io\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k0Fqi4_32g0c","colab_type":"text"},"cell_type":"markdown","source":["## 3. Data\n","\n","### 3.1 Preprocesado de datos como siempre."]},{"metadata":{"id":"f_JmG4m_Ngcc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["stop_words = get_stop_words('en') + list(punctuation) + [' ']\n","nlp = spacy.load('en_core_web_sm')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9lxC89ZNbG35","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":91},"outputId":"5aa6ad6a-efaf-413c-c17d-37fc1fdd39bb","executionInfo":{"status":"ok","timestamp":1530777801443,"user_tz":-120,"elapsed":19779,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-49cc62f4-983b-4afa-a054-eceb1b53810d\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-49cc62f4-983b-4afa-a054-eceb1b53810d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving topic_modelling.csv to topic_modelling (1).csv\n","User uploaded file \"topic_modelling.csv\" with length 211933 bytes\n"],"name":"stdout"}]},{"metadata":{"id":"2hcqCHNubDxe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["df = pd.read_csv(io.StringIO(uploaded['topic_modelling.csv'].decode('utf-8')))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aoSkOA2NqDy0","colab_type":"text"},"cell_type":"markdown","source":["### Preparar Dataset"]},{"metadata":{"id":"-7wBBk6nNgck","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#get data\n","documents = []\n","for row in df.iterrows():\n","    _, info = row\n","    _, q, a = info\n","    q = re.sub(r'\\n', '', q)\n","    a = re.sub(r'\\n', '', a)\n","    q = [t.text for t in nlp(q.rstrip(), disable=['parser', 'tagger', 'ner']) if t.text not in stop_words]\n","    a = [t.text for t in nlp(a.rstrip(), disable=['parser', 'tagger', 'ner']) if t.text not in stop_words]\n","    documents.append(q)\n","    documents.append(a)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LxyD4PhL4Q9p","colab_type":"text"},"cell_type":"markdown","source":["#### 3.2 Exploración light del dataset"]},{"metadata":{"id":"GJI1zFRMNgcp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"66d591f2-f878-469f-e20b-0e238df3c2cc","executionInfo":{"status":"ok","timestamp":1530778077135,"user_tz":-120,"elapsed":442,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["#dictionary building manually as always\n","vocab = set([t for doc in documents for t in doc])\n","w2id = {k:i for  i,k in enumerate(vocab)}\n","id2w = {i:k for k, i in w2id.items()}\n","print('{} unique tokens'.format(len(w2id)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3165 unique tokens\n"],"name":"stdout"}]},{"metadata":{"id":"-UOF_SPIqRF1","colab_type":"text"},"cell_type":"markdown","source":["## Introducción a Gensim"]},{"metadata":{"id":"mVH8PD9rNgc7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"3LtUite3Ngc-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"298b5c18-6333-4773-8a9a-808f01529952","executionInfo":{"status":"ok","timestamp":1530781155211,"user_tz":-120,"elapsed":453,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3165"]},"metadata":{"tags":[]},"execution_count":34}]},{"metadata":{"id":"KkhPYIIaNgdD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"VOH850Lg25_h","colab_type":"text"},"cell_type":"markdown","source":["### 3.3 Implementación usando Gensim\n","\n","[LDA API](https://radimrehurek.com/gensim/models/ldamodel.html)"]},{"metadata":{"id":"90vTaSSCNgdG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"Lq6LG1vdNgdI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"_arFPlNstxPU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"fL_uL1FM3MCZ","colab_type":"text"},"cell_type":"markdown","source":["#### 3.4 Visualización del modelo."]},{"metadata":{"id":"yA_Mx4GNNgdM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"JomVf_UhNgdV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"CG_UAxBANgdc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZkxX_CYJ3c-D","colab_type":"text"},"cell_type":"markdown","source":["#### 3.6 Con que modelo nos quedamos?"]},{"metadata":{"id":"wavHWOCpNgdf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from gensim.models import CoherenceModel\n","def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n","    None"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7IbMSU5PNgdh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}