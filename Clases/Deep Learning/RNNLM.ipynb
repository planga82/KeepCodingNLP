{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNNLM.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"IRBlrFdoE2FA","colab_type":"text"},"cell_type":"markdown","source":["# Language Modeling. Hemos vuelto.\n","\n","Ahora que hemos visto un montón de arquitecturas, y sus aplicaciones al lenguaje natural, si quisieramos hacer language modeling... cuál escogeríais?\n","\n","![](https://cdn-ak.f.st-hatena.com/images/fotolife/a/aki-don/20170929/20170929085607.png)\n","\n","Hay mucísimas formas de intentarlo.\n","\n","Implementaremos algunas de ellas , para que veais que en deep learning, hay libertad para intentarlo practicamente todo. Predecir palabras? Predecir carácteres. Usar embeddings? No Usarlos? Usar Bidirectional LSTMs? Stackearlas? \n","\n","Básicamente, seguiremos el mismo pipeline que hasta ahora.\n","\n","Un poco de preproceso, preparar los datos, escoger la arquitectura a usar, y entrenar/predecir.\n","\n","Esta vez os daré un snippet de código para visualizar en directo lo que esta aprendiendo la red, y poder leer ejemplos de aquello que aprende.\n","\n","Lo haremos todo con keras, como siempre!"]},{"metadata":{"id":"BPs_-1UsHMv8","colab_type":"text"},"cell_type":"markdown","source":["## Imports"]},{"metadata":{"id":"tq-vZfRT9bmY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download en_core_web_sm"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9KTjchCwMzzD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import spacy\n","import numpy as np\n","\n","import pickle\n","import json\n","import os\n","import csv\n","import pprint as pp\n","\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","from random import shuffle, choice, sample\n","\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","from copy import copy\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","data_path = '../datasets/data/'\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import pylab as pl\n","from IPython import display\n","\n","sns.set(color_codes=True)\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","%matplotlib notebook"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GfqsamXkMzzG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"f51775a1-1788-49d4-e769-37660b063336"},"cell_type":"code","source":["from keras.models import Model, Sequential\n","from keras.layers import Input, CuDNNLSTM, Dense, LSTM\n","from keras.layers import Bidirectional\n","from keras.layers import Embedding\n","from keras.layers import Merge, Dot, Concatenate, Flatten, Permute, Multiply, dot, concatenate\n","from keras.layers import TimeDistributed\n","from keras.layers import Activation\n","from keras.preprocessing import sequence\n","from keras.callbacks import Callback\n","from keras.optimizers import SGD\n","from keras.models import load_model\n","\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"JgQqy9l6HPNu","colab_type":"text"},"cell_type":"markdown","source":["## Preprocess"]},{"metadata":{"id":"xbA_BTAGMzzK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"ac3da618-ac1e-41af-dcd9-89170258b2d0"},"cell_type":"code","source":["uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["747\n"],"name":"stdout"}]},{"metadata":{"id":"zXCwqokG9tdE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["df = pd.read_csv(io.StringIO(uploaded['spam.csv'].decode('ISO-8859-1')))\n","drop_col = df.columns[2:]\n","df = df.drop(columns=drop_col, axis=1)\n","df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1KSqyeCm9usk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["spam_dataset = []\n","for index, row in df.iterrows():\n","    if index>0:\n","        sentence = row[1]\n","        spam_dataset.append(sentence)\n","print(spam_dataset[0])\n","len(spam_dataset)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jW5c-nE6MzzP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["tokenized = [list(x) for x in spam_dataset]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KkB5WUlbMzzS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["init_chars = [x[:5] for x in tokenized]\n","for i in range(len(init_chars)):\n","    tmp = init_chars[i]\n","    tmp.insert(0, '<SOS>')\n","    init_chars[i] = tmp[:5]    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"_zCvGJnqMzzT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"4a3e8bac-076d-4806-83cb-dfa78bf36dcc"},"cell_type":"code","source":["init_chars[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<SOS>', 'G', 'o', ' ', 'u']"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"a0z_bbdRMzzX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"1abf3e14-452d-47ec-e9e5-fca5f36863d4"},"cell_type":"code","source":["start_token = [s[1] for s in tokenized if len(s) > 1]\n","len(start_token)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["747"]},"metadata":{"tags":[]},"execution_count":32}]},{"metadata":{"id":"mgV7eHVfMzzc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"90fc272b-9c0b-4478-d708-bc7457c341c4"},"cell_type":"code","source":["maxlen = max([len(x) for x in tokenized])\n","avglen = sum([len(x) for x in tokenized])/len(tokenized)\n","print(maxlen, avglen)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["223 138.429718875502\n"],"name":"stdout"}]},{"metadata":{"id":"xG6wbq1oMzzh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from collections import Counter"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Pm8qb7S3Mzzk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q4oWsT0SMzzn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"RNz9pVRtMzzs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"fBquffzJMzzy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["SAMPLE_EVERY = 3\n","PLOT_EVERY = 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4tdteb0lHTNN","colab_type":"text"},"cell_type":"markdown","source":["## Helper functions"]},{"metadata":{"id":"gq0lOMoyMzz0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def sample_pred(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YVMl3_E0Mzz-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class Sampletest(Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        if epoch % SAMPLE_EVERY == 0  and epoch>0:\n","            data_test = []\n","            nb_samples = 1\n","            \n","            params = {\n","                'maxlen': maxlen,\n","                'vocab': nb_vocab,\n","                'use_embeddings': True\n","                }\n","            for _ in range(nb_samples):\n","                data_test = choice(init_chars)\n","                x_pred = np.zeros((1, params['maxlen'], params['vocab']), dtype=np.bool)\n","                for diversity in [0.2, 0.6, 1.2]:\n","                    print('----- diversity:', diversity)\n","                    sentence = copy(data_test)\n","                    generated = copy(data_test)\n","                    for i in range(len(data_test), 400):\n","                        x_pred = np.zeros((1, params['maxlen'], params['vocab']))\n","                        for t, char in enumerate(sentence):\n","                            x_pred[0, t, w2id[char] if char in w2id else w2id['<UNK>']] = 1.\n","                        preds = self.model.predict(x_pred, verbose=0)[0]\n","                        next_index = sample_pred(preds, diversity)\n","                        next_char = id2w[next_index]\n","                        if next_char == '<EOS>':\n","                            break\n","                        generated += [next_char]\n","                        sentence = sentence[1:] \n","                        sentence += [next_char]\n","                    print(''.join(generated))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R-G4B_J-Mz0B","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class HistoryDisplay(Callback):\n","    \n","    def on_train_begin(self, logs={}):\n","        self.losses = []\n","        self.accs = []\n","        self.epochs = []\n","        self.fig, self.ax = plt.subplots()\n","        #plt.show()\n","        \n","        plt.ion()\n","        self.fig.show()\n","        self.fig.canvas.draw()\n","    \n","    def on_epoch_end(self, epoch, logs):\n","        self.epochs.append(epoch)\n","        self.losses.append(logs['loss'])\n","        self.accs.append(logs['acc'])\n","        if epoch % PLOT_EVERY == 0:\n","            \n","            self.ax.clear()\n","            self.ax.plot(self.epochs, self.accs, 'g', label='acc')\n","            self.ax.plot(self.epochs, self.losses, 'b', label='loss')\n","            legend = self.ax.legend(loc='upper right', shadow=True, fontsize='x-large')\n","            #display.clear_output(wait=True)\n","            #display.display(pl.gcf())\n","            self.fig.canvas.draw()\n","            \n","            #plt.draw()\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"G9HoaaKfMz0D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class TimeHistory(Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","\n","    def on_epoch_begin(self, batch, logs={}):\n","        self.epoch_time_start = time.time()\n","\n","    def on_epoch_end(self, batch, logs={}):\n","        self.times.append(time.time() - self.epoch_time_start)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3-j3k2CdHXeJ","colab_type":"text"},"cell_type":"markdown","source":["## Decidir arquitectura y preparar el train y el predict"]},{"metadata":{"id":"NUbfuvv8Mz0K","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class LM:\n","    def __init__(self, **kwargs):\n","        self.params = kwargs.pop('params', None)\n","    \n","    def compile_bidirectional(self, params={}):\n","        None              \n","        \n","    def train(self, model, data, params={}):\n","        \n","        callbacks = self._get_callbacks()\n","\n","    def predict(self, model, data, params={}):        \n","        None\n","    \n","    def load(self, model_path='seq2seq_attn.h5'):\n","        return load_model(model_path)\n","    \n","    def _get_callbacks(self, model_path='seq2seq_attn.h5'):\n","        es = EarlyStopping(monitor='loss', patience=4, mode='auto', verbose=0)\n","        save_best = ModelCheckpoint(model_path, monitor='loss', verbose = 0, save_best_only=True, save_weights_only=False, period=2)\n","        st = Sampletest()\n","        hd = HistoryDisplay()\n","        rlr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose=0)\n","        return [st, save_best, hd]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J1BvbwqhHe4j","colab_type":"text"},"cell_type":"markdown","source":["## Hyperparametros"]},{"metadata":{"id":"Y8xxeun3Mz0N","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"adMpZ7bVMz0S","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["LOAD_MODEL = False\n","bTrain = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W2wDT77qHjgm","colab_type":"text"},"cell_type":"markdown","source":["## Compilar"]},{"metadata":{"id":"oIYlC9ZjMz0U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["lm = LM()\n","if LOAD_MODEL:\n","    path = 'final_{}.h5'.format(dtype)\n","    lm_model = lm.load(model_path=path)\n","    lm_model.summary()\n","else:\n","    lm_model = lm.compile_bidirectional(params=compile_params)    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"XJmV8jqUHmJa","colab_type":"text"},"cell_type":"markdown","source":["## Entrenar"]},{"metadata":{"id":"JXjlLxs9Mz0X","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_params = {\n","    'epochs': 500,\n","    'batch_size': 512,\n","    'shuffle': True,\n","    'vocab': nb_vocab,\n","    'maxlen': maxlen,\n","    'use_embeddings': True\n","}\n","pp.pprint(train_params)\n","if bTrain:\n","    lm.train(model=lm_model, data=data_train, params=train_params)"],"execution_count":0,"outputs":[]}]}