{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Neural Networks.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"L8BYS83YMwpA","colab_type":"text"},"cell_type":"markdown","source":["# Recursos \n","\n","[LSTMS](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n","\n","[Unreasonably unRNNsonal](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n","\n","[Best Practices: Deep Learning for NLP](http://ruder.io/deep-learning-nlp-best-practices/index.html)"]},{"metadata":{"id":"96noGFojMwpC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"23dc119b-3840-4461-b2f4-8f6ea290d1ad","executionInfo":{"status":"ok","timestamp":1531066282310,"user_tz":-120,"elapsed":2796,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["%matplotlib inline\n","\n","import keras\n","import numpy as np\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"g5Y8VgiUMwpF","colab_type":"text"},"cell_type":"markdown","source":["# Prerequisitos\n","\n","Para el día de hoy asumiremos que hemos visto Deep Learning. Haremos un breve repaso, pero la idea es centrarse en el uso de las distintas arquitecturas dentro de Deep Learning.\n","\n","# Brevísimo repaso\n","\n","Deep Learning se convierte en viable por dos grandes factores, el uso de GPUs, y la aparición del \"Big Data\". Son modelos de Machine Learning, pero que además aprenden \"features\". Es decir, hace 5-10 años se gastaba muchos esfuerzos en conseguir buenas features para cada tipo de problema, hoy en día, se gastan muchos esfuerzos en comprar GPUs y conseguir datos. \n","\n","Deep Learning ha tenido un immenso desarrollo en Computer Vision, en NLP el progreso es menor. El progreso en NLP empieza a crecer con el desarrollo de los word embeddings, que ahora son parte obligada en cualquier pipeline de NLP que use deep learning. En la anterior clase creamos nuestros propios word embeddings, ahora es momento de añadirlos dentro del pipeline.\n","\n","Como es bien sabido, entrenamos nuestros modelos con gran cantidad de datos, no siempre bien curados. [Aquí](https://retina.elpais.com/retina/2017/05/12/tendencias/1494612619_910023.html) teneis un artículo que salió el año pasado en El Pais, en que se denunciaba el bias que conlleva entrenar ciertos modelos así. De hecho, me costaba creermelo, así que decidí comprobarlo, y la verdad es que ... los resultados me sorprendieron... por ser ciertos. En visión por ordenador, este tipo de problemas no nos lo encontramos, podemos encontrarnos otro tipo de problemas, pero este no. Este tipo de problemas son generados cuando usamos unsupervised learning para entrenar modelos. \n","\n","Dicho esto, si para imagen hemos usado redes convolucionales, y quizas ¿recurrentes? para texto usaremos las mismas. A medida que las vayamos usando iremos explicando un poquito de rol, y que podemos esperar de ellas, y la motivación en su uso.\n","\n","![BILSTM](https://pbs.twimg.com/media/C8f9PdkVoAACcot.jpg \"BILSTM\")\n","\n","## Tipos de red que usaremos\n","1. DNN\n","2. CNN\n","3. RNN\n","\n","## Arquitecturas y Operaciones avanzadas (si hay tiempo)\n","1. Seq2Seq\n","2. Attention"]},{"metadata":{"id":"F11c1In1MwpF","colab_type":"text"},"cell_type":"markdown","source":["## Pipeline para redes neuronales\n","\n","Como modifica nuestro pipeline Deep Learning? Más bien poco. Seguiremos generalmente generando un vocabulario de nuestro test de entrenamientos. En algunos casos usaremos tokens especiales como '_UNK_', _PAD_, _SOS_ o _EOS_, nada que no hayamos visto antes. Usaremos las mismas técnicas de mapeo de palabra a índice como ya hemos hecho con anterioridad y poco más. Donde si nos cambia un poco es en el tema del diseño del modelo, donde hay que tener en cuenta que hay que añadir word embeddings en el proceso. De todas formas como veréis, es bastante fácil recordar como, porque siempre funciona exactamente igual. \n","\n","En resumidas cuentas:\n","\n","1. Data preprocess.\n","2. Word Embeddings\n","2. Define Model\n","3. ???? (fit)\n","4. Profit\n","\n","## Diseño normal de una red\n","\n","![Typical Design](https://i.imgur.com/ijJ0M5G.png \"Typical Design\")\n","\n","Fijaros una cosa que es muy importante aquí, aunque lo he diferenciado. Los embeddings son una parte ENTRENABLE de la red. Es decir, no es que generemos unos embeddings, y eso pasen a ser el input de nuestros modelos, sino que son parte ENTRENABLE. Es verdad, que como cualquier capa de una red, sus pesos pueden ser congelados, pero es una opción. \n","\n","### Tips cuando metemos word embeddings\n","\n","* Suele ser buena idea usar pre-trained word embeddings. Aquí tenéis [GloVe](https://nlp.stanford.edu/projects/glove/), [word2vec](https://code.google.com/archive/p/word2vec/) y [fasttext](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md)\n","\n","* Algo que mucha gente se olvida cuando usa pretrained vectors, es que los usa todos. Tenemos que plantearnos que vocabulario usara nuestra aplicación. Si tenemos un train set muy claro, lo ideal es solo usar una matriz de *V x dim*, donde V es el vocabulario del train set. Esto se hace porque en muchas aplicaciones de hoy en día, sobretodo si vamos a trabajar con datos de usuarios, con input libre, es muy probable que empiezen a entrar palabras que no hemos visto nunca en el entreno, por lo tanto es mejor evaluar en codiciones \"reales\" usando el token de *UNK* cuando no hemos visto el token/palabra del input.\n","\n","* No entraremos en tips para mejorar la performance en el entreno, pero si que es buena idea cuando usemos por ejemplo CNNs, que hagamos un pequeno estudio previo de la longitud máxima de la secuencia, y la media, para poder padear acorde.\n","\n","### Que pasa cuando hacemos fine-tunning de word embeddings?\n","\n","Imaginad que tenemos, como el caso de los mencionades anteriormente unos word embeddings \"genéricos\", entrenados sólo por tener los word embeddings. Luego los usamos para una tárea de clasificación. Son reaprovechables estos word-embeddings re-entrenados?\n"]},{"metadata":{"id":"oglbj9ZwMwpG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Epm9nzapMwpJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"UfMJv2QLMwpL","colab_type":"text"},"cell_type":"markdown","source":["## Ejemplo de clasificación clásico\n","\n","### Imports/Preprocess"]},{"metadata":{"id":"qZyh367YCrM8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":583},"outputId":"51f3f23e-bc30-4750-cf96-79c7602a839c","executionInfo":{"status":"ok","timestamp":1531066298420,"user_tz":-120,"elapsed":8507,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download en_core_web_sm"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.11)\r\n","Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (2017.4.5)\r\n","Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.31.2)\r\n","Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n","Requirement already satisfied: thinc<6.11.0,>=6.10.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.10.2)\n","Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n","Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.5)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n","Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n","Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.28.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (4.23.4)\n","Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.11.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.10.11)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.1.0)\n","Requirement already satisfied: cytoolz<0.9,>=0.8 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (0.8.2)\n","Requirement already satisfied: msgpack-python in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (0.5.6)\n","Requirement already satisfied: msgpack-numpy==0.4.1 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (0.4.1)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy) (0.9.0)\n","Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n","\u001b[K    100% |████████████████████████████████| 37.4MB 24.8MB/s \n","\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /usr/local/lib/python3.6/dist-packages\n","\n","\u001b[93m    Linking successful\u001b[0m\n","    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_sm\n","\n","    You can now load the model via spacy.load('en_core_web_sm')\n","\n"],"name":"stdout"}]},{"metadata":{"id":"BCeE51_2MwpL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import spacy\n","\n","import pickle\n","import json\n","import os\n","import csv\n","\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import io\n","\n","\n","from random import sample\n","\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B6y-NmRfMwpO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner', 'textcat'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kV46IZyLMwpR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def split_train_val_test(dataset, split=0.2):\n","\n","    x, y = zip(*dataset)\n","    x = np.array(list(x))\n","    y = np.array(list(y))\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=split, random_state=1337) #l33t seed\n","    for train_index, test_index in sss.split(x, y):\n","        x_train, x_val = x[train_index], x[test_index]\n","        y_train, y_val = y[train_index], y[test_index]\n","    splits = {'train':(x_train, y_train), 'test':(x_val, y_val)}\n","    return splits"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ms22jHZ0brGD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":91},"outputId":"70111d22-754f-4003-f712-07efbfd47f9e","executionInfo":{"status":"ok","timestamp":1531066524265,"user_tz":-120,"elapsed":167687,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-51427b69-ef4f-4e47-babe-fb3a34240b63\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-51427b69-ef4f-4e47-babe-fb3a34240b63\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving test.csv to test (3).csv\n","User uploaded file \"test.csv\" with length 21775285 bytes\n"],"name":"stdout"}]},{"metadata":{"id":"MOjumzsadsOx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["labels = ['Company',\n","            'EducationalInstitution',\n","            'Artist',\n","            'Athlete',\n","            'OfficeHolder', \n","            'MeanOfTransportation',\n","            'Building',\n","            'NaturalPlace',\n","            'Village',\n","            'Animal',\n","            'Plant',\n","            'Album',\n","            'Film',\n","            'WrittenWork'\n","         ]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DswuMGvCDVa0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1907},"outputId":"5285f15a-f6d5-4a32-c29e-65a650419eda","executionInfo":{"status":"ok","timestamp":1531066525948,"user_tz":-120,"elapsed":973,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["df = pd.read_csv(io.StringIO(uploaded['test.csv'].decode('utf-8')), names=['class', 'title', 'content'])\n","\n","# col_list = ['text', 'message']\n","\n","# df = df[col_list]\n","\n","# df = df.drop(columns=drop_col, axis=1)\n","df"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>title</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>TY KU</td>\n","      <td>TY KU /taɪkuː/ is an American alcoholic bever...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Odd Lot Entertainment</td>\n","      <td>OddLot Entertainment founded in 2001 by longt...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Henkel</td>\n","      <td>Henkel AG &amp; Company KGaA operates worldwide w...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>GOAT Store</td>\n","      <td>The GOAT Store (Games Of All Type Store) LLC ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>RagWing Aircraft Designs</td>\n","      <td>RagWing Aircraft Designs (also called the Rag...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>Pošte Srpske</td>\n","      <td>Pošte Srpske is one of three companies respon...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>Open Kernel Labs</td>\n","      <td>Open Kernel Labs (OK Labs) is a privately own...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>Skye Bank</td>\n","      <td>Skye Bank Plc. commonly known as Skye Bank is...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>CNet Technology</td>\n","      <td>CNet Technology is a Taiwanese company that m...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>188BET</td>\n","      <td>188BET is an online sportsbook provider. 188B...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>MEPC plc</td>\n","      <td>MEPC plc is a leading British-based property ...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1</td>\n","      <td>Walter Aircraft Engines</td>\n","      <td>Walter Aircraft Engines was a company that ma...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1</td>\n","      <td>Export-Import Bank of Romania</td>\n","      <td>Exim Bank is The Export-Import Bank of Romani...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>Shell Oil Company</td>\n","      <td>Shell Oil Company is the United States-based ...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1</td>\n","      <td>Anabolic Video</td>\n","      <td>Anabolic Video is an American pornographic mo...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1</td>\n","      <td>Thon Hotels</td>\n","      <td>Thon Hotels (formerly known as Rainbow Hotels...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1</td>\n","      <td>Cook Group</td>\n","      <td>Cook Group Incorporated is an American privat...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1</td>\n","      <td>Slumberland Furniture</td>\n","      <td>Slumberland Furniture Inc. is a furniture ret...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1</td>\n","      <td>Outboard Marine Corporation</td>\n","      <td>Outboard Marine Corporation (OMC) was a maker...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1</td>\n","      <td>Moon River Brewing Company</td>\n","      <td>The Moon River Brewing Company is a brew pub ...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>1</td>\n","      <td>Murfin Music International</td>\n","      <td>Murfin Music International and Murfin Media a...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>1</td>\n","      <td>Avista</td>\n","      <td>Avista Utilities is a U.S. energy company. Av...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>1</td>\n","      <td>Korchma Taras Bulba</td>\n","      <td>Korchma Taras Bulba – the chain of restaurant...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>1</td>\n","      <td>Arçelik</td>\n","      <td>Arçelik A.Ş. is a household appliances manufa...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>1</td>\n","      <td>Ace of Clubs Records</td>\n","      <td>Ace of Clubs was owned by Decca Records in th...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>1</td>\n","      <td>Aerostar</td>\n","      <td>Aerostar S.A. is an aeronautical manufacturin...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>1</td>\n","      <td>Shandong Gaosu Group</td>\n","      <td>Shandong Gaosu Group or Shandong Hi-Speed Gro...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>1</td>\n","      <td>Aras Corp</td>\n","      <td>Aras Corporation is an American developer and...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>1</td>\n","      <td>Lam Research</td>\n","      <td>Lam Research Corporation is an American corpo...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>1</td>\n","      <td>Mataano</td>\n","      <td>Mataano is a women's fashion line. Founded in...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>69970</th>\n","      <td>14</td>\n","      <td>Tetragrammaton Labyrinth</td>\n","      <td>Tetragrammaton Labyrinth (断罪者〜Tetragrammaton ...</td>\n","    </tr>\n","    <tr>\n","      <th>69971</th>\n","      <td>14</td>\n","      <td>Slovenska smer</td>\n","      <td>Slovenska smer is a Slovene book containing c...</td>\n","    </tr>\n","    <tr>\n","      <th>69972</th>\n","      <td>14</td>\n","      <td>The Last Voyage of Somebody the Sailor</td>\n","      <td>The Last Voyage of Somebody the Sailor is a n...</td>\n","    </tr>\n","    <tr>\n","      <th>69973</th>\n","      <td>14</td>\n","      <td>The Dinosaur Heresies</td>\n","      <td>The Dinosaur Heresies: New Theories Unlocking...</td>\n","    </tr>\n","    <tr>\n","      <th>69974</th>\n","      <td>14</td>\n","      <td>The Squares of the City</td>\n","      <td>The Squares of the City is a science fiction ...</td>\n","    </tr>\n","    <tr>\n","      <th>69975</th>\n","      <td>14</td>\n","      <td>Pleiades (journal)</td>\n","      <td>Pleiades: A Journal of New Writing is an awar...</td>\n","    </tr>\n","    <tr>\n","      <th>69976</th>\n","      <td>14</td>\n","      <td>Citizen Soldiers</td>\n","      <td>Citizen Soldiers: The U.S. Army from the Norm...</td>\n","    </tr>\n","    <tr>\n","      <th>69977</th>\n","      <td>14</td>\n","      <td>Magic Fern (novel)</td>\n","      <td>The Magic Fern is a novel by the American wri...</td>\n","    </tr>\n","    <tr>\n","      <th>69978</th>\n","      <td>14</td>\n","      <td>An Israeli Love Story</td>\n","      <td>An Israeli Love Story is a play translated fr...</td>\n","    </tr>\n","    <tr>\n","      <th>69979</th>\n","      <td>14</td>\n","      <td>Mathematics of Operations Research</td>\n","      <td>Mathematics of Operations Research is a peer-...</td>\n","    </tr>\n","    <tr>\n","      <th>69980</th>\n","      <td>14</td>\n","      <td>The Lacuna</td>\n","      <td>The Lacuna is a 2009 novel by Barbara Kingsol...</td>\n","    </tr>\n","    <tr>\n","      <th>69981</th>\n","      <td>14</td>\n","      <td>Night Mary</td>\n","      <td>Night Mary is a horror comic book limited ser...</td>\n","    </tr>\n","    <tr>\n","      <th>69982</th>\n","      <td>14</td>\n","      <td>Bloodhound (novel)</td>\n","      <td>Bloodhound by Tamora Pierce is the second nov...</td>\n","    </tr>\n","    <tr>\n","      <th>69983</th>\n","      <td>14</td>\n","      <td>The Treasure of Tranicos (collection)</td>\n","      <td>The Treasure of Tranicos is a 1980 collection...</td>\n","    </tr>\n","    <tr>\n","      <th>69984</th>\n","      <td>14</td>\n","      <td>Requiem for a Dream (novel)</td>\n","      <td>Requiem for a Dream is a 1978 novel by Hubert...</td>\n","    </tr>\n","    <tr>\n","      <th>69985</th>\n","      <td>14</td>\n","      <td>Packing for Mars</td>\n","      <td>Packing for Mars: The Curious Science of Life...</td>\n","    </tr>\n","    <tr>\n","      <th>69986</th>\n","      <td>14</td>\n","      <td>Kokoro</td>\n","      <td>Kokoro (こゝろ or in post-war orthography こころ) i...</td>\n","    </tr>\n","    <tr>\n","      <th>69987</th>\n","      <td>14</td>\n","      <td>Seventh-day Adventist Hymnal</td>\n","      <td>The Seventh-day Adventist Hymnal is the offic...</td>\n","    </tr>\n","    <tr>\n","      <th>69988</th>\n","      <td>14</td>\n","      <td>Man vs Beast</td>\n","      <td>Man vs Beast is the sixth novel of the CHERUB...</td>\n","    </tr>\n","    <tr>\n","      <th>69989</th>\n","      <td>14</td>\n","      <td>Sétimo</td>\n","      <td>Sétimo (English: Seventh) is a vampire horror...</td>\n","    </tr>\n","    <tr>\n","      <th>69990</th>\n","      <td>14</td>\n","      <td>The Gift of Gab</td>\n","      <td>The Gift of Gab is an early science fiction s...</td>\n","    </tr>\n","    <tr>\n","      <th>69991</th>\n","      <td>14</td>\n","      <td>The Common Pursuit</td>\n","      <td>The Common Pursuit is a play by Simon Gray wh...</td>\n","    </tr>\n","    <tr>\n","      <th>69992</th>\n","      <td>14</td>\n","      <td>Sometimes the Magic Works</td>\n","      <td>Sometimes the Magic Works: Lessons from a Wri...</td>\n","    </tr>\n","    <tr>\n","      <th>69993</th>\n","      <td>14</td>\n","      <td>Zia (novel)</td>\n","      <td>Zia is the sequel to the award-winning Island...</td>\n","    </tr>\n","    <tr>\n","      <th>69994</th>\n","      <td>14</td>\n","      <td>Scottish Socialist Voice</td>\n","      <td>The Scottish Socialist Voice is a political n...</td>\n","    </tr>\n","    <tr>\n","      <th>69995</th>\n","      <td>14</td>\n","      <td>Energy Victory</td>\n","      <td>Energy Victory: Winning the War on Terror by ...</td>\n","    </tr>\n","    <tr>\n","      <th>69996</th>\n","      <td>14</td>\n","      <td>Bestiario</td>\n","      <td>Bestiario is a book of 8 short stories writte...</td>\n","    </tr>\n","    <tr>\n","      <th>69997</th>\n","      <td>14</td>\n","      <td>Wuthering Heights</td>\n","      <td>Wuthering Heights is a novel by Emily Brontë ...</td>\n","    </tr>\n","    <tr>\n","      <th>69998</th>\n","      <td>14</td>\n","      <td>L'Indépendant</td>\n","      <td>L'Indépendant is a newspaper published in Lux...</td>\n","    </tr>\n","    <tr>\n","      <th>69999</th>\n","      <td>14</td>\n","      <td>The Prophecy (novel)</td>\n","      <td>The Prophecy is the fifth novel by New York T...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>70000 rows × 3 columns</p>\n","</div>"],"text/plain":["       class                                   title  \\\n","0          1                                   TY KU   \n","1          1                   Odd Lot Entertainment   \n","2          1                                  Henkel   \n","3          1                              GOAT Store   \n","4          1                RagWing Aircraft Designs   \n","5          1                            Pošte Srpske   \n","6          1                        Open Kernel Labs   \n","7          1                               Skye Bank   \n","8          1                         CNet Technology   \n","9          1                                  188BET   \n","10         1                                MEPC plc   \n","11         1                 Walter Aircraft Engines   \n","12         1           Export-Import Bank of Romania   \n","13         1                       Shell Oil Company   \n","14         1                          Anabolic Video   \n","15         1                             Thon Hotels   \n","16         1                              Cook Group   \n","17         1                   Slumberland Furniture   \n","18         1             Outboard Marine Corporation   \n","19         1              Moon River Brewing Company   \n","20         1              Murfin Music International   \n","21         1                                  Avista   \n","22         1                     Korchma Taras Bulba   \n","23         1                                 Arçelik   \n","24         1                    Ace of Clubs Records   \n","25         1                                Aerostar   \n","26         1                    Shandong Gaosu Group   \n","27         1                               Aras Corp   \n","28         1                            Lam Research   \n","29         1                                 Mataano   \n","...      ...                                     ...   \n","69970     14                Tetragrammaton Labyrinth   \n","69971     14                          Slovenska smer   \n","69972     14  The Last Voyage of Somebody the Sailor   \n","69973     14                   The Dinosaur Heresies   \n","69974     14                 The Squares of the City   \n","69975     14                      Pleiades (journal)   \n","69976     14                        Citizen Soldiers   \n","69977     14                      Magic Fern (novel)   \n","69978     14                   An Israeli Love Story   \n","69979     14      Mathematics of Operations Research   \n","69980     14                              The Lacuna   \n","69981     14                              Night Mary   \n","69982     14                      Bloodhound (novel)   \n","69983     14   The Treasure of Tranicos (collection)   \n","69984     14             Requiem for a Dream (novel)   \n","69985     14                        Packing for Mars   \n","69986     14                                  Kokoro   \n","69987     14            Seventh-day Adventist Hymnal   \n","69988     14                            Man vs Beast   \n","69989     14                                  Sétimo   \n","69990     14                         The Gift of Gab   \n","69991     14                      The Common Pursuit   \n","69992     14               Sometimes the Magic Works   \n","69993     14                             Zia (novel)   \n","69994     14                Scottish Socialist Voice   \n","69995     14                          Energy Victory   \n","69996     14                               Bestiario   \n","69997     14                       Wuthering Heights   \n","69998     14                           L'Indépendant   \n","69999     14                    The Prophecy (novel)   \n","\n","                                                 content  \n","0       TY KU /taɪkuː/ is an American alcoholic bever...  \n","1       OddLot Entertainment founded in 2001 by longt...  \n","2       Henkel AG & Company KGaA operates worldwide w...  \n","3       The GOAT Store (Games Of All Type Store) LLC ...  \n","4       RagWing Aircraft Designs (also called the Rag...  \n","5       Pošte Srpske is one of three companies respon...  \n","6       Open Kernel Labs (OK Labs) is a privately own...  \n","7       Skye Bank Plc. commonly known as Skye Bank is...  \n","8       CNet Technology is a Taiwanese company that m...  \n","9       188BET is an online sportsbook provider. 188B...  \n","10      MEPC plc is a leading British-based property ...  \n","11      Walter Aircraft Engines was a company that ma...  \n","12      Exim Bank is The Export-Import Bank of Romani...  \n","13      Shell Oil Company is the United States-based ...  \n","14      Anabolic Video is an American pornographic mo...  \n","15      Thon Hotels (formerly known as Rainbow Hotels...  \n","16      Cook Group Incorporated is an American privat...  \n","17      Slumberland Furniture Inc. is a furniture ret...  \n","18      Outboard Marine Corporation (OMC) was a maker...  \n","19      The Moon River Brewing Company is a brew pub ...  \n","20      Murfin Music International and Murfin Media a...  \n","21      Avista Utilities is a U.S. energy company. Av...  \n","22      Korchma Taras Bulba – the chain of restaurant...  \n","23      Arçelik A.Ş. is a household appliances manufa...  \n","24      Ace of Clubs was owned by Decca Records in th...  \n","25      Aerostar S.A. is an aeronautical manufacturin...  \n","26      Shandong Gaosu Group or Shandong Hi-Speed Gro...  \n","27      Aras Corporation is an American developer and...  \n","28      Lam Research Corporation is an American corpo...  \n","29      Mataano is a women's fashion line. Founded in...  \n","...                                                  ...  \n","69970   Tetragrammaton Labyrinth (断罪者〜Tetragrammaton ...  \n","69971   Slovenska smer is a Slovene book containing c...  \n","69972   The Last Voyage of Somebody the Sailor is a n...  \n","69973   The Dinosaur Heresies: New Theories Unlocking...  \n","69974   The Squares of the City is a science fiction ...  \n","69975   Pleiades: A Journal of New Writing is an awar...  \n","69976   Citizen Soldiers: The U.S. Army from the Norm...  \n","69977   The Magic Fern is a novel by the American wri...  \n","69978   An Israeli Love Story is a play translated fr...  \n","69979   Mathematics of Operations Research is a peer-...  \n","69980   The Lacuna is a 2009 novel by Barbara Kingsol...  \n","69981   Night Mary is a horror comic book limited ser...  \n","69982   Bloodhound by Tamora Pierce is the second nov...  \n","69983   The Treasure of Tranicos is a 1980 collection...  \n","69984   Requiem for a Dream is a 1978 novel by Hubert...  \n","69985   Packing for Mars: The Curious Science of Life...  \n","69986   Kokoro (こゝろ or in post-war orthography こころ) i...  \n","69987   The Seventh-day Adventist Hymnal is the offic...  \n","69988   Man vs Beast is the sixth novel of the CHERUB...  \n","69989   Sétimo (English: Seventh) is a vampire horror...  \n","69990   The Gift of Gab is an early science fiction s...  \n","69991   The Common Pursuit is a play by Simon Gray wh...  \n","69992   Sometimes the Magic Works: Lessons from a Wri...  \n","69993   Zia is the sequel to the award-winning Island...  \n","69994   The Scottish Socialist Voice is a political n...  \n","69995   Energy Victory: Winning the War on Terror by ...  \n","69996   Bestiario is a book of 8 short stories writte...  \n","69997   Wuthering Heights is a novel by Emily Brontë ...  \n","69998   L'Indépendant is a newspaper published in Lux...  \n","69999   The Prophecy is the fifth novel by New York T...  \n","\n","[70000 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"vOSjl1Q2MwpT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["dataset = []\n","for row in df.iterrows():\n","    ix, data = row\n","    dataset.append((data[2], data[0]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TtZQahWOMwpZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from collections import Counter"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cvubzj1MfRrV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"c5dd97f7-2b27-4851-b19d-859ffa196c93","executionInfo":{"status":"ok","timestamp":1531066639032,"user_tz":-120,"elapsed":105054,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["tokens = []\n","tokenized = []\n","for x, y in dataset:\n","    x_t = nlp(x)\n","    toks = [t.text for t in x_t]\n","    tokens+= toks\n","    tokenized.append((toks, y))\n","    \n","vocab_counter = Counter(tokens)\n","vocab = set(tokens)\n","print('Num de features a usar: ', len(vocab))  \n","print(len(tokenized))    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Num de features a usar:  203596\n","70000\n"],"name":"stdout"}]},{"metadata":{"id":"6jFdRbQGeP7x","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"ebefb720-eaba-405d-dd5e-60063bdc97e2","executionInfo":{"status":"ok","timestamp":1531066645394,"user_tz":-120,"elapsed":475,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["maxlen = max([len(x) for x, _ in tokenized])\n","maxlen"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["547"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"y4CLZQsrgLx9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"02b49069-4236-46f0-9380-959d26d9e155","executionInfo":{"status":"ok","timestamp":1531066647158,"user_tz":-120,"elapsed":437,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["lens = [len(x) for x, _ in tokenized]\n","median = np.median(np.array(lens))\n","mean = np.mean(np.array(lens))\n","maxlen = int(median)*2\n","print(median, mean, maxlen)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["53.0 53.20654285714286 106\n"],"name":"stdout"}]},{"metadata":{"id":"dwbZZa2ZeBzD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"c1352a82-3ca8-435c-cfbf-49d8deded0cd","executionInfo":{"status":"ok","timestamp":1531066649076,"user_tz":-120,"elapsed":652,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["tokenized_filtered = [(x, y) for x, y in tokenized if len(x) < maxlen]\n","len(tokenized_filtered)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["69782"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"id":"9Xw3L89cMwpt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Construir el vocabulario como siempre\n","w2id = {k:i for i, k in enumerate(vocab)}\n","w2id['<UNK>'] = len(w2id)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DOrF5K3yaRNg","colab_type":"text"},"cell_type":"markdown","source":["### Padding + Input preparation"]},{"metadata":{"id":"KRqMi2Bzcx0O","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["l2id = {label:i for i, label in enumerate(labels)}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JLMKFHy6Mwpv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Preparar Input. Padding. Conversión a input\n","# maxlen = min(maxlen, 50)\n","input_ready = []\n","for x, y in tokenized_filtered:\n","    sentence = np.zeros((maxlen))\n","    label = np.zeros((len(labels)))\n","    label[int(y)-1] = 1\n","    for i, t in enumerate(x):\n","        sentence[i] = w2id[t] if t in vocab_counter and vocab_counter[t]>=5 else w2id['<UNK>']\n","    input_ready.append((sentence,label))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YrGax_kKMwpy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"5cb6f7e5-97f8-4b39-a2a4-081b993704ad","executionInfo":{"status":"ok","timestamp":1531065725404,"user_tz":-120,"elapsed":400,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["input_ready[0][0].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(106,)"]},"metadata":{"tags":[]},"execution_count":21}]},{"metadata":{"id":"PB6aYD37Mwp2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":181},"outputId":"010a70e8-479b-46b8-bd8f-246fcb432302","executionInfo":{"status":"ok","timestamp":1531065727320,"user_tz":-120,"elapsed":1753,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["splits = split_train_val_test(input_ready)\n","print(splits['train'][0].shape)\n","print(splits['train'][1].shape)\n","splits['train'][1]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(55825, 106)\n","(55825, 14)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 1.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":22}]},{"metadata":{"id":"G_IbXWEZakHd","colab_type":"text"},"cell_type":"markdown","source":["# Simple Models\n","\n","## No Embeddings\n","\n","### As a sequence of tokens"]},{"metadata":{"id":"C78KvHdXMwp5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"O-yv0mY2atRr","colab_type":"text"},"cell_type":"markdown","source":["### Simple Model Fit"]},{"metadata":{"id":"UwDJFBk2Mwp9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"UWlivSoeawDV","colab_type":"text"},"cell_type":"markdown","source":["### Simple Model Test"]},{"metadata":{"id":"TMPGd2HpMwqA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"WfjDXdLCMwqF","colab_type":"text"},"cell_type":"markdown","source":["### Ahora con unigrams"]},{"metadata":{"id":"ln-eaqdLMwqF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"UQER8YYFMwqK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"qU8CKLAXMwqP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nu-HolZEMwqT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"nVPgCPRLMwqZ","colab_type":"text"},"cell_type":"markdown","source":["## Ahora con embeddings"]},{"metadata":{"id":"O-h9q9t_Mwqa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SlO1PZZZMwqh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"jYAsqzbsMwqe","colab_type":"text"},"cell_type":"markdown","source":["Que ha pasado conn los shapes? Son correctos? Es correcta la shape del output?\n","\n","# Deep Averaging Networks\n","\n","Este paper del 2015 ([DAN](http://www.cs.umd.edu/~miyyer/pubs/2015_acl_dan.pdf)), presentan un modelo super simple, que da muy buenos resultados en text classification. \n","\n","Esta es la arquitectura.\n","\n","![](https://i.imgur.com/Ry4isGW.jpg =500x)\n","\n","Como veis es muy muy simple, cogemos emeddings, hacemos un average de ellos, y lo pasamos por un par de capas. Vamos a implementarlo y ver que pasa.\n","\n","Esta estructura tan simple, actualmente se usa dentro de sistemas complicadíssimos, como Alexa."]},{"metadata":{"id":"P1YnLlHuMwqe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from keras.layers import Input, Average, average, Lambda\n","from keras.models import Model\n","\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X_GgFvBT8eJl","colab_type":"text"},"cell_type":"markdown","source":["#### Creación de Lambda Custom"]},{"metadata":{"id":"ABKT9qE9Mwqk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"RNlNk6NjMwqm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"WYkdh-Ly8l33","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"rIxK-dYjMwqq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0R52rvq9Mwqu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"klCh529JMwqw","colab_type":"text"},"cell_type":"markdown","source":["# Convolutional Neural Networks para Texto\n","\n","## Refresco de la arquitectura típica.\n","\n","![](https://adeshpande3.github.io/assets/Cover.png)\n","\n","Tenemos un input, normalmente en imágenes podemos pasarlo en (3, HEIGHT, WIDTH), por ejemplo, esto lo pasamos por una capa convolucional, que no es más que multiplicar trozos de la imagen por unos filtros, que no son más que una matriz de pesos que queremos aprender, hacer el pooling, que es quedarn-nos con las features más importantes, y así ir repitiendo. El resultado de estas convoluciones+poolings, es lo que anteriormente era *feature engineering*. El vector de feature resultantes se pasa por unas fully connected (Dense) layers, y al final una predicción.\n","\n","[Stanford CNN](http://cs231n.github.io/convolutional-networks/) Aquí tenéis un link, que seguro que ya os han pasado, que explica perfectamente el funcionamiento de las redes convolucionales.\n","\n","## Para texto\n","\n","La idea de redes convolucionales para texto fue introducida en 2014 es este [paper](http://www.aclweb.org/anthology/D14-1181) por Yoon Kim. Es un magnífico paper, que de la nada, consiguió SoTA resultados, con una estructura, algo más compleja que la de los DANs, peró dejo unas ideas muy interesantes. Además el paper esta muy bien porque vislumbra ya que pasa cuando usamos pre-trained word embeddings versus si usamos aleatorios al iniciar la red y alguna otra comparación. Bastante recomendable la lectura, aunque sea por encima.\n","\n","Os dejo aquí la arquitectura que implementaremos.\n","\n","![CNN](https://datawarrior.files.wordpress.com/2016/10/cnn.png?w=640 \"CNN Simple\")\n","\n","Fijaros en una cosa muy interesante de la imagen. Os recuerda a algo los filtros? n-grams? Pues si. Las redes convolucionales para texto, \"aprenden\" n-grams. Hemos vuelto a la segunda clase. El paper además introduce un concepto, o un rehuso del concepto que visteis en deep learning, en visión por ordenador, que es el de channel. Aquí en lugar de RGB, podríamos usar GloVe, SkipGrams, y FastText vectors. De todas formas veremos que los modelos con poca complejidad ya dan bastantes buenos resultados.\n","\n"]},{"metadata":{"id":"Go0oKC_4Mwq0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xpx6KEuzMwq3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"JU-DfuimMwrB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"82RQL8UtMwrH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"EGwGgr4sMwrO","colab_type":"text"},"cell_type":"markdown","source":["# Recurrent Neural Network para texto\n","\n","Hasta ahora, hemos seguido trabajando basandonos en una premisa, que no es del todo cierta, que es que cada variable de nuestro input es independiente. Las capas nos sirven para buscar formas de combinarlas pero en el momento del input, cada *x* es independiente. Y realmente, como ya hemos comentado anteriormente, y como visteis cuando hicimos Language Modeling, cada palabra realmente depende del pasado. De hecho, cada palabra depende del pasado y del futuro, pero de momento, quedemonos en que cada feature depende del pasado, no solo del pasado más immediato, sino de todo el pasado.\n","\n","Como modelamos esto? De bien seguro que en Deep Learning ya habeis visto la arquitectura, lo modelamos con Recurrent Neural Networks. De hecho, para deep, las redes más profundas son las recurrentes. Pero en lugar de ser profundas en \"capas que nosotros podamos stackear\" son muy profundas en el eje del tiempo.\n","\n","No implementaremos estas redes desde 0, lo hicisteis en Deep Learning? En cualquier caso, aquí dejo un [tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) magnífico.\n","\n","![RNN](http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg \"RNN Simple\")\n","\n","Equaciones de una RNN\n","\n","![](http://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D++s_t+%26%3D+%5Ctanh%28Ux_t+%2B+Ws_%7Bt-1%7D%29+%5C%5C++%5Chat%7By%7D_t+%26%3D+%5Cmathrm%7Bsoftmax%7D%28Vs_t%29++%5Cend%7Baligned%7D++&bg=ffffff&fg=000&s=0)\n","\n","Haremos un pequeño ejercico para que entendáis lo que es cada cosa.\n","\n","*   U: Matriz input-hidden\n","*   W:  Matriz hidden-hidden\n","*   V: Matriz hidden-output\n","*   t: tiempo (time-step, input en el momento t...)\n","*   st: hidden state\n","*   xt: input en el step t. 1-hot vector\n","\n","Tenemos un vocabulario de 50, por decir algo, y nuestro problema es un Language Modeling, con lo que el espacio de outputs será 50 igual. Si fuera un problema de clasificación pues los labels que tengamos.\n"]},{"metadata":{"id":"bqlg218QXeAY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def softmax(x):\n","    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n","    e_x = np.exp(x - np.max(x))\n","    return e_x / e_x.sum(axis=0) # only difference\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EUPvun64SMOq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"RowQbEJQU3lp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vp9eDMaaUtPo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"k_kHGXpIVlNm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0oWQ95y1XQLx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"KFx7a2DPXm-W","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"39F4uMJZYb3d","colab_type":"text"},"cell_type":"markdown","source":["De hecho lo que hemos hecho aquí arriba practicamente sería el forward pass implementado en numpy.\n","\n","Vamos a ver la implementación en Keras, y a entrenar una para un problema de clasificación"]},{"metadata":{"id":"azfb_Qq8MwrO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from keras.layers import LSTM, SimpleRNN"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XCoJ9aefMwrR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["rnn_type = SimpleRNN(100)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"N7_4M4qkMwrS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"gzBg8Pn8MwrY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"NVJ26cveMwrc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"TEuCVPl-Mwrh","colab_type":"text"},"cell_type":"markdown","source":["# LSTM\n","\n","Las LSTMs son quizás de mis preferidas estructuras preferidas, y quizás hasta la fecha uno de los componentes más relevantes en Deep Learning.\n","\n","Se que habéis visto ya redes recurrentes, y que os han explicado algo de las LSTMs. Aquí nos pararemos un segundo, en explicaros de dónde vienen las LSTMs, y porque no nos es suficiente con las recurrents. Imagino que este blog [post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) ya os lo han recomendado, de hecho si la imagen os suena, la he sacado de ahi.\n","\n","![LSTM](http://www.stratio.com/wp-content/uploads/2017/10/6-1.jpg =600x)\n","\n","### Que pasa con las RNNs?\n","\n","Si miráis el dibujo de arriba, el de las Vanilla RNNs, y os acordáis que he dicho que son las redes más profundas, veréis que no os he mentido. Las redes recurrentes de tan profundas que son, tienen ciertos problemas, que ahora són muy obvios, no tanto hace un tiempo. El principal problema se llama Vanishing Gradient, descubierto por Sepp Hochreiter en 1991 (hace casi 30 años). \n","\n","#### Vanishing Gradient\n","\n","Si os fijais, las matricecs W, U, V, son compartidas en el tiempo, pero W y U, además de alguna forma u otra se ven en cada forward pass. Que dices?\n","\n","![](https://i.imgur.com/U4PU3ao.jpg =400x)\n","\n","Cuando quereis calcular algo en el step t=5, teneis que tener calculado lo que pasaba en el t=4, pero para el t=4 necesitáis el t=3 y así hasta el 0.\n","\n","Esto esta muy bonito, porque conseguimos que cualquier punto de la secuencia pueda afectar al output en t=actual, pero tiene el problema que W es compartida en todos los timesteps (U igual). Al ser compartidos los valores de W, los valores que modifican W, es decir los gradientes, tambien hay que calcularlos a cada momento. Es decir, que cuando calculemos estos valores en t=5, los tendremos que pasar a 4, 3... y hasta 0.\n","Esto provoca, que si estamos trabajando con valores muy peques, al final, estos valores tendiran a 0, hasta convertir-se en 0s o NaNs, o si por lo que sea, estos valores son muy grandes, los gradientes se dispararan, y subiran por las nubes. La consecuencia de todo esto, es que estas redes, aunque potencialmente pueden aprender largas dependencias, la verdad es que no son capaces de ello.\n","\n","![](https://i.imgur.com/YDiQB8d.png)\n","\n","Vanilla RNN vs LSTM\n","\n","![](https://i.imgur.com/Eb5aATV.png)\n","\n","Ver que pasa con W\n","\n","### Vale, pero cuentame las LSTMs\n","\n","En 1997, hace 21 años, en un laboratorio europeo, Sepp Hochreiter y Juergen Schmidhuber sacan estas LSTMs, que ellos describen como el trabajo \"obvio\" que deriva del descubrimiento del \"Vanishing Gradient\". Y si, dijo obvio. Bien, las LSTMs, basicamente son 4 capas, dentro de una \"super-capa\". \n","\n","Estas LSTMs, debido a su estructura interna, son capaces de guardar información entre dependencias más largas. No entraremos en el detalle de como lo hacen, pero para que veias como funciona el forward pass, implementaremos las ecuaciones de una celda LSTM. [Blog post](https://weberna.github.io/blog/2017/11/15/LSTM-Vanishing-Gradients.html) explicando el porque las LSTMs no tienen el mismo problema que las vanilla RNN.\n","\n","![](https://i.imgur.com/h4tZrh0.jpg)\n","\n","Como podéis ver, una celda LSTM es bastante más complicada que la de una recurrente normal, y esto tiene un coste computacional associado, a más matrices, más cuesta entrenar, y más tiempo (por pequeno que sea), cuesta predecir. \n","\n","Las celdas LSTMs tiene 3 pasos, que queremos olvidar, que queremos aprender, y que queremos mostrar, en este orden. Es decir, nuestras matrices gestionan, que olbidamos del paso anterior, que creemos que es útil del input actual, y que queremos mostrar en el input actual. Vamos a ver sus ecuaciones, y luego a usar una en una red con keras.\n","\n","\n"]},{"metadata":{"id":"oFpaXk42gJr-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# introducir ecuaciones como en Vanilla RNN\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1tDjJ4kx5nty","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# cosas\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eXPzCSre_d4G","colab_type":"text"},"cell_type":"markdown","source":["![](https://i.imgur.com/jbAEXGd.jpg =500x)\n","\n","El bias del output no es de t sino de o."]},{"metadata":{"id":"VHxoA3ja9ErD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"eHpKu0eSCnjT","colab_type":"text"},"cell_type":"markdown","source":["![](https://i.imgur.com/jbAEXGd.jpg =500x)\n","\n","Es b_o aquí.\n"]},{"metadata":{"id":"O9lOKwKNAFz1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"RPJf-TovAGV5","colab_type":"text"},"cell_type":"markdown","source":["### Implementación en Keras"]},{"metadata":{"id":"jURsfh04zs9D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from keras.layers import CuDNNLSTM"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FWocXHOgMwrh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["rnn_type = CuDNNLSTM(100)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KHj0_5uHMwrj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"z6E97M_RMwrm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"hEnFjKPBMwrn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"o9Dgu47g2QP4","colab_type":"text"},"cell_type":"markdown","source":["## Ampliaciones de la LSTM\n","\n","Para finalizar, con las las redes recurrentes, podéis hacer exactamente igual que con las convolucionales. Podeis stackear capas. Como quedaría entonces?\n","\n","![](https://discuss.pytorch.org/uploads/default/optimized/2X/f/fb98eb0d16b722e019db59f97825aa529cb6bc08_1_685x499.png =500x)\n","\n","Es decir, en la primera capa, el input seria exactamente igual, pero el input de las LSTMs en las siguientes capas sería el output de la capa anterior, exactamente igual que cualquier otra arquitectura.\n","\n","Al principio he puesto la imagen sobre BiLSTM. Una BiLSTM es una arquitectura algo especial, no es una LSTM con 2 capas...unicamente.\n","\n","Os acordais que a veces, cuando hablo de que cuando hablamos de cómo hablamos  o escribimos, que en realidad no estamos construyendo palabra a palabra, sino que nuestro cerebro tiene una idea de principio a fin, y en verdad vamos rellenando, de atrás hacia adelante, y vice-versa. Pues las BiLSTMs, sse llaman así, porque son Bidireccionales. Tienen 2 capas, pero el input es la propia x, no como cuando stackeamos capas.\n","\n","![](https://cdn-images-1.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)\n","\n","Si os fijais en el sentido de las flechas, veréis que unas van hacia un lado, y las otras hacia el otro, es decir, de principio a fin, y de fin a principio. Esta arquitectura, actualmente es el standard para muchísimas tareas! \n","\n","Y, en keras, es facilísimo de implementar."]},{"metadata":{"id":"3Zj7v9iH5I45","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"rCwq6bJa5PfC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"BrUxshl0Mwrs","colab_type":"text"},"cell_type":"markdown","source":["# Results Visualization"]},{"metadata":{"id":"6aEJrEogMwrs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"hbaFl6xeMwr6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"8c2e2a39-1f69-47de-ee71-c8be671d601d"},"cell_type":"code","source":["plt.rcParams['figure.figsize'] = [15, 7.5]\n","fig, ax = plt.subplots()\n","ind = np.arange(1, 7)\n","\n","values = [x for x, _ in scores]\n","labels = [y for _, y in scores]\n","\n","plt.bar(ind, values)\n","ax.set_xticks(ind)\n","ax.set_xticklabels(labels)\n","ax.set_ylim([0.85, 1])\n","ax.set_ylabel('Accuracy')\n","ax.set_title('Architecture Type')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.text.Text at 0x7fb8bab86160>"]},"metadata":{"tags":[]},"execution_count":304},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA3wAAAHGCAYAAAAv2okYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XvcpWVdL/7PwHhCBx1llEiT2uFX7GDbQ+JPUREqfwb5\ns+jgIWHrzmyj2UGN3OShg+Y2NjvCCt2ZWe00FdFMk0RBa/JE5s6yr3nASiiHQMTwBDy/P9a9cPk4\nh4eZWTwz17zfr9e85j7f37XW9TzP+qzruu+1YWVlJQAAAIznoPUuAAAAgOUQ+AAAAAYl8AEAAAxK\n4AMAABiUwAcAADAogQ8AAGBQG9e7AABYVFV/meR23X3v3dx/JcnduvtfVi1/dJKTuvuJVVVJ7tLd\n79zNc+zR/rs49h2SvHuaPSTJ4Uk+Ps2/rbufurfPCcC4BD4A9hlV9a1Jrk5yZVU9sLv/am8du7tf\nn+T10+yjM/sbuLuBbU/336Hu/kySeyZJVT0syf/u7nvu7fMAcGAQ+ADYl5yS5DVJvpDkCUn+Kkmq\n6sgkW5O8Osl9uvuhVfWIJGcmuUWSjyR5QndfOR3nkVX140m+LsmZ3X1mVZ2a5PFJfj3Jzyf5UlVt\n7u6fraonJ/mZJLeezvnE7v58VR2W5HeTfEuSzyV5RpJbLe6f5G+TPL67T5hqPXU+X1WvSHJlkhOS\n/FKSNyZ5cZJHJLllkpd29wtuyhNUVe9L8qLufu00f2KSX07yU0nOTvLnSU6cjv+Y7n53Vd1qT88L\nwP7JNXwA7BOq6uAk35/kdUnekFlou+XCJocl+Zsp7N02yR8m+eHuvkeSj2YWqOaO7O77Jvm+JL9c\nVbeYr+juP8msp+/Xp7B37LTvw7v7yMx6GOfH+tUkf9/d35RZGP2jJBcs7r+Gh3Z8ku/s7tckeVaS\neyX5tsxC5MlTYLsp/ijJYxfmH53kVdP0vZK8t7srya8k+a1p+d44LwD7IYEPgH3F9yR5X3d/truv\nTXJRkpMW1t8iXxmS+aAk/9zdH5rmn5Xkpxe2/YPp/w9k1mt32E7Oe1KSV3f3ZdP8b2cWPJPkkZkF\nrHT3BzILkl+8iY/rwu7+wsK5frO7v9jd/5HklQvnWqtXJ3lEVd1+CsknJfnjad3nFqZfl+Q7quqQ\nvXReAPZDhnQCsK84NbNevc9M8xuTbM4suCTJ9d392Wn6sCTz7dLdX1p1rM9Oy6+f3V8lB+/kvHdI\n8uiq+u5p/qDMhj1u7zzX3ITHM3flwvQdkpxVVfPhlLdK8t6bcrDu/lRVvTezwPaxJJd298er6huS\nXNXdK9Om87rvsDfOC8D+SeADYN1N18I9LMkd5+GtqjYm+Zeq2rKdXa7IQq/d1It1x9V35lyjy5L8\nXnc/YyfnuXQ6z5FJPrVqm+vz1YFy8y7O9Wvd/abdqHPRHyX5wcyGsr56YfmdtlPHlXvxvADsZwzp\nBGBf8CNJ3r7YU9fd1yV5a5LHbGf7v0hyeFXdf5r/hSTPuQnn+3JmvV7J7EYq3z8PllX1qKr6uYV1\np07L75XkrzP7sHRx/8tnq+vWU/A8eSfnfUOS/1pVB1fVhqo6Y7r5zE31miQPns71xwvLD6mq/2+a\nPjnJ+6fhpHvrvADsZwQ+APYFpyQ5fzvLX5/Z3Tq/ynSN3w8k+YOq+kiSb0/y7Jtwvj9J8pSqem13\n/3WSFyS5qKo+nNndOt8wbfdzSe5aVZdm1pP22O7+/OL+Sd6R5D2Z3Sn0LQv7bs9Lknwyyd8l+Yck\nR2cWXm+S6W6k70zyie7+54VVlyZ58PScPDvJf9ub5wVg/7NhZWVl11sBAPuUqvrNJB/q7t+c5h+W\n2Xf2ffO6FgbAPkUPHwDsZ6rqqMzuIPqH610LAPu2pd60paq+NbOhLWd19zmr1p2Q2RCa65O8ubt/\naVp+VpJjkqwkeXp3v2+ZNQLA/qSqfjHJjyZ5andfvd71ALBvW9qQzulLcd+U5B+T/N/tBL6/z+w7\nlz6V5OIkP55kS5JndveJVXV0kpd39wOXUiAAAMDgljmk84uZDTe5bPWKqvqmJFd29z939w1J3pzk\n+Onf+UnS3R9OsrmqDl1ijQAAAMNaWuDr7uumO5ltz+FJti3MfzrJ121n+bZpGQAAADfRvvLF6xtu\n4vIbXXfd9SsbNx68q80AAABGtcPctF6B77J8dc/d10/LvrRq+RGZfaHtDl111bV7vTi+1pYtm7Jt\n2zXrXQb7CO2BOW2BOW2BOW2BOW3h5rNly6YdrluXr2Xo7kuTHFpVR1bVxiQnJrlg+ndyklTVfZJc\n1t1aCQAAwG5YWg9fVd03yZlJjkzy5ao6Ockbk3yiu1+f5CeS/NG0+au7+yNJPlJVl1TV1iQ3JDlt\nWfUBAACMbmmBr7svSfKwnax/Z5Kv+cqF7j59WTUBAAAcSNZlSCcAAADLJ/ABAAAMSuADAAAYlMAH\nAAAwKIEPAABgUAIfAADAoAQ+AACAQQl8AAAAgxL4AAAABiXwAQAADErgAwAAGJTABwAAMCiBDwAA\nYFACHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK4AMAABiUwAcAADAogQ8AAGBQAh8AAMCg\nNq53AQBwoHnir759vUtgF15++sPXuwSAvUIPHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK\n4AMAABiUr2UAAIB9gK9s2fftj1/ZoocPAABgUAIfAADAoAQ+AACAQQl8AAAAg3LTFoCbiYvx9337\n48X4ALAzevgAAAAGJfABAAAMSuADAAAYlMAHAAAwKDdtgSVzo459nxt1AACj0sMHAAAwKIEPAABg\nUAIfAADAoAQ+AACAQQl8AAAAgxL4AAAABrXUr2WoqrOSHJNkJcnTu/t9C+seleSMJF9M8qruPqeq\nbpfklUk2J7lVkud391uXWSMAAMColtbDV1UPTXJUdz8wyZOSnL2w7qAk5yR5ZJKHJDmpqu6a5NQk\n3d3HJTk5ya8vqz4AAIDRLXNI5/FJzk+S7v5wks1Vdei07rAkn+nubd19Q5ILk5yQ5Iokd5q22TzN\nAwAAsBuWOaTz8CSXLMxvm5Z9dpreVFVHJbk0yXFJLuruF1XVqVX10cwC3/fu6iSbNx+SjRsP3tu1\nsx1btmxa7xJgKbRt5rQF5rSFPeP5Y1T7Y9te6jV8q2yYT3T3SlWdkuTlSa5O8okkG6rq8Un+qbsf\nUVX3TvI7Se63s4NeddW1SyyZuS1bNmXbtmvWuwxYCm2bOW2BOW1h93nPwMj21ba9syC6zCGdl2XW\nozd3RJLL5zPdfXF3H9vdJ2YW+i5N8qAkb53WfzDJEVWl+w4AAGA3LDPwXZDZjVdSVfdJcll33xiJ\nq+otVXXnqrptkpOSvC3JR5M8YFp/9ySf6+7rl1gjAADAsJYW+Lp7a5JLqmprZnfoPG26Pu/R0yYv\nyywU/kWSF3b3FUnOTXJkVV2c5P8kecqy6gMAABjdUq/h6+7TVy364MK685Kct2r7zyX5oWXWBAAA\ncKBY5pBOAAAA1pHABwAAMCiBDwAAYFACHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK4AMA\nABiUwAcAADAogQ8AAGBQAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAGJfABAAAMSuADAAAYlMAHAAAw\nKIEPAABgUAIfAADAoAQ+AACAQQl8AAAAgxL4AAAABiXwAQAADErgAwAAGJTABwAAMCiBDwAAYFAC\nHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK4AMAABiUwAcAADAogQ8AAGBQAh8AAMCgBD4A\nAIBBCXwAAACDEvgAAAAGJfABAAAMSuADAAAYlMAHAAAwKIEPAABgUAIfAADAoAQ+AACAQW1c5sGr\n6qwkxyRZSfL07n7fwrpHJTkjyReTvKq7z5mWPy7Js5Jcl+Q53f2ny6wRAABgVEvr4auqhyY5qrsf\nmORJSc5eWHdQknOSPDLJQ5KcVFV3rao7JXlukgcnOTHJo5ZVHwAAwOiW2cN3fJLzk6S7P1xVm6vq\n0O7+bJLDknymu7clSVVdmOSEJJ9P8rbuvibJNUmevMT6AAAAhrbMwHd4kksW5rdNyz47TW+qqqOS\nXJrkuCQXTdsdUlVvTLI5yfO6+8Il1ggAADCspV7Dt8qG+UR3r1TVKUlenuTqJJ9YWH+nJI9Ocvck\n76iqu3f3yo4OunnzIdm48eDlVc2NtmzZtN4lwFJo28xpC8xpC3vG88eo9se2vczAd1lmPXpzRyS5\nfD7T3RcnOTZJquqFmfX03SbJ1u6+LsnHquqaJFuSfHpHJ7nqqmv3euF8rS1bNmXbtmvWuwxYCm2b\nOW2BOW1h93nPwMj21ba9syC6zMB3QZLnJzm3qu6T5LLp2rwkSVW9JckpSf4jyUlJzkxyqySvqKoX\nZTak83ZJrlhijQAAAMNaWuDr7q1VdUlVbU1yQ5LTqurUJFd39+uTvCyzULiS5IXdfUWSVNVrk7x7\nOszTuvuGZdUIAAAwsqVew9fdp69a9MGFdeclOW87+5yb5Nxl1gUAAHAgWNr38AEAALC+BD4AAIBB\nCXwAAACDEvgAAAAGJfABAAAMSuADAAAYlMAHAAAwKIEPAABgUAIfAADAoAQ+AACAQQl8AAAAgxL4\nAAAABiXwAQAADErgAwAAGJTABwAAMCiBDwAAYFACHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEA\nAAxK4AMAABiUwAcAADAogQ8AAGBQAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAGJfABAAAMSuADAAAY\nlMAHAAAwKIEPAABgUAIfAADAoAQ+AACAQQl8AAAAgxL4AAAABiXwAQAADErgAwAAGJTABwAAMCiB\nDwAAYFACHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxq4zIPXlVnJTkmyUqSp3f3+xbWPSrJ\nGUm+mORV3X3OwrrbJPlQkl/q7lcss0YAAIBRLa2Hr6oemuSo7n5gkiclOXth3UFJzknyyCQPSXJS\nVd11Yfczkly5rNoAAAAOBMsc0nl8kvOTpLs/nGRzVR06rTssyWe6e1t335DkwiQnJElV3TPJvZL8\n6RJrAwAAGN4yA9/hSbYtzG+bls2nN1XVUVV1iyTHJbnLtO7MJD+zxLoAAAAOCEu9hm+VDfOJ7l6p\nqlOSvDzJ1Uk+kWRDVT0hyV919yeqak0H3bz5kGzcePAy6mWVLVs2rXcJsBTaNnPaAnPawp7x/DGq\n/bFtLzPwXZav9OglyRFJLp/PdPfFSY5Nkqp6YZJLkzw6yTdV1YlJ7prki1X1L939th2d5Kqrrt37\nlfM1tmzZlG3brlnvMmAptG3mtAXmtIXd5z0DI9tX2/bOgugyA98FSZ6f5Nyquk+Sy7r7xmeoqt6S\n5JQk/5HkpCRndverFtY/L8mlOwt7AAAA7NjSAl93b62qS6pqa5IbkpxWVacmubq7X5/kZZmFwpUk\nL+zuK5ZVCwAAwIFoqdfwdffpqxZ9cGHdeUnO28m+z1tSWQAAAAeEZd6lEwAAgHUk8AEAAAxK4AMA\nABiUwAcAADAogQ8AAGBQAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAGJfABAAAMSuADAAAYlMAHAAAw\nKIEPAABgUAIfAADAoAQ+AACAQe0y8FXVPW+OQgAAANi7Nq5hm9dV1VVJfifJq7v72iXXBAAAwF6w\nyx6+7v6WJE9J8o1JLqqql1bV/ZdeGQAAAHtkTdfwdfeHuvs5SX4mydFJ3lhV76yqo5ZaHQAAALtt\nl0M6q+ruSU5N8pgkf5/kV5K8Ncn9k/xBkgcssT4AAAB201qu4bsos+v3Ht7dly0sf29VvXcpVQEA\nALDH1jKk895JPjIPe1X1lKq6XZJ099OWWRwAAAC7by2B73eTHL4wf9skv7+ccgAAANhb1hL47tjd\nZ89nuvvMJHdYXkkAAADsDWsJfLeqqqPnM1V13yS3XF5JAAAA7A1ruWnLTyd5Q1XdPsnBSbYl+dGl\nVgUAAMAeW8sXr7+nu++R5F5J7tHdR0cPHwAAwD5vLd/Dd2iSxyc5bJq/VZL/kuSI5ZYGAADAnljL\nNXyvTvLtmYW8TUlOTPITyywKAACAPbeWwHfr7n5Kkk929zOTHJfkh5ZbFgAAAHtqrXfpvG2Sg6rq\nTt19ZZL/tOS6AAAA2ENruUvnK5P8WJL/neTDVbUtyT8utSoAAAD22FoC37ndvZIkVXVhkjsn+Zul\nVgUAAMAeW0vge3tm1+2luz+V5FNLrQgAAIC9Yi2B72+q6heTbE3ypfnC7n770qoCAABgj60l8H3H\n9P+xC8tWMuv5AwAAYB+1y8DX3cfdHIUAAACwd+0y8FXVuzLr0fsq3f2QpVQEAADAXrGWIZ1nLEzf\nMsnDk3xuOeUAAACwt6xlSOfFqxb9eVW9eUn1AAAAsJesZUjnN61adLcktZxyAAAA2FvWMqTzwoXp\nlSSfTfK8pVQDAADAXrOWIZ3fWFUHdfcNSVJVt+juLy+/NAAAAPbEQbvaoKp+IMkbFha9q6pOXl5J\nAAAA7A27DHxJfjbJ4xfmvyfJM5ZTDgAAAHvLWgLfhu6+ej4zTV+/vJIAAADYG9Zy05b3V9Wrk1yU\nWUB8RJJL1nLwqjoryTGZ3ezl6d39voV1j8rsO/6+mORV3X3OtPx/JDl2qu2F3X3emh8NAAAAN1pL\n4PvJJI9L8oDMgtsfJHnNrnaqqocmOaq7H1hVRyd5eZIHTusOSnJOkvsk+fckb6mq85McleRbp33u\nlOQDSQQ+AACA3bCWIZ2HJPlSdz+tu38yyeZp2a4cn+T8JOnuDyfZXFWHTusOS/KZ7t423f3zwiQn\nJHlnkh+ctvlMkttW1cFrfjQAAADcaC09fK9McvHC/G2T/H6SR+9iv8Pz1UM/t03LPjtNb6qqo5Jc\nmuS4JBd19/VJ/mPa/klJ3jwtAwAA4CZaS+C7Y3efPZ/p7jOr6sTdONeGhWOsVNUpmQ3zvDrJJxbX\nT9f3PSnJd+/qoJs3H5KNG3UC3hy2bNm03iXAUmjbzGkLzGkLe8bzx6j2x7a9lsB3q6o6ehqWmaq6\nX5JbrmG/yzLr0Zs7Isnl85nuvjizm7Okql6YWU9fqup7kvz3JI9YvDvojlx11bVrKIU9tWXLpmzb\nds16lwFLoW0zpy0wpy3sPu8ZGNm+2rZ3FkTXEvh+Oskbqur2mV3zd0WSH13DfhckeX6Sc6vqPkku\n6+4bn6GqekuSUzIbwnlSkjOnc7w4yQndfeUazgEAAMAO7DLwdfd7ktyjqu6W2bV2pyR5Y2Y9djvb\nb2tVXVJVW5PckOS0qjo1ydXd/fokL8ssFK5k9vULV1TVkzO7ocsfV9X8UE/o7n/arUcHAABwANtl\n4KuqY5L8lyQ/nFkP35OTvG4tB+/u01ct+uDCuvOy6isXuvulSV66lmMDAACwczsMfFX1rCSnZnZX\nzlcmuV+S13T3q26e0gAAANgTO+vh+5Ukf5fktO5+R5JU1crNUhUAAAB7bGeB726ZXa/329OXn78i\na7s7JwAAAPuAg3a0orv/tbtf1N2V5IlJvjnJ3avqT6rqkTdbhQAAAOyWHQa+Rd39zu4+NbM7c74p\nyXOWWRQAAAB7bi3fw3ej6Xv0zp3+AQAAsA9bUw8fAAAA+x+BDwAAYFACHwAAwKAEPgAAgEEJfAAA\nAIMS+AAAAAYl8AEAAAxK4AMAABiUwAcAADAogQ8AAGBQAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAG\nJfABAAAMSuADAAAYlMAHAAAwKIEPAABgUAIfAADAoAQ+AACAQQl8AAAAgxL4AAAABiXwAQAADErg\nAwAAGJTABwAAMCiBDwAAYFACHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK4AMAABiUwAcA\nADAogQ8AAGBQAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAGJfABAAAMauMyD15VZyU5JslKkqd39/sW\n1j0qyRlJvpjkVd19zq72AQAAYO2W1sNXVQ9NclR3PzDJk5KcvbDuoCTnJHlkkockOamq7rqzfQAA\nALhpljmk8/gk5ydJd384yeaqOnRad1iSz3T3tu6+IcmFSU7YxT4AAADcBMsMfIcn2bYwv21aNp/e\nVFVHVdUtkhyX5C672AcAAICbYKnX8K2yYT7R3StVdUqSlye5OsknFtdvb58d2bz5kGzcePBeK5Id\n27Jl03qXAEuhbTOnLTCnLewZzx+j2h/b9jID32X56t65I5JcPp/p7ouTHJskVfXCJJcmufXO9tme\nq666du9Uy05t2bIp27Zds95lwFJo28xpC8xpC7vPewZGtq+27Z0F0WUO6bwgyclJUlX3SXJZd9/4\nDFXVW6rqzlV12yQnJXnbrvYBAABg7ZbWw9fdW6vqkqramuSGJKdV1alJru7u1yd5WWYBbyXJC7v7\niiRXrN5nWfUBAACMbqnX8HX36asWfXBh3XlJzlvDPgAAAOyGZQ7pBAAAYB0JfAAAAIMS+AAAAAYl\n8AEAAAxK4AMAABiUwAcAADAogQ8AAGBQAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAGJfABAAAMSuAD\nAAAYlMAHAAAwKIEPAABgUAIfAADAoAQ+AACAQQl8AAAAgxL4AAAABiXwAQAADErgAwAAGJTABwAA\nMCiBDwAAYFACHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK4AMAABiUwAcAADAogQ8AAGBQ\nAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAGJfABAAAMSuADAAAYlMAHAAAwKIEPAABgUAIfAADAoAQ+\nAACAQQl8AAAAgxL4AAAABiXwAQAADErgAwAAGNTGZR68qs5KckySlSRP7+73Law7Lcnjk1yf5P3d\n/VNVdbskr0yyOcmtkjy/u9+6zBoBAABGtbQevqp6aJKjuvuBSZ6U5OyFdYcmeWaSY7v7wUnuVVXH\nJDk1SXf3cUlOTvLry6oPAABgdMsc0nl8kvOTpLs/nGTzFPSS5EvTv9tV1cYkhyS5MskVSe40bbN5\nmgcAAGA3LDPwHZ5k28L8tmlZuvsLSZ6f5ONJPpnkPd39ke5+VZJvqKqPJnlnkmcssT4AAIChLfUa\nvlU2zCemnr5nJ7lHks8meXtV3TvJtyX5p+5+xDT/O0nut7ODbt58SDZuPHh5VXOjLVs2rXcJsBTa\nNnPaAnPawp7x/DGq/bFtLzPwXZapR29yRJLLp+mjk3y8u69Ikqp6V5L7Jrl/krcmSXd/sKqOqKqD\nu/v6HZ3kqquuXUbtrLJly6Zs23bNepcBS6FtM6ctMKct7D7vGRjZvtq2dxZElzmk84LMbrySqrpP\nksu6e/4MXZrk6Kq6zTR/vyT/mOSjSR4w7XP3JJ/bWdgDAABgx5bWw9fdW6vqkqramuSGJKdV1alJ\nru7u11fVi5O8o6quS7K1u99VVR9I8vKquniq7SnLqg8AAGB0S72Gr7tPX7Xogwvrzk1y7qrtP5fk\nh5ZZEwAAwIFimUM6AQAAWEcCHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK4AMAABiUwAcA\nADAogQ8AAGBQAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAGJfABAAAMSuADAAAYlMAHAAAwKIEPAABg\nUAIfAADAoAQ+AACAQQl8AAAAgxL4AAAABiXwAQAADErgAwAAGJTABwAAMCiBDwAAYFACHwAAwKAE\nPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK4AMAABiUwAcAADCojetdwKie+KtvX+8S2IWXn/7w9S4B\nALxn2A94z8D+TA8fAADAoAQ+AACAQQl8AAAAgxL4AAAABiXwAQAADErgAwAAGJTABwAAMCiBDwAA\nYFACHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxq4zIPXlVnJTkmyUqSp3f3+xbWnZbk8Umu\nT/L+7v6pafnjkjwryXVJntPdf7rMGgEAAEa1tB6+qnpokqO6+4FJnpTk7IV1hyZ5ZpJju/vBSe5V\nVcdU1Z2SPDfJg5OcmORRy6oPAABgdMsc0nl8kvOTpLs/nGTzFPSS5EvTv9tV1cYkhyS5MskJSd7W\n3dd09+Xd/eQl1gcAADC0ZQa+w5NsW5jfNi1Ld38hyfOTfDzJJ5O8p7s/kuTIJIdU1Rur6l1VdfwS\n6wMAABjaUq/hW2XDfGLq6Xt2knsk+WySt1fVvadt7pTk0UnunuQdVXX37l7Z0UE3bz4kGzcevNTC\nGdOWLZvWuwT2EdoCc9oCc9oCi7QH5vbHtrDMwHdZph69yRFJLp+mj07y8e6+Ikmq6l1J7pvk35Js\n7e7rknysqq5JsiXJp3d0kquuunYJpXMg2LbtmvUugX2EtsCctsCctsAi7YG5fbUt7CyILnNI5wVJ\nTk6SqrpPksu6e/4MXZrk6Kq6zTR/vyT/OO3z8Ko6aLqBy+2SXLHEGgEAAIa1tB6+7t5aVZdU1dYk\nNyQ5rapOTXJ1d7++ql6c2ZDN6zLr1XtXklTVa5O8ezrM07r7hmXVCAAAMLKlXsPX3aevWvTBhXXn\nJjl3O/tsdzkAAAA3zTKHdAIAALCOBD4AAIBBCXwAAACDEvgAAAAGJfABAAAMSuADAAAYlMAHAAAw\nKIEPAABgUAIfAADAoAQ+AACAQQl8AAAAgxL4AAAABiXwAQAADErgAwAAGJTABwAAMCiBDwAAYFAC\nHwAAwKAEPgAAgEEJfAAAAIMS+AAAAAYl8AEAAAxK4AMAABjUhpWVlfWuAQAAgCXQwwcAADAogQ8A\nAGBQAh8AAMCgBD4AAIBBCXwAAACDEvgAAAAGtXG9C2D9VNWRSf42ySVJVpLcOskzu/sv1rj/4Ume\n390/vrQi2WNV9bAkT+3ukxeWPS/JFd19zna2Pz3Jxd39VzdbkaSqHpPklUm+rruvWO965qb285ok\nf7ew+Evd/d1r2Pd52UE728V+t0vyoe4+ctXyX0vyoST/muQbu/u3bspx2X1VdVSS/5VkS5KDk2xN\n8owkneRPNkDZAAAJhElEQVTM7v6Nabsjkzyvu0+tqlck2dTdP7BwnIu6+2E3b/XsLaveNyTJrab5\nn0jysWgLw5te19d29/0Wlh2a5HeS3CWz3w9XJDklyUlJnpTZ+8tvyVfazRMy+3v3D939lIXjPDXJ\nb3T3huU/kgOLwEfPf+FW1UOS/EKS71njjv+aRNgbTHf/6nrXcIB6bGZvmE5O8tvrXMtqFy9+YLDe\nuvvP1ruGA0lVHZzkdUme1t0XV9WGJGcneU6Sf0vyY1X1iu6+Zju7f3NVHdPd774ZS2a5ejGoTWHu\nsdEWDmQ/neS93f3iJKmqM5I8rrtfkuT3F0Liw+Y7VFWS/OequkV3f3la/H1JLr85Cz9QCHwsukuS\nT1XVvZO8JMmXk9yQ5AeTXJPkD5J8XWaf6D03yT9k+pSnqr4ryQuSXJ/kVd39v9ahfm6iqro4yceT\nfHuSD3T3f53+eL82ybum/2+T5M1Jfqy7v7Gq/nGa/3SSN+Vr28qhSX4/s/Dy/yT5ren4D0jyku5+\nSVX9XJLvn/b5k+5+wc3ziPdNVXXHJN+Z5IlJnpXkt6efw7O6++HTNs9NclWStyU5J7Ne+WuSnJrk\nDpn9fH5uWnf7JE/L7Ofx77r7yVV1+2z/9Tw2s5/dLyf552n5l9ZY90VJ3pHkuzJ7LX9vquf6JMdP\nm92/qi5IckSSZ3T3n1XV9yf52STXJXl/d//s9Anx6zL7JPgvFs7x+CQ/l+Rfknw+yYeq6tQk3zo9\n1t/L17bhb5+WfybJ+zPrlfqxrPodJjiu2Xdl9kn8xUnS3StV9azMXvMHZfZcPzOzALjaGUlemOS4\nm6lWbn7vSXJUZj+f2sKB6Q5JbjGf6e5fXuN+703y3Un+tKrultnfoTX9/eGmcQ0fVVUXVdW7k/zP\nJL+W5M6ZfZJ7XJK/TPK4JN+W5LDufkhmPYB3XDjAhiS/meSRmf3xP6GqbnPzPgx2032T/HyS+yd5\nZFXdYWHdE5L8fXc/OLM3zvMhFrdI8pbu/pVsv60kyXdk9ob+e5O8KLM/9Cdl9qY7mQ0Fe1BmgfCq\n5Ty0/coPZhae/yzJUVX19d39wSRHLLwm35dZIPqNJD/e3ccnuSDJadP6/5zZJ6pvSnLbJI/o7gcl\nuWdVfVt2/HqeneRRU7D8t6mWm+Ly6ZgHJ7ljdx87TX/btP7O0/DPH0nyK9NwzTOSPLy7H5rkblX1\noCSPz2wY57FJ/ia58XfLCzILj9+X5Ju3c/7tteHnJvnFqV3efdpuh7/D2KV7ZnpN5rr78939xWn2\npUlOmob5r/a3ST5ZVSctuUbWQVXdIsmjkvz1tEhbODC9JMljq+qvq+qF0weWa/HaJI+Zpn84yeuX\nUh0CH7OhGd19TGaf4r46szd9L5h6fx6T5E6Z9eZtqqrfT/LwJK9aOMaWJF/o7m3dfX13n9jdn795\nHwa7YSXJR7v7X7v7hiSXZdYzNHd0ZiEuSd64at/3Tv9vr60kyce6+98zG5rx6e7+1LTt/Pivzayn\n6seS/OHee0j7rccm+aPuvj6z5+aHp+V/kuQRVfUNmf2MfSqznsCXTb1rP5pZz3zylec8Sa5M8obp\ndTk6s9fla17PqrpLZp/Mnzcd77gkX7+d+h46fTA0//f8hXXztnB5kg9M04uv9UVJ0t0fSnK3zK7j\n+IYkb53OeVRmoexemV0XduM+U93XdPenpyE/8/oXba8Nb6/t7ux3GDu3klmI367uvi6zYP68HWzy\nC0meOw0NZf83/6D4osx+1t/R3ecn2sKBqrs/mqSSnJ7klkkurKonrmHXdyV5wNRJ8ANJzl9elQc2\nQzq5UXf/Q1V9PsmvJ3nRNPTqGUlu193XVtUxmfXInJrkxCS/OO16fXx4sC/bltlwi0Vbknw2syF1\nizasmr5hml5Ztd18yMXXtJVp+eJxF6c3JEl3/0RV3TPJDyW5qKq+c3qjcMCpqrtmNtz1zKpaSXJI\nZj1w/zPJeUmemuSwzHr3kuTaJMd198rCMY7M9JpU1S0z+7T13t39r1X1pmmz7b2eX0ryqTXcOGFn\n1/Dt9LXOV7edlemcl3T3V10rPPXyzeub/z5ZrHlx+Y7OP9/nax7rDn6HreUNCbOw/NTFBVV1q8zC\nepKku19TVT+V5B6rd+7uf66qd2R2Ewf2f4vX/r82yUdWrdQWDjBVdZvpg/4LklxQVW/MLPS/fGf7\ndfcN05D/05L8R3dfMV3bx17mTTo3mq4j+rokhyf52PQH/ZFJbllV90ny2OkOnj+R2afxSZKpV+Hg\nqvr6qtpQVW9aNTSQ9fWRJHetqm9OkqrakllPzvZ6SxZ9LMn8Llz/7w62OSyr2squiqmq21fVc7r7\nH7r7FzPrjTp01w9jWI/J7NrGe3f3d2T2Kekdq+o/JXl3Zj9r35tZz1+SfDDJI5Kkqn6kqo5fdbxN\nSa6bwt7dMnsNb5ntvJ7dfdV0nHtN/z9tuv5tb3rwdOxvT/LJzO7qeHRV3Xla/vyq+vpp+by++TU+\n/57k9lV1h2no2IPWeM6veaw7+x3GLv15krvPh+JV1UGZDdX+4VXb/ffMene25wWZ3djh1ssqknXx\nzCS/WlWHrFquLRxY/ryqTliYv2tm11avxWsyG5b/ul1tyO4T+FgcmvHmzD7FPSuzbvXXZHa90CmZ\nvYl8fFW9K7M//i9edZz/ltkb0q1JLuzuz9w85bMr01C4xyV56fQ6vzbJT2Y2FGdnXpHk2Gmfu2TW\nk7vab+Rr28rtt7PdYj1XJ9lSVe+tqrcneXd3X7nWxzOgxyT53fnM1HP3e0l+ZJremuT23f1P0yZP\nT/LsabjmqfnKMMr5/v+e2R/f92V2Ldv/yOxn+vey/dfzSUl+d/rZfnBmwWu11UM6L5qGma7Fp6dP\ne/9Pkp/v7muT/FSSN1fVX2Y2bPOyzG7RfUxVXZhZ6F2Zhmk+L8nFmbXbD63xnL+c5Neq6q2Z3Vzo\n+iSfyM5/h7ED0+vwPUmeXFXvz+ymOldn1r4Wt7soO/i9Mn248MrMPlBkEN39iczeqJ+xavlF0RZG\nVot/DzK7Zv9ZVfXO6e/6DyR59hqP9c4kX8hsRAtLsmFlZfVILYCkqu6e5J7d/daqemBm37m4y+9e\nY990IL2e09DNa7v7/1bVzyfZcKDfCRaAA5dr+IAduTrJz1TVczK7Juon17ke9syB9Hp+McnvTNck\nX5vZTXEA4ICkhw8AAGBQruEDAAAYlMAHAAAwKIEPAABgUAIfAADAoAQ+AACAQQl8AAAAg/r/AcJT\nHR5FaFokAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7fb8bac40be0>"]},"metadata":{"tags":[]}}]}]}