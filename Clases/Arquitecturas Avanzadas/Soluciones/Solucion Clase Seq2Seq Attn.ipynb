{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq Attn.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":["i5_oV-zCY-av","A8SYkTpHYqVo","702qFiEUxHZF","MmslbSP5xHZf"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"INzqe5KoY6IN","colab_type":"text"},"cell_type":"markdown","source":["# Sequence to Sequence with Attention\n","\n","Los modelos encoder-decoder tienen un problema, si os fijasteis, y sino, ver foto, el contexto del encoder era el útlimo estado de nuestra red recurrente. Es decir, pretendemos que una frase, da igual si es corta, larga o lo que sea, pretendemos que quede en un vector de tamaño fijo, ya sea 64 o 1024. Obviamente, si usamos 1024 posiciones sería mejor, pero no dejamos de depender de un vector de tamaño fijo.\n","\n","![](https://pytorch.org/tutorials/_images/seq2seq.png)\n","\n","Es por eso, que en 2015, empezaron a salir, basados de nuevo en Computer Vision los llamádos módulos de atención. Estos módulos nos permiten que nuestras redes aprendan dónde hay información relevante en el encoder. Y muy importante, nos permiten ver a nosotros donde se estan fijando.\n","\n","![](https://i.imgur.com/JaSRu42.png =700x)\n","\n","Estos modelos, son usados ya en cualquier sistema encoder-decoder, de hecho en los links que hemos visto anteriormente sobre el sistema de Google Translate, y cualquier otro sistema, usan ya estos sistemas. Aquí podeis ver un ejemplo aplicado a la traducción francés-inglés visto arriba.\n","\n","![](https://camo.githubusercontent.com/c54ad54bebb12b5b585ab666664e6d0e6002d894/68747470733a2f2f692e696d6775722e636f6d2f357936534376552e706e67 =900x)\n","\n","## Explain Attention Network\n","\n","Basicamente, el cambio que hacemos en esta arquitectura es el siguiente. En lugar de usar sólo el ultimo hidden_state de nuestro encoder, vamos a usarlos todos, y dejar que la red aprenda donde hay información relevante para producir el output. Es decir, en lugar de fijar-nos en lo último, o de fijar-nos en todo, ayudamos a nuestra arquitectura a fijar-se en aquello que es relevante.\n","\n","Ver ejemplo en [Attentional interfaces](https://distill.pub/2016/augmented-rnns/#attentional-interfaces)\n","\n","Hay varias maneras de calcular este nuevo contexto, nosotros implementaremos una en Keras (Luong's Attention, del segundo paper que os recomiendo aquí.) \n","\n","La forma de conseguir esto, no es distinta a nada que no hayamos hecho hasta la fecha, dot products, quizás una fully connected layer, y una softmax para generar una distribución que diga que partes son las más importantes.\n","\n","En estos dos papers, podeis leer en más detalle el funcionamiento de los módulos de atención.\n","\n","*   [Neural Machine Translation by jointly learning to align and translate](https://arxiv.org/pdf/1409.0473.pdf)\n","*   [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/pdf/1508.04025.pdf)\n","\n","Son papers algo complicados, pero muy influyentes en las tareas de NLP actuales.\n","\n","A continuación, haremos una simple implementación de un módulo de atención en numpy, y luego lo implementaremos en Keras modificando así nuestra arquitectura encoder-decoder (Sequence 2 Sequence)\n","\n"]},{"metadata":{"id":"_W8dD-y3Wz6M","colab_type":"text"},"cell_type":"markdown","source":["## Numpy Implementation"]},{"metadata":{"id":"YLsoPgUrKFjE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"eb3abe83-4d93-4a88-a058-1121b523bf19","executionInfo":{"status":"ok","timestamp":1531261127682,"user_tz":-120,"elapsed":592,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["import numpy as np"],"execution_count":1,"outputs":[]},{"metadata":{"id":"9eIf_sOUMzc-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"cd4e3a56-c846-4435-c858-d5fe2b17fb31","executionInfo":{"status":"ok","timestamp":1531261129072,"user_tz":-120,"elapsed":1208,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["def softmax(x, axis=0):\n","    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n","    e_x = np.exp(x - np.max(x))\n","    return e_x / e_x.sum(axis=axis) # only difference\n"],"execution_count":2,"outputs":[]},{"metadata":{"id":"gyxSLSxoZoZu","colab_type":"text"},"cell_type":"markdown","source":["#### Alignment score\n","\n","![](https://i.imgur.com/pjJrL24.png =400x)\n","\n","#### Alignment vector\n","\n","![](https://i.imgur.com/QAOe4Qk.png =400x)\n","\n","#### Context vector\n","\n","![](https://i.imgur.com/4fjOKja.png =650x)\n","\n"]},{"metadata":{"id":"Z9nOSC7WKHIi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"98da1441-8a7b-44bd-d810-978c2f8e6127","executionInfo":{"status":"ok","timestamp":1531261130091,"user_tz":-120,"elapsed":838,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[""],"execution_count":2,"outputs":[]},{"metadata":{"id":"Eg1Y-5PyQ6jt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"de832089-e4c3-4c84-9d29-5276cba6cca9","executionInfo":{"status":"ok","timestamp":1531261131609,"user_tz":-120,"elapsed":1234,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[""],"execution_count":2,"outputs":[]},{"metadata":{"id":"gNbKUJsAUjGD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"e2ad4b07-e3be-42c3-8312-efbeebfd2114","executionInfo":{"status":"ok","timestamp":1531261133024,"user_tz":-120,"elapsed":1224,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[""],"execution_count":2,"outputs":[]},{"metadata":{"id":"w9CbShb9exUs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"12ce2eaf-6c93-4b8d-c5e4-08e847719b3a","executionInfo":{"status":"ok","timestamp":1531261133894,"user_tz":-120,"elapsed":716,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[""],"execution_count":2,"outputs":[]},{"metadata":{"id":"i5_oV-zCY-av","colab_type":"text"},"cell_type":"markdown","source":["## Imports"]},{"metadata":{"id":"W-ofFt27xHYu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"72b2d7e9-d65f-4e3c-c7d2-338c75555a6f","executionInfo":{"status":"ok","timestamp":1531261135606,"user_tz":-120,"elapsed":1527,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["from keras.models import Model\n","from keras.layers import Input, CuDNNLSTM, Dense, LSTM\n","from keras.layers import Bidirectional\n","from keras.layers import Embedding\n","from keras.layers import Merge, Dot, Concatenate, Flatten, Permute, Multiply, dot, concatenate, Average\n","from keras.layers import TimeDistributed\n","from keras.layers import Activation\n","from keras.activations import softmax\n","from keras.preprocessing import sequence\n","from keras.callbacks import Callback\n","from keras.optimizers import SGD\n","from keras.models import load_model\n","import tensorflow as tf\n","import keras.backend as K\n","\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","\n","\n","from random import shuffle, choice, sample\n","import time\n","\n","import pprint as pp\n","import pickle\n","\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import pylab as pl\n","from IPython import display\n","\n","sns.set(color_codes=True)\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","%matplotlib notebook"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"A8SYkTpHYqVo","colab_type":"text"},"cell_type":"markdown","source":["## Data"]},{"metadata":{"id":"L_wM95I6xHY4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"5b0e02d2-b1e8-4b6a-d78f-7f9840ba8f78","executionInfo":{"status":"ok","timestamp":1531261136569,"user_tz":-120,"elapsed":768,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["USE_EMBEDDINGS = True\n","SAMPLE_EVERY = 3\n"],"execution_count":4,"outputs":[]},{"metadata":{"id":"yQD9aXDvxHY9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"bf3f9326-c82d-4ca9-9f98-a41f94f8a701","executionInfo":{"status":"ok","timestamp":1531261137970,"user_tz":-120,"elapsed":1204,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["def generate_dummy_data():\n","    x = [ix for ix in range(100)]\n","    data = []\n","    for ix_source in range(3, 5):\n","        for ix_target in range(3, 5):\n","            for ix, _ in enumerate(x):\n","                data.append((x[ix:ix+ix_source], x[ix+ix_source:ix+ix_target*2]))\n","    return data\n","    \n","dummy_data = generate_dummy_data()\n","shuffle(dummy_data)\n"],"execution_count":5,"outputs":[]},{"metadata":{"id":"kKve_smSpdme","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"fd677e2e-2c3e-4cf8-e910-6ee5e688f5bb","executionInfo":{"status":"ok","timestamp":1531261139093,"user_tz":-120,"elapsed":939,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[" # sentence preparation\n","data_tr = []\n","for i, (inp, out) in enumerate(dummy_data):\n","    # _in = inp.split()\n","    # _in = inp.split()\n","    \n","    inp.insert(0, '<SOS>')\n","    out.insert(0, '<SOS>')\n","    \n","    inp.append('<EOS>')\n","    out.append('<EOS>')\n","    \n","    data_tr.append((inp, out))"],"execution_count":6,"outputs":[]},{"metadata":{"id":"n2XDa9OLxHZA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"13e14845-bd0e-41f7-d44c-a33def484617","executionInfo":{"status":"ok","timestamp":1531261139973,"user_tz":-120,"elapsed":706,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["maxlen_source = max([len(x) for x, _ in dummy_data])\n","maxlen_source"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"702qFiEUxHZF","colab_type":"text"},"cell_type":"markdown","source":["## Data Preparation"]},{"metadata":{"id":"_vFuAQ0sxHZR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"2b2f7494-e7e9-4550-8e13-c24ad7498422","executionInfo":{"status":"ok","timestamp":1531261141303,"user_tz":-120,"elapsed":656,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["#vocabulary preparation\n","vocab = []\n","for inp, out in data_tr:\n","    vocab+=[w for w in inp]\n","    vocab+=[w for w in out]\n","vocab = list(set(vocab))\n","vocab.insert(0, '<PAD>')\n","vocab.append('<UNK>')\n","print(vocab)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['<PAD>', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, '<EOS>', '<SOS>', '<UNK>']\n"],"name":"stdout"}]},{"metadata":{"id":"R3KXFsqGxHZV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"1193c57d-1f93-4d12-c6ea-66561fe4368b","executionInfo":{"status":"ok","timestamp":1531261144853,"user_tz":-120,"elapsed":638,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["w2id = {w:i for i, w in enumerate(vocab)}\n","id2w = {w:i for i, w in w2id.items()}\n","#pp.pprint(id2w)"],"execution_count":9,"outputs":[]},{"metadata":{"id":"Gbymh3YzxHZZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"bca9d0fa-534d-4844-aa25-953e79a13af3","executionInfo":{"status":"ok","timestamp":1531261146048,"user_tz":-120,"elapsed":598,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["data_train = []\n","for inp, out in data_tr:\n","    ind_enc_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in inp]\n","    ind_dec_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in out]\n","    ind_dec_out = [w2id[w] if w in w2id else w2id['<UNK>'] for w in out[1:]]\n","    data_train.append((ind_enc_in, ind_dec_in, ind_dec_out))"],"execution_count":10,"outputs":[]},{"metadata":{"id":"Y0WcW3HKXIS6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"9ae42171-6a15-4f52-e2e8-2b6240d0bf3f","executionInfo":{"status":"ok","timestamp":1531261147079,"user_tz":-120,"elapsed":665,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["def split_train_val_test(dataset, split=0.2):\n","\n","    xe, xd, y = zip(*dataset)\n","    xe = np.array(list(xd))\n","    xd = np.array(list(xd))\n","    y = np.array(list(y))\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=split, random_state=1337) #l33t seed\n","    for train_index, test_index in sss.split(xe, y):\n","        xe_train, xe_val = xe[train_index], xe[test_index]\n","        xd_train, xd_val = xd[train_index], xd[test_index]\n","        y_train, y_val = y[train_index], y[test_index]\n","    splits = {'train':(xe_train, xd_train, y_train), 'test':(xe_val, xd_val, y_val)}\n","    return splits"],"execution_count":11,"outputs":[]},{"metadata":{"id":"MmslbSP5xHZf","colab_type":"text"},"cell_type":"markdown","source":["## Auxiliary functions"]},{"metadata":{"id":"djJKkTb90eUj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"53ee7d95-4a40-4991-ea7b-dec7f704b2c9","executionInfo":{"status":"ok","timestamp":1531261147988,"user_tz":-120,"elapsed":578,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["def sample_pred(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    # print('sample pred: ',probas.shape) # apply here LM\n","    return np.argmax(probas)"],"execution_count":12,"outputs":[]},{"metadata":{"id":"yRHc24apxHZi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"38a5115e-e540-49dd-eac6-edb48c8e5268","executionInfo":{"status":"ok","timestamp":1531261149039,"user_tz":-120,"elapsed":618,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["class Sampletest(Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        if epoch % 5 == 0  and epoch>0:\n","            nb_samples = 1\n","            data_t = sample(data_tr, nb_samples)\n","            data_test = []\n","            for inp, out in data_t:\n","                ind_enc_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in inp]\n","                ind_dec_in = [w2id['<SOS>']] # w2id[w] if w in w2id else w2id['<UNK>'] for w in out.split(' ')\n","                data_test.append((ind_enc_in,ind_dec_in))\n","\n","            params = {\n","                'max_encoder_len': maxlen_source+2,\n","                'max_decoder_len': maxlen_source+2,\n","                'target_len': len(vocab),\n","                'use_embeddings': True\n","                }\n","            if 'use_embeddings' in params and params['use_embeddings']:\n","                encoder_input_data = np.zeros(shape=(nb_samples, train_params['max_encoder_len']))    \n","                decoder_input_data = np.zeros(shape=(nb_samples, train_params['max_decoder_len']))\n","                for i, (ei, di) in enumerate(data_test):\n","                    for j, idx in enumerate(ei):\n","                        encoder_input_data[i, j] = idx\n","                    for j, idx_di in enumerate(di):\n","                        decoder_input_data[i, j] = idx_di        \n","            else:\n","                encoder_input_data = np.zeros(shape=(nb_samples, params['max_encoder_len'], params['target_len']))    \n","                decoder_input_data = np.zeros(shape=(nb_samples, params['max_decoder_len'], params['target_len']))\n","\n","                for i, (ei, di) in enumerate(data_test):\n","                    for j, idx in enumerate(ei):\n","                        encoder_input_data[i, j, idx] = 1\n","                    for j, idx_di in enumerate(di):\n","                        decoder_input_data[i, j, idx_di] = 1\n","            temperature = choice([0.1, 0.3, 1.5])\n","            for i in range(1, params['max_decoder_len']):\n","                output = self.model.predict([encoder_input_data, decoder_input_data]) #.argmax(axis=2)\n","                # print(output.shape)\n","                output_t = np.apply_along_axis(sample_pred, 2, output, temperature=temperature)\n","                # print(output_t.shape)\n","                decoder_input_data[:,i] = output_t[:,i]\n","                \n","            result = decoder_input_data\n","            for r, original in zip(result, data_t):\n","                \n","                sentence = original\n","                repr_out = []\n","                for ix in r:\n","                    token = id2w[ix]\n","                    if token == '<EOS>':\n","                        break\n","                    else:\n","                        repr_out.append(token)\n","            \n","                print('Test Sample epoch({}): {} ====> {}'.format(epoch, sentence, repr_out[1:]))"],"execution_count":13,"outputs":[]},{"metadata":{"id":"fq5cJ7I6xHZl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"da5172be-dae4-4342-f843-8740ab2607dc","executionInfo":{"status":"ok","timestamp":1531261150001,"user_tz":-120,"elapsed":566,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["class HistoryDisplay(Callback):\n","    \n","    def on_train_begin(self, logs={}):\n","        self.losses = []\n","        self.accs = []\n","        self.epochs = []\n","        self.fig, self.ax = plt.subplots()\n","        #plt.show()\n","        \n","        plt.ion()\n","        self.fig.show()\n","        self.fig.canvas.draw()\n","    \n","    def on_epoch_end(self, epoch, logs):\n","        self.epochs.append(epoch)\n","        self.losses.append(logs['loss'])\n","        self.accs.append(logs['acc'])\n","        if epoch % PLOT_EVERY == 0:\n","            \n","            self.ax.clear()\n","            self.ax.plot(self.epochs, self.accs, 'g', label='acc')\n","            self.ax.plot(self.epochs, self.losses, 'b', label='loss')\n","            legend = self.ax.legend(loc='upper right', shadow=True, fontsize='x-large')\n","            #display.clear_output(wait=True)\n","            #display.display(pl.gcf())\n","            self.fig.canvas.draw()\n","            \n","            #plt.draw()\n","        "],"execution_count":14,"outputs":[]},{"metadata":{"id":"BJLyYqlGYs_H","colab_type":"text"},"cell_type":"markdown","source":["## Architecture Defintion"]},{"metadata":{"id":"gG0dh3kUawcq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"31733907-a807-4783-ee61-f3a41981ff3e","executionInfo":{"status":"ok","timestamp":1531261151062,"user_tz":-120,"elapsed":566,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["from keras.engine.topology import Layer"],"execution_count":15,"outputs":[]},{"metadata":{"id":"dUXHWc5VxHZ0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"7cca440b-f465-48d6-c65d-f82e2e7686fc","executionInfo":{"status":"ok","timestamp":1531261152915,"user_tz":-120,"elapsed":1262,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["class Seq2Seq:\n","    def __init__(self, **kwargs):\n","        self.params = kwargs.pop('params', None)\n","    \n","    def compile_attention_seq2seq(self, params={}):\n","        \n","        # embeddings\n","        \n","        embedding_layer_encoder = Embedding(input_dim=params['vocab'], output_dim=params['emb_feats'], input_length=params['max_encoder_len'], name='embedding_layer_encoder')\n","        \n","        embedding_layer_decoder = Embedding(input_dim=params['vocab'], output_dim=params['emb_feats'], input_length=params['max_decoder_len'], name='embedding_layer_decoder')\n","        \n","        \n","        # ENCODER\n","        encoder_inputs = Input(shape=(params['max_encoder_len'], ), name='encoder_input')       \n","        \n","        encoder_embedding = embedding_layer_encoder(encoder_inputs)\n","        \n","        encoder = LSTM(params['hidden_size'], return_state=True, return_sequences=True, name='encoder')\n","        \n","        encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n","\n","        # inicializar el decoder con el ultimo estado de nuestro encoder\n","        encoder_states = [state_h, state_c]\n","        \n","        # DECODER\n","               \n","        decoder_inputs = Input(shape=(params['max_decoder_len'], ), name='decoder_input')       \n","        \n","        decoder_embedding = embedding_layer_decoder(decoder_inputs)\n","        \n","        decoder = LSTM(params['hidden_size'], return_sequences=True, name='decoder')\n","        decoder_outputs = decoder(decoder_embedding, encoder_states)\n","        \n","        # empieza la fiesta // Attention Layer\n","        \n","        sc = dot([decoder_outputs, encoder_outputs], axes=[2, 2], name='partial_scores')\n","        print(sc)\n","        scores = Dense(params['hidden_size'], activation='softmax', name='scores')(sc)\n","        print(scores)\n","        \n","        attention_weights = Activation('softmax', name='attention_weights')(dot([scores, encoder_outputs], axes=[2, 2], name='alignment_vector'))\n","        \n","        print('attention_weights', attention_weights)\n","        print('decoder_outputs', decoder_outputs)\n","        \n","        context = dot([attention_weights, encoder_outputs], axes=[2,1], name='context_vector')\n","        decoder_combined = concatenate([context, decoder_outputs])\n","        \n","        # h_hat\n","        h_hat = TimeDistributed(Dense(64, activation='tanh'))(decoder_combined)\n","        decoder_outputs = TimeDistributed(Dense(params['target_size'], activation='softmax'))(h_hat)\n","        \n","        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","        \n","        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","        model.summary()\n","        return model\n","        \n","    def train(self, model, data, params={}):\n","        \n","        callbacks = self._get_callbacks()\n","        print(callbacks)\n","        if 'shuffle' in params and params['shuffle']:\n","            shuffle(data)\n","        encoder_input_data = np.zeros(shape=(len(data), params['max_encoder_len']))    \n","        decoder_input_data = np.zeros(shape=(len(data), params['max_decoder_len']))\n","        decoder_target_data = np.zeros(shape=(len(data), params['max_decoder_len'], params['target_len']))\n","        for i, (ei, di,dt) in enumerate(data):\n","            for j, idx in enumerate(ei):\n","                encoder_input_data[i, j] = idx\n","            for j, idx_di in enumerate(di):\n","                decoder_input_data[i, j] = idx_di\n","            for j in range(params['max_decoder_len']):      \n","                if j<len(dt):\n","                    decoder_target_data[i, j, dt[j]] = 1\n","                else:\n","                    decoder_target_data[i, j, 0] = 1 \n","        model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=params['batch_size'], epochs=params['epochs'],  callbacks=callbacks, verbose=1)\n","            \n","    def predict(self, model, data, params={}):        \n","\n","\n","        nb_samples = len(data)\n","        data_t = sample(data_tr, nb_samples)\n","        data_test = []\n","        predicted_out = []\n","        for samp in range(nb_samples):\n","            for inp, out in data_t:\n","                ind_enc_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in inp]\n","                ind_dec_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in out]\n","                data_test.append((ind_enc_in,ind_dec_in))\n","\n","\n","            encoder_input_data = np.zeros(shape=(1, params['max_encoder_len']))    \n","            decoder_input_data = np.zeros(shape=(1, params['max_decoder_len']))\n","\n","            for i, (ei, di) in enumerate(data_test):\n","                for j, idx in enumerate(ei):\n","                    encoder_input_data[i, j] = idx\n","                for j, idx_di in enumerate(di):\n","                    decoder_input_data[i, j] = idx_di\n","\n","            result = self.model.predict([encoder_input_data, decoder_input_data])\n","            for r, original in zip(result, data_t):\n","                original_sentence = original[0]\n","                idx = np.argmax(r, axis=1)\n","                print(idx)\n","                repr_out = []\n","                for ix in idx:\n","                    token = id2w[ix]\n","                    if token == '<EOS>':\n","                        break\n","                    else:\n","                        repr_out.append(token)\n","            predicted_out.append(repr_out)\n","        return predicted_out\n","    \n","    def load(self, model_path='seq2seq_attn.h5'):\n","        return load_model(model_path)\n","    \n","    def _get_callbacks(self, model_path='seq2seq_attn.h5'):\n","        es = EarlyStopping(monitor='loss', patience=9, mode='auto', verbose=1)\n","        save_best = ModelCheckpoint(model_path, monitor='loss', verbose = 1, save_best_only=True, save_weights_only=False, period=2)\n","        st = Sampletest()\n","        # hd = HistoryDisplay()\n","        rlr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose=1)\n","        return [rlr, es, st]#st, save_best,  hd,"],"execution_count":16,"outputs":[]},{"metadata":{"id":"DzGG3GhaxHZ-","colab_type":"text"},"cell_type":"markdown","source":["## Compile model "]},{"metadata":{"id":"sz5V330IxHZ_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":151},"outputId":"ec09d54b-2a43-4ee9-a2f6-4ae2cf7102d9","executionInfo":{"status":"ok","timestamp":1531261154408,"user_tz":-120,"elapsed":983,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["compile_params = {\n","    'vocab': len(vocab),\n","    'emb_feats': 50,\n","    'hidden_size': 128,\n","    'target_size': len(vocab),\n","    'input_size': len(vocab),\n","    'max_encoder_len': maxlen_source+2,\n","    'max_decoder_len': maxlen_source+2,\n","    'use_embeddings': True,\n","}\n","\n","pp.pprint(compile_params)\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["{'emb_feats': 50,\n"," 'hidden_size': 128,\n"," 'input_size': 104,\n"," 'max_decoder_len': 8,\n"," 'max_encoder_len': 8,\n"," 'target_size': 104,\n"," 'use_embeddings': True,\n"," 'vocab': 104}\n"],"name":"stdout"}]},{"metadata":{"id":"KKjxhF2ZxHaF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":773},"outputId":"593bad67-b6ec-4475-a146-918599e11a9f","executionInfo":{"status":"ok","timestamp":1531261157529,"user_tz":-120,"elapsed":1982,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["s2s = Seq2Seq()\n","\n","s2s_model = s2s.compile_attention_seq2seq(params=compile_params)    "],"execution_count":18,"outputs":[{"output_type":"stream","text":["Tensor(\"partial_scores/MatMul:0\", shape=(?, ?, ?), dtype=float32)\n","Tensor(\"scores/truediv:0\", shape=(?, 8, 128), dtype=float32)\n","attention_weights Tensor(\"attention_weights/truediv:0\", shape=(?, 8, ?), dtype=float32)\n","decoder_outputs Tensor(\"decoder/transpose_1:0\", shape=(?, ?, 128), dtype=float32)\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","encoder_input (InputLayer)      (None, 8)            0                                            \n","__________________________________________________________________________________________________\n","decoder_input (InputLayer)      (None, 8)            0                                            \n","__________________________________________________________________________________________________\n","embedding_layer_encoder (Embedd (None, 8, 50)        5200        encoder_input[0][0]              \n","__________________________________________________________________________________________________\n","embedding_layer_decoder (Embedd (None, 8, 50)        5200        decoder_input[0][0]              \n","__________________________________________________________________________________________________\n","encoder (LSTM)                  [(None, 8, 128), (No 91648       embedding_layer_encoder[0][0]    \n","__________________________________________________________________________________________________\n","decoder (LSTM)                  (None, 8, 128)       91648       embedding_layer_decoder[0][0]    \n","                                                                 encoder[0][1]                    \n","                                                                 encoder[0][2]                    \n","__________________________________________________________________________________________________\n","partial_scores (Dot)            (None, 8, 8)         0           decoder[0][0]                    \n","                                                                 encoder[0][0]                    \n","__________________________________________________________________________________________________\n","scores (Dense)                  (None, 8, 128)       1152        partial_scores[0][0]             \n","__________________________________________________________________________________________________\n","alignment_vector (Dot)          (None, 8, 8)         0           scores[0][0]                     \n","                                                                 encoder[0][0]                    \n","__________________________________________________________________________________________________\n","attention_weights (Activation)  (None, 8, 8)         0           alignment_vector[0][0]           \n","__________________________________________________________________________________________________\n","context_vector (Dot)            (None, 8, 128)       0           attention_weights[0][0]          \n","                                                                 encoder[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 8, 256)       0           context_vector[0][0]             \n","                                                                 decoder[0][0]                    \n","__________________________________________________________________________________________________\n","time_distributed_1 (TimeDistrib (None, 8, 64)        16448       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","time_distributed_2 (TimeDistrib (None, 8, 104)       6760        time_distributed_1[0][0]         \n","==================================================================================================\n","Total params: 218,056\n","Trainable params: 218,056\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"F6godnwCSV0r","colab_type":"text"},"cell_type":"markdown","source":["Comprobar si los shapes son iguales en keras que en numpy!"]},{"metadata":{"id":"nRtE8bcFxHaL","colab_type":"text"},"cell_type":"markdown","source":["## Train"]},{"metadata":{"id":"AOcX4SMBxHaO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"bc2bad4a-dd8e-42b8-da2a-ac79d5e1e95f","executionInfo":{"status":"ok","timestamp":1531261158861,"user_tz":-120,"elapsed":1297,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["# data_train"],"execution_count":19,"outputs":[]},{"metadata":{"id":"coFazOl3xHaR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3122},"outputId":"ce7b7af6-ada2-493d-ac05-daca84f31c19","executionInfo":{"status":"error","timestamp":1531261166363,"user_tz":-120,"elapsed":6564,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["train_params = {\n","    'epochs': 500,\n","    'batch_size': 16,\n","    'shuffle': True,\n","    'target_len': len(vocab),\n","    'max_encoder_len': maxlen_source+2,\n","    'max_decoder_len': maxlen_source+2,\n","    'use_embeddings': True\n","}\n","pp.pprint(train_params)\n","\n","s2s.train(model=s2s_model, data=data_train, params=train_params)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["{'batch_size': 16,\n"," 'epochs': 500,\n"," 'max_decoder_len': 8,\n"," 'max_encoder_len': 8,\n"," 'shuffle': True,\n"," 'target_len': 104,\n"," 'use_embeddings': True}\n","[<keras.callbacks.ReduceLROnPlateau object at 0x7fee0f476550>, <keras.callbacks.EarlyStopping object at 0x7fee0f476208>, <__main__.Sampletest object at 0x7fee0f4765f8>]\n","Epoch 1/500\n"],"name":"stdout"},{"output_type":"error","ename":"InternalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(16, 50), b.shape=(50, 128), m=16, n=128, k=50\n\t [[Node: decoder/while/MatMul_3 = MatMul[T=DT_FLOAT, _class=[\"loc:@train...rayWriteV3\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder/while/TensorArrayReadV3, decoder/while/MatMul_3/Enter)]]\n\t [[Node: loss/mul/_175 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3778_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-410b6ebaf956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms2s_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-c0d05b5cf058>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, data, params)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(16, 50), b.shape=(50, 128), m=16, n=128, k=50\n\t [[Node: decoder/while/MatMul_3 = MatMul[T=DT_FLOAT, _class=[\"loc:@train...rayWriteV3\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder/while/TensorArrayReadV3, decoder/while/MatMul_3/Enter)]]\n\t [[Node: loss/mul/_175 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3778_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'decoder/while/MatMul_3', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-0d1cdc88e17f>\", line 3, in <module>\n    s2s_model = s2s.compile_attention_seq2seq(params=compile_params)\n  File \"<ipython-input-16-c0d05b5cf058>\", line 33, in compile_attention_seq2seq\n    decoder_outputs = decoder(decoder_embedding, encoder_states)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 538, in __call__\n    output = super(RNN, self).__call__(full_input, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 2112, in call\n    initial_state=initial_state)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 609, in call\n    input_length=timesteps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2771, in rnn\n    swap_memory=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3209, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2941, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2878, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2757, in _step\n    tuple(constants))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 600, in step\n    return self.cell.call(inputs, states, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\", line 1884, in call\n    x_o = K.dot(inputs_o, self.kernel_o)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 1076, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 2014, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4279, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(16, 50), b.shape=(50, 128), m=16, n=128, k=50\n\t [[Node: decoder/while/MatMul_3 = MatMul[T=DT_FLOAT, _class=[\"loc:@train...rayWriteV3\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder/while/TensorArrayReadV3, decoder/while/MatMul_3/Enter)]]\n\t [[Node: loss/mul/_175 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3778_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"]}]},{"metadata":{"id":"O7h2z9smxHaX","colab_type":"text"},"cell_type":"markdown","source":["## Predict"]},{"metadata":{"id":"JhB1Kxsgx1lg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["predict_params = {\n","            'max_encoder_len': maxlen + 2,\n","            'max_decoder_len': maxlen + 2,\n","            'target_len': len(vocab)\n","            }\n","\n","s2s.predict(model=s2s_model, data=['', ''], params=predict_params)\n","\n","# data tiene que ser una lista de esas predicciones que quereis hacer. Fijaros en la implementación de Sampletest más arriba"],"execution_count":0,"outputs":[]}]}