{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":["XL1NQjYqkXjL","94Lc8jzsJA5J","nT68AKpKxKWW","xujVkl70xKXO","pLnTOi2ixKXj"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"sPJSlwGfMNLZ","colab_type":"text"},"cell_type":"markdown","source":["# Arquitecturas avanzadas de NLP. Sequence 2 Sequence\n","\n","[Uno de los mejores resources](https://distill.pub/2016/augmented-rnns/)\n","\n","Hoy/ahora, veremos una de las arquitecturas más usadas, para un tipo de problema muy concreto, pero muy extendido. Si os acordais de Language Modeling, generábamos secuencias, con una palabra o carácter de semilla, pero podía ir a cualquier parte la secuencia. Con Sequence 2 Sequence (Seq2Seq - S2S), lo que queremos es condicionar el output de nuestra arquitectura a todo un contexto.\n","\n","![Seq2Seq](https://cdn-images-1.medium.com/max/1600/1*_6-EVV3RJXD5KDjdnxztzg@2x.png)\n","\n","Esta arquitectura apareció por primera vez en 2014, [paper](https://www.aclweb.org/anthology/D14-1179), y aunque tuvo mucha repercusión, no fue hasta que en 2015... lo vemos despues!\n","\n","Estas arquitecturas, ya en 2014 mostraron gran potencial, y se confirmó cuando empresas como Google, decidieron cambiar productos tan importantes como el Google Translate a arquitecturas similares a esta. Os dejó un blog [post](https://codesachin.wordpress.com/2017/01/18/understanding-the-new-google-translate/) para que veais, y el [paper](https://arxiv.org/pdf/1609.08144.pdf) original dónde se explica el funcionamiento de la arquitectura. Otra aplicación bastante interesante, es la de generar respuestas a correos electrónicos de forma automática [info aquí](https://ai.googleblog.com/2015/11/computer-respond-to-this-email.html).\n","\n","### Vale bien, pero que hace esto?\n","\n","El dibujo de arriba, si seguis el timeline (time-steps), queda bastante claro. Primero codificamos un mensaje (steps-1-4), luego inicializamos el decoder (flecha entre 4 y 5), y empezamos la decodificación (5-7). \n","\n","Durante el entreno, se pasan dos inputs distintos, el input del encoder, y el del decoder. El input del encoder aquí sería\n","\n","\n"]},{"metadata":{"id":"p_Z4-b6BlpY8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"9232ee5e-adc9-4e51-d772-20fda9611ef4","executionInfo":{"status":"ok","timestamp":1531215410359,"user_tz":-120,"elapsed":790,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["input_encoder = [\"<SOS>\", \"how\", \"are\", \"you\", \"?\", \"<EOS>\"]\n","input_decoder = [\"<SOS>\", \"I\", \"am\", \"good\", \"<EOS>\"]\n","target_decoder = input_decoder[1:]\n","target_decoder"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['I', 'am', 'good', '<EOS>']"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"GvA_6Qh1lr3T","colab_type":"text"},"cell_type":"markdown","source":["Fijaros que el encoder no tiene un target, sino que calcularemos la loss en el decoder, y pasaremos el gradiente hacía atrás desde el decoder, hasta el primer step del encoder.\n","\n","Del dibujo de arriba, ya lo habeis visto absolutamente todo. Las celdas azules verdes y azules son...? Normalmente son celdas RNN, ya sean vanilla RNN, LSTMs o GRUs (que aunque no las hemos introducido en el curso, son una variamente algo más \"barata\" que las LSTMs).\n","\n","La única flecha que os debería preocupar es la de verde a azul. En esa parte estamos copiando el último estado de nuestra encoder-RNN, y usandolo como estado inicial en el decoder-RNN. Si os acordáis del dibujo, de las LSTMs, básicamente queremos h_t, cuando t = T, es decir en su último estado.\n","\n","![](https://i.imgur.com/nE53oh1.png)\n","\n","### Keras tip\n","\n","![](https://i.imgur.com/V9Pkm8d.png)\n","\n","Keras nos permite obtener el estado de una LSTM, seteando return_state a True.\n","\n","Esto modifica el output, devolviendonos 3 tensores, el output, el hidden state, i el cell state. En caso normal, el output i el hidden state, son lo mismo, pero esto puede ser modificado con el keyword return_sequences, que nos permite obtener una matriz con un output por timestep, el hidden state (del último estado) y el cell_state del último estado.\n","\n","Ahora que ya sabemos como recoger el hidden state, ya podemos ir a implementar un Seq2Seq en Keras.\n","\n","No implementaremos nada en numpy, porque ya tenemos casi todo implementado (almenos el forward pass) en sesiones pasadas, con lo que saltaremos a Keras directamente.\n"]},{"metadata":{"id":"XL1NQjYqkXjL","colab_type":"text"},"cell_type":"markdown","source":["## Imports"]},{"metadata":{"id":"WXvp_fvsxKV9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"f3494fe6-7cfb-4952-b8ef-ab6c2f5dd66f","executionInfo":{"status":"ok","timestamp":1531256065637,"user_tz":-120,"elapsed":2332,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["from keras.models import Model\n","from keras.layers import Input, CuDNNLSTM, Dense, LSTM\n","from keras.layers import Bidirectional\n","from keras.layers import Embedding\n","from keras.preprocessing import sequence\n","from keras.callbacks import Callback\n","from keras.layers import TimeDistributed\n","from keras.optimizers import SGD\n","from keras.models import load_model\n","\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","\n","import numpy as np\n","from random import shuffle, choice, sample\n","\n","import pprint as pp\n","\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import pylab as pl\n","from IPython import display\n","\n","sns.set(color_codes=True)\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","%matplotlib notebook"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"94Lc8jzsJA5J","colab_type":"text"},"cell_type":"markdown","source":["## Data"]},{"metadata":{"id":"08ZzfxETc0ql","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"9f6dd32c-3f55-4355-91b2-f66de380cf2a","executionInfo":{"status":"ok","timestamp":1531256068712,"user_tz":-120,"elapsed":572,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["def generate_dummy_data():\n","    x = [ix for ix in range(100)]\n","    data = []\n","    for ix_source in range(3, 5):\n","        for ix_target in range(3, 5):\n","            for ix, _ in enumerate(x):\n","                data.append((x[ix:ix+ix_source], x[ix+ix_source:ix+ix_target*2]))\n","    return data\n","    "],"execution_count":2,"outputs":[]},{"metadata":{"id":"XU-BCbjdd7F7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"8b80e547-a1ec-43b3-97cc-ac7b1c1a3478","executionInfo":{"status":"ok","timestamp":1531256069937,"user_tz":-120,"elapsed":873,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["dummy_data = generate_dummy_data()"],"execution_count":3,"outputs":[]},{"metadata":{"id":"iWVoNQPqxKWQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"52ec9017-cd32-415f-de23-f8043f6c5569","executionInfo":{"status":"ok","timestamp":1531256071301,"user_tz":-120,"elapsed":1220,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["shuffle(dummy_data)"],"execution_count":4,"outputs":[]},{"metadata":{"id":"DEY8F0LL-WhS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"797958aa-a455-4aff-df20-95667a4a076a","executionInfo":{"status":"ok","timestamp":1531256086219,"user_tz":-120,"elapsed":1425,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["dummy_data[0]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([47, 48, 49, 50], [51, 52, 53, 54])"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"nT68AKpKxKWW","colab_type":"text"},"cell_type":"markdown","source":["## Data Preprocess"]},{"metadata":{"id":"iahClNecxKWY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":17},"outputId":"1c59ce85-3dea-46c7-db3e-a1bb10aa2c29","executionInfo":{"status":"ok","timestamp":1531256209722,"user_tz":-120,"elapsed":582,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["data_tr = []\n","\n","for i, (inp, out) in enumerate(dummy_data):\n","    inp.insert(0, '<SOS>')\n","    out.insert(0, '<SOS>')\n","    \n","    inp.append('<EOS>')\n","    out.append('<EOS>')\n","    \n","    data_tr.append((inp, out))"],"execution_count":7,"outputs":[]},{"metadata":{"id":"vIHDdlVqopCG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"a60063db-26ac-4e71-d5e3-c808741f507f","executionInfo":{"status":"ok","timestamp":1531256239284,"user_tz":-120,"elapsed":652,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["maxlen = max([len(x) for x, _ in dummy_data])\n","maxlen"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"dGD-24qOxKWe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"b2336712-ec17-4570-fb10-a38c2cd9a5bd","executionInfo":{"status":"ok","timestamp":1531256241253,"user_tz":-120,"elapsed":581,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["#vocabulary preparation\n","vocab = []\n","for inp, out in data_tr:\n","    vocab+=[w for w in inp]\n","    vocab+=[w for w in out]\n","vocab = list(set(vocab))\n","vocab.insert(0, '<PAD>')\n","vocab.append('<UNK>')\n","print(vocab)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["['<PAD>', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, '<EOS>', '<SOS>', '<UNK>']\n"],"name":"stdout"}]},{"metadata":{"id":"Y-PY3iZExKWm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"f1a71478-19cc-4851-f7dc-06d2ac7d9bc6","executionInfo":{"status":"ok","timestamp":1531256246785,"user_tz":-120,"elapsed":586,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["w2id = {w:i for i, w in enumerate(vocab)}\n","id2w = {w:i for i, w in w2id.items()}"],"execution_count":10,"outputs":[]},{"metadata":{"id":"xfULT57_xKWs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"43f5df14-0773-4ddc-c64f-6e04e1930063","executionInfo":{"status":"ok","timestamp":1531258107540,"user_tz":-120,"elapsed":570,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["data_train = []\n","\n","for inp, out in data_tr:\n","    enc_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in inp]\n","    dec_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in out]\n","    dec_out = [w2id[w] if w in w2id else w2id['<UNK>'] for w in out[1:]]\n","    \n","    data_train.append((enc_in, dec_in, dec_out))"],"execution_count":44,"outputs":[]},{"metadata":{"id":"3MVoau6KFlJL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"ec6592c6-d1cc-44fa-eca9-841b24c7a236","executionInfo":{"status":"ok","timestamp":1531258108737,"user_tz":-120,"elapsed":569,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["data_train[0]"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([102, 48, 49, 50, 51, 101], [102, 52, 53, 54, 55, 101], [52, 53, 54, 55, 101])"]},"metadata":{"tags":[]},"execution_count":45}]},{"metadata":{"id":"Qea0Y4UPF-DC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"0c57a361-9c54-4392-be86-ba006a7370cd","executionInfo":{"status":"ok","timestamp":1531258114454,"user_tz":-120,"elapsed":603,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["data_tr[0]"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['<SOS>', 47, 48, 49, 50, '<EOS>'], ['<SOS>', 51, 52, 53, 54, '<EOS>'])"]},"metadata":{"tags":[]},"execution_count":46}]},{"metadata":{"id":"mz8irJdSxKWz","colab_type":"text"},"cell_type":"markdown","source":["## Auxiliary Functions"]},{"metadata":{"id":"GY7ZXd-rxKW0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"d86d2ca6-e959-4cf5-bfda-fa44a5b54bc1","executionInfo":{"status":"ok","timestamp":1531258352340,"user_tz":-120,"elapsed":580,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["class Sampletest(Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        if epoch % 1 == 0  and epoch>0:\n","            nb_samples = 1\n","            data_t = sample(data_tr, nb_samples)\n","            data_test = []\n","            for inp, out in data_t:\n","                ind_enc_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in inp]\n","                ind_dec_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in out]\n","                data_test.append((ind_enc_in,ind_dec_in))\n","\n","            params = {\n","                'max_encoder_len': maxlen + 2,\n","                'max_decoder_len': maxlen + 2,\n","                'target_len': len(vocab)\n","                }\n","\n","            encoder_input_data = np.zeros(shape=(nb_samples, params['max_encoder_len']))    \n","            decoder_input_data = np.zeros(shape=(nb_samples, params['max_decoder_len']))\n","\n","            for i, (ei, di) in enumerate(data_test):\n","                for j, idx in enumerate(ei):\n","                    encoder_input_data[i, j] = idx\n","                for j, idx_di in enumerate(di):\n","                    decoder_input_data[i, j] = idx_di\n","\n","            result = self.model.predict([encoder_input_data, decoder_input_data])\n","            for r, original in zip(result, data_t):\n","                original_sentence = original[0]\n","                idx = np.argmax(r, axis=1)\n","                print(idx)\n","                repr_out = []\n","                for ix in idx:\n","                    token = id2w[ix]\n","                    if token == '<EOS>':\n","                        break\n","                    else:\n","                        repr_out.append(token)\n","                #print('   '*40, end='\\r')\n","                print('Test Sample epoch({}): {} ====> {}'.format(epoch, original_sentence, \" \".join(repr_out)))"],"execution_count":55,"outputs":[]},{"metadata":{"id":"CDsE61T-xKW5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class HistoryDisplay(Callback):\n","    \n","    def on_train_begin(self, logs={}):\n","        self.losses = []\n","        self.accs = []\n","        self.epochs = []\n","        self.fig, self.ax = plt.subplots()\n","        #plt.show()\n","        \n","        plt.ion()\n","        self.fig.show()\n","        self.fig.canvas.draw()\n","    \n","    def on_epoch_end(self, epoch, logs):\n","        self.epochs.append(epoch)\n","        self.losses.append(logs['loss'])\n","        self.accs.append(logs['acc'])\n","        if epoch % 3 == 0:\n","            \n","            self.ax.clear()\n","            self.ax.plot(self.epochs, self.accs, 'g--', label='acc')\n","            self.ax.plot(self.epochs, self.losses, 'b--', label='loss')\n","            legend = self.ax.legend(loc='upper right', shadow=True, fontsize='x-large')\n","            #display.clear_output(wait=True)\n","            #display.display(pl.gcf())\n","            self.fig.canvas.draw()\n","            \n","            #plt.draw()\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"qFgDxMc9JSr-","colab_type":"text"},"cell_type":"markdown","source":["## Architecture definition"]},{"metadata":{"id":"Dz0BdGQGxKXD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"e3a69073-a577-4b46-db7a-053d3b3e3532","executionInfo":{"status":"ok","timestamp":1531258355416,"user_tz":-120,"elapsed":570,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["class Seq2Seq:\n","    def __init__(self, **kwargs):\n","        self.params = kwargs.pop('params', None)\n","    \n","    def compile_basic_seq2seq(self, params={}):\n","        \n","        encoder_inputs = Input(shape=(params['max_encoder_len'], ), name='encoder_input')\n","        embedding_layer = Embedding(input_dim=params['vocab'], output_dim=params['emb_feats'], name='embedding_layer')\n","        \n","        encoder_embedding = embedding_layer(encoder_inputs)\n","        \n","        encoder = LSTM(params['hidden_size'], return_state=True, name='encoder')\n","        \n","        encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n","        print(encoder_outputs.shape, state_h.shape, state_c.shape)\n","        # inicializar el decoder con el ultimo estado de nuestro encoder\n","        encoder_states = [state_h, state_c]\n","        \n","        decoder_inputs = Input(shape=(params['max_decoder_len'], ), name='decoder_input')\n","        embedding_layer_dec = Embedding(input_dim=params['vocab'], output_dim=params['emb_feats'], name='embedding_layer_decoder')\n","        \n","        decoder_embedding = embedding_layer_dec(decoder_inputs)\n","        decoder = LSTM(params['hidden_size'], return_state=True, return_sequences=True, name='decoder')\n","        \n","        decoder_out, _, _ = decoder(decoder_embedding, initial_state=encoder_states)\n","        \n","        decoder_dense = Dense(params['target_size'], activation='softmax', name='softmax')\n","        \n","        decoder_outputs = TimeDistributed(decoder_dense)(decoder_out)\n","        \n","        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","        \n","        model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n","        model.summary()\n","        \n","        return model\n","        \n","    def train(self, model, data, params={}):\n","        \n","        callbacks = self._get_callbacks()\n","        if 'shuffle' in params and params['shuffle']:\n","            shuffle(data)\n","        \n","        encoder_input_data = np.zeros(shape=(len(data), train_params['max_encoder_len']))    \n","        decoder_input_data = np.zeros(shape=(len(data), train_params['max_decoder_len']))\n","        decoder_target_data = np.zeros(shape=(len(data), train_params['max_decoder_len'], train_params['target_len']))\n","        for i, (ei, di,dt) in enumerate(data):            \n","            for j, idx in enumerate(ei):\n","                encoder_input_data[i, j] = idx\n","            for j, idx_di in enumerate(di):\n","                decoder_input_data[i, j] = idx_di\n","            for j, idx_dt in enumerate(dt):\n","                decoder_target_data[i, j, idx_dt] = 1       \n","                \n","        model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=params['batch_size'], epochs=params['epochs'], callbacks=callbacks, verbose=1)\n","            \n","    def predict(self, model, data, params={}):\n","        \n","        nb_samples = len(data)\n","        data_t = sample(data_tr, nb_samples)\n","        data_test = []\n","        predicted_out = []\n","        for samp in range(nb_samples):\n","            for inp, out in data_t:\n","                ind_enc_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in inp]\n","                ind_dec_in = [w2id[w] if w in w2id else w2id['<UNK>'] for w in out]\n","                data_test.append((ind_enc_in,ind_dec_in))\n","\n","\n","            encoder_input_data = np.zeros(shape=(1, params['max_encoder_len']))    \n","            decoder_input_data = np.zeros(shape=(1, params['max_decoder_len']))\n","\n","            for i, (ei, di) in enumerate(data_test):\n","                for j, idx in enumerate(ei):\n","                    encoder_input_data[i, j] = idx\n","                for j, idx_di in enumerate(di):\n","                    decoder_input_data[i, j] = idx_di\n","\n","            result = self.model.predict([encoder_input_data, decoder_input_data])\n","            for r, original in zip(result, data_t):\n","                original_sentence = original[0]\n","                idx = np.argmax(r, axis=1)\n","                print(idx)\n","                repr_out = []\n","                for ix in idx:\n","                    token = id2w[ix]\n","                    if token == '<EOS>':\n","                        break\n","                    else:\n","                        repr_out.append(token)\n","            predicted_out.append(repr_out)\n","        return predicted_out\n","                        \n","                        \n","    def load(self, model_path='seq2seq.h5'):\n","        return load_model(model_path)\n","    \n","    def _get_callbacks(self, model_path='seq2seq.h5'):\n","        es = EarlyStopping(monitor='loss', patience=20, mode='auto', verbose=1)\n","        save_best = ModelCheckpoint(model_path, monitor='loss', verbose = 1, save_best_only=True, save_weights_only=False, period=2)\n","        st = Sampletest()\n","        # hd = HistoryDisplay()\n","        rlr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n","              patience=5, min_lr=0.0001, verbose=1)\n","        return [st, rlr]"],"execution_count":56,"outputs":[]},{"metadata":{"id":"xujVkl70xKXO","colab_type":"text"},"cell_type":"markdown","source":["## Compile model definition"]},{"metadata":{"id":"wbgoZhQIxKXQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"8d44f9b7-14d3-4a9d-c574-c533881bb78c","executionInfo":{"status":"ok","timestamp":1531257380017,"user_tz":-120,"elapsed":580,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["compile_params = {\n","    'vocab': len(vocab),\n","    'emb_feats': 50,\n","    'hidden_size': 256,\n","    'target_size': len(vocab),\n","    'input_size': len(vocab),\n","    'max_encoder_len': maxlen+2,\n","    'max_decoder_len': maxlen+2    \n","}"],"execution_count":24,"outputs":[]},{"metadata":{"id":"PkdG6LOxxKXc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":420},"outputId":"aea9f483-78a5-4d79-b5c5-388600e87915","executionInfo":{"status":"ok","timestamp":1531258357677,"user_tz":-120,"elapsed":1161,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["s2s = Seq2Seq()\n","s2s_model = s2s.compile_basic_seq2seq(params=compile_params)    "],"execution_count":57,"outputs":[{"output_type":"stream","text":["(?, 256) (?, 256) (?, 256)\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","encoder_input (InputLayer)      (None, 8)            0                                            \n","__________________________________________________________________________________________________\n","decoder_input (InputLayer)      (None, 8)            0                                            \n","__________________________________________________________________________________________________\n","embedding_layer (Embedding)     (None, 8, 50)        5200        encoder_input[0][0]              \n","__________________________________________________________________________________________________\n","embedding_layer_decoder (Embedd (None, 8, 50)        5200        decoder_input[0][0]              \n","__________________________________________________________________________________________________\n","encoder (LSTM)                  [(None, 256), (None, 314368      embedding_layer[0][0]            \n","__________________________________________________________________________________________________\n","decoder (LSTM)                  [(None, 8, 256), (No 314368      embedding_layer_decoder[0][0]    \n","                                                                 encoder[0][1]                    \n","                                                                 encoder[0][2]                    \n","__________________________________________________________________________________________________\n","time_distributed_7 (TimeDistrib (None, 8, 104)       26728       decoder[0][0]                    \n","==================================================================================================\n","Total params: 665,864\n","Trainable params: 665,864\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"pLnTOi2ixKXj","colab_type":"text"},"cell_type":"markdown","source":["## Seq2Seq Train"]},{"metadata":{"id":"CjbIHENSxKXn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":7238},"outputId":"19646836-a56c-44f5-e5cc-70d25638b2cd","executionInfo":{"status":"error","timestamp":1531258425132,"user_tz":-120,"elapsed":66764,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["train_params = {\n","    'epochs': 1000,\n","    'batch_size': 32,\n","    'shuffle': True,\n","    'target_len': len(vocab),\n","    'max_encoder_len': maxlen +2,\n","    'max_decoder_len': maxlen +2\n","    \n","}\n","\n","s2s.train(model=s2s_model, data=data_train, params=train_params)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Epoch 1/1000\n","400/400 [==============================] - 2s 6ms/step - loss: 2.5118 - acc: 0.0875\n","Epoch 2/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.5086 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(1): ['<SOS>', 91, 92, 93, '<EOS>'] ====> \n","Epoch 3/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.5054 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(2): ['<SOS>', 18, 19, 20, '<EOS>'] ====> \n","Epoch 4/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.5021 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(3): ['<SOS>', 7, 8, 9, '<EOS>'] ====> \n","Epoch 5/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4989 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(4): ['<SOS>', 33, 34, 35, '<EOS>'] ====> \n","Epoch 6/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4957 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(5): ['<SOS>', 58, 59, 60, '<EOS>'] ====> \n","Epoch 7/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4924 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(6): ['<SOS>', 20, 21, 22, 23, '<EOS>'] ====> \n","Epoch 8/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4892 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(7): ['<SOS>', 44, 45, 46, 47, '<EOS>'] ====> \n","Epoch 9/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4860 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(8): ['<SOS>', 20, 21, 22, 23, '<EOS>'] ====> \n","Epoch 10/1000\n","192/400 [=============>................] - ETA: 0s - loss: 2.4826 - acc: 0.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"],"name":"stdout"},{"output_type":"stream","text":["400/400 [==============================] - 1s 2ms/step - loss: 2.4828 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(9): ['<SOS>', 34, 35, 36, 37, '<EOS>'] ====> \n","Epoch 11/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4796 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(10): ['<SOS>', 46, 47, 48, 49, '<EOS>'] ====> \n","Epoch 12/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4763 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(11): ['<SOS>', 7, 8, 9, 10, '<EOS>'] ====> \n","Epoch 13/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4731 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(12): ['<SOS>', 92, 93, 94, '<EOS>'] ====> \n","Epoch 14/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4699 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(13): ['<SOS>', 14, 15, 16, 17, '<EOS>'] ====> \n","Epoch 15/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4666 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(14): ['<SOS>', 20, 21, 22, '<EOS>'] ====> \n","Epoch 16/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4634 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(15): ['<SOS>', 61, 62, 63, 64, '<EOS>'] ====> \n","Epoch 17/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4602 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(16): ['<SOS>', 45, 46, 47, 48, '<EOS>'] ====> \n","Epoch 18/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4569 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(17): ['<SOS>', 64, 65, 66, '<EOS>'] ====> \n","Epoch 19/1000\n","128/400 [========>.....................] - ETA: 0s - loss: 2.4084 - acc: 0.1250"],"name":"stdout"},{"output_type":"stream","text":["400/400 [==============================] - 1s 2ms/step - loss: 2.4537 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(18): ['<SOS>', 98, 99, '<EOS>'] ====> \n","Epoch 20/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4504 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(19): ['<SOS>', 73, 74, 75, '<EOS>'] ====> \n","Epoch 21/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4471 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(20): ['<SOS>', 58, 59, 60, 61, '<EOS>'] ====> \n","Epoch 22/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4438 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(21): ['<SOS>', 39, 40, 41, '<EOS>'] ====> \n","Epoch 23/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4405 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(22): ['<SOS>', 66, 67, 68, 69, '<EOS>'] ====> \n","Epoch 24/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4372 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(23): ['<SOS>', 63, 64, 65, '<EOS>'] ====> \n","Epoch 25/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4339 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(24): ['<SOS>', 21, 22, 23, '<EOS>'] ====> \n","Epoch 26/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4306 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(25): ['<SOS>', 9, 10, 11, '<EOS>'] ====> \n","Epoch 27/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4272 - acc: 0.1250\n"],"name":"stdout"},{"output_type":"stream","text":["[101 101 101 101 101 101 101 101]\n","Test Sample epoch(26): ['<SOS>', 77, 78, 79, 80, '<EOS>'] ====> \n","Epoch 28/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4239 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(27): ['<SOS>', 34, 35, 36, 37, '<EOS>'] ====> \n","Epoch 29/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4205 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(28): ['<SOS>', 39, 40, 41, 42, '<EOS>'] ====> \n","Epoch 30/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4172 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(29): ['<SOS>', 28, 29, 30, 31, '<EOS>'] ====> \n","Epoch 31/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4138 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(30): ['<SOS>', 44, 45, 46, 47, '<EOS>'] ====> \n","Epoch 32/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4103 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(31): ['<SOS>', 50, 51, 52, 53, '<EOS>'] ====> \n","Epoch 33/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4069 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(32): ['<SOS>', 60, 61, 62, 63, '<EOS>'] ====> \n","Epoch 34/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4035 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(33): ['<SOS>', 9, 10, 11, '<EOS>'] ====> \n","Epoch 35/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.4000 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(34): ['<SOS>', 63, 64, 65, '<EOS>'] ====> \n","Epoch 36/1000\n"," 64/400 [===>..........................] - ETA: 0s - loss: 2.4880 - acc: 0.1250"],"name":"stdout"},{"output_type":"stream","text":["400/400 [==============================] - 1s 2ms/step - loss: 2.3965 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(35): ['<SOS>', 82, 83, 84, '<EOS>'] ====> \n","Epoch 37/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3930 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(36): ['<SOS>', 31, 32, 33, 34, '<EOS>'] ====> \n","Epoch 38/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3895 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(37): ['<SOS>', 34, 35, 36, 37, '<EOS>'] ====> \n","Epoch 39/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3859 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(38): ['<SOS>', 97, 98, 99, '<EOS>'] ====> \n","Epoch 40/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3824 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(39): ['<SOS>', 34, 35, 36, '<EOS>'] ====> \n","Epoch 41/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3788 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(40): ['<SOS>', 48, 49, 50, '<EOS>'] ====> \n","Epoch 42/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3751 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(41): ['<SOS>', 30, 31, 32, 33, '<EOS>'] ====> \n","Epoch 43/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3715 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(42): ['<SOS>', 80, 81, 82, '<EOS>'] ====> \n","Epoch 44/1000\n","384/400 [===========================>..] - ETA: 0s - loss: 2.3652 - acc: 0.1250"],"name":"stdout"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r400/400 [==============================] - 1s 2ms/step - loss: 2.3678 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(43): ['<SOS>', 19, 20, 21, 22, '<EOS>'] ====> \n","Epoch 45/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3642 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(44): ['<SOS>', 98, 99, '<EOS>'] ====> \n","Epoch 46/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3604 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(45): ['<SOS>', 78, 79, 80, 81, '<EOS>'] ====> \n","Epoch 47/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3567 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(46): ['<SOS>', 94, 95, 96, '<EOS>'] ====> \n","Epoch 48/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3529 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(47): ['<SOS>', 29, 30, 31, '<EOS>'] ====> \n","Epoch 49/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3491 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(48): ['<SOS>', 0, 1, 2, '<EOS>'] ====> \n","Epoch 50/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3453 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(49): ['<SOS>', 21, 22, 23, 24, '<EOS>'] ====> \n","Epoch 51/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3415 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(50): ['<SOS>', 72, 73, 74, 75, '<EOS>'] ====> \n","Epoch 52/1000\n","224/400 [===============>..............] - ETA: 0s - loss: 2.3489 - acc: 0.1250"],"name":"stdout"},{"output_type":"stream","text":["400/400 [==============================] - 1s 2ms/step - loss: 2.3376 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(51): ['<SOS>', 54, 55, 56, '<EOS>'] ====> \n","Epoch 53/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3337 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(52): ['<SOS>', 52, 53, 54, 55, '<EOS>'] ====> \n","Epoch 54/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3298 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(53): ['<SOS>', 65, 66, 67, '<EOS>'] ====> \n","Epoch 55/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3258 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(54): ['<SOS>', 30, 31, 32, '<EOS>'] ====> \n","Epoch 56/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3219 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(55): ['<SOS>', 81, 82, 83, '<EOS>'] ====> \n","Epoch 57/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3179 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(56): ['<SOS>', 1, 2, 3, 4, '<EOS>'] ====> \n","Epoch 58/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3138 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(57): ['<SOS>', 24, 25, 26, '<EOS>'] ====> \n","Epoch 59/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3098 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(58): ['<SOS>', 22, 23, 24, '<EOS>'] ====> \n","Epoch 60/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3057 - acc: 0.1250\n"],"name":"stdout"},{"output_type":"stream","text":["[101 101 101 101 101 101 101 101]\n","Test Sample epoch(59): ['<SOS>', 57, 58, 59, '<EOS>'] ====> \n","Epoch 61/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.3016 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(60): ['<SOS>', 42, 43, 44, '<EOS>'] ====> \n","Epoch 62/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2975 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(61): ['<SOS>', 31, 32, 33, 34, '<EOS>'] ====> \n","Epoch 63/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2934 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(62): ['<SOS>', 25, 26, 27, 28, '<EOS>'] ====> \n","Epoch 64/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2893 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(63): ['<SOS>', 75, 76, 77, 78, '<EOS>'] ====> \n","Epoch 65/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2851 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(64): ['<SOS>', 76, 77, 78, 79, '<EOS>'] ====> \n","Epoch 66/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2810 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(65): ['<SOS>', 40, 41, 42, '<EOS>'] ====> \n","Epoch 67/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2768 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(66): ['<SOS>', 23, 24, 25, 26, '<EOS>'] ====> \n","Epoch 68/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2727 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(67): ['<SOS>', 11, 12, 13, '<EOS>'] ====> \n","Epoch 69/1000\n"," 64/400 [===>..........................] - ETA: 0s - loss: 2.3140 - acc: 0.1250"],"name":"stdout"},{"output_type":"stream","text":["400/400 [==============================] - 1s 2ms/step - loss: 2.2685 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(68): ['<SOS>', 85, 86, 87, 88, '<EOS>'] ====> \n","Epoch 70/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2643 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(69): ['<SOS>', 5, 6, 7, 8, '<EOS>'] ====> \n","Epoch 71/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2602 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(70): ['<SOS>', 44, 45, 46, '<EOS>'] ====> \n","Epoch 72/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2561 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(71): ['<SOS>', 74, 75, 76, '<EOS>'] ====> \n","Epoch 73/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2520 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(72): ['<SOS>', 68, 69, 70, '<EOS>'] ====> \n","Epoch 74/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2479 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(73): ['<SOS>', 31, 32, 33, 34, '<EOS>'] ====> \n","Epoch 75/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2439 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(74): ['<SOS>', 5, 6, 7, '<EOS>'] ====> \n","Epoch 76/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2399 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(75): ['<SOS>', 17, 18, 19, '<EOS>'] ====> \n","Epoch 77/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2360 - acc: 0.1250\n"],"name":"stdout"},{"output_type":"stream","text":["[101 101 101 101 101 101 101 101]\n","Test Sample epoch(76): ['<SOS>', 60, 61, 62, '<EOS>'] ====> \n","Epoch 78/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2321 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(77): ['<SOS>', 97, 98, 99, '<EOS>'] ====> \n","Epoch 79/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2283 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(78): ['<SOS>', 80, 81, 82, '<EOS>'] ====> \n","Epoch 80/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2246 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(79): ['<SOS>', 32, 33, 34, '<EOS>'] ====> \n","Epoch 81/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2210 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(80): ['<SOS>', 66, 67, 68, 69, '<EOS>'] ====> \n","Epoch 82/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2174 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(81): ['<SOS>', 24, 25, 26, '<EOS>'] ====> \n","Epoch 83/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2140 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(82): ['<SOS>', 7, 8, 9, '<EOS>'] ====> \n","Epoch 84/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2106 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(83): ['<SOS>', 10, 11, 12, 13, '<EOS>'] ====> \n","Epoch 85/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2074 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(84): ['<SOS>', 94, 95, 96, '<EOS>'] ====> \n","Epoch 86/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2043 - acc: 0.1250\n"],"name":"stdout"},{"output_type":"stream","text":["[101 101 101 101 101 101 101 101]\n","Test Sample epoch(85): ['<SOS>', 79, 80, 81, '<EOS>'] ====> \n","Epoch 87/1000\n","400/400 [==============================] - 1s 2ms/step - loss: 2.2013 - acc: 0.1250\n","[101 101 101 101 101 101 101 101]\n","Test Sample epoch(86): ['<SOS>', 65, 66, 67, 68, '<EOS>'] ====> \n","Epoch 88/1000\n","288/400 [====================>.........] - ETA: 0s - loss: 2.1770 - acc: 0.1250"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-108bae716435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms2s_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-56-e0dd5c26240c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, data, params)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_dt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"sUbRwAzyxKXt","colab_type":"text"},"cell_type":"markdown","source":["## Predict"]},{"metadata":{"id":"1WZ7Nd0MxKXu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"3c4dd757-bd17-43b7-d5fc-6ea2e12006a0","executionInfo":{"status":"ok","timestamp":1531219813746,"user_tz":-120,"elapsed":590,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":["predict_params = {\n","            'max_encoder_len': maxlen + 2,\n","            'max_decoder_len': maxlen + 2,\n","            'target_len': len(vocab)\n","            }\n","\n","s2s.predict(model=s2s_model, data=['', ''], params=predict_params)\n","\n","# data tiene que ser una lista de esas predicciones que quereis hacer. Fijaros en la implementación de Sampletest más arriba"],"execution_count":1,"outputs":[]},{"metadata":{"id":"zRwH09lPxKXx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"a11d3eb3-f122-4d39-b4bd-486d82e199bd","executionInfo":{"status":"ok","timestamp":1531219815061,"user_tz":-120,"elapsed":566,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[""],"execution_count":1,"outputs":[]},{"metadata":{"id":"7tGij_2YxKX0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"4e870a6b-dd89-474e-a1c6-e0ac799d570a","executionInfo":{"status":"ok","timestamp":1531219816075,"user_tz":-120,"elapsed":567,"user":{"displayName":"David Torrejon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100674754889499666756"}}},"cell_type":"code","source":[""],"execution_count":1,"outputs":[]}]}