{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PracticaNLP-Problema1.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"pRJ7fiaDYMqo","colab_type":"text"},"cell_type":"markdown","source":["# Introducción \n","\n","La idea de la práctica es visitar aquellos temas que en cierta manera nos permitan ver más contenido del curso.\n","\n","La práctica esta dividida en 4 o 5 subapartados, que ya tenéis en este mismo Notebook. Estos subapartados estan aquí para que rellenéis el código que hace falta para la realización de la práctica. Obviamente podéis usar tantas celdas como os hagan falta, es más es de agradecer si el código final esta algo \"limpio\". Usar funciones, algo de comentario, etc, etc...\n","\n","Usaremos 2 datasets, uno para el primer ejercicio, y otro para el resto de ejercicios.\n","\n","Ejercicios:\n","\n","\n","1.   Machine Learning vs Deep Learning (Acordaros que hay que implementar el pipeline visto en clase entero)\n","\n","    1.1. Implementación de un modelo de Sentiment Analysis con algún algoritmo de Machine Learning Clásico.\n","    \n","    1.2. Implementación de un modelo de Sentiment Analysis con alguna arquitectura de Deep Learning.\n","    \n","    1.3. Breve Comparación de resultados. Confusion Matrix.\n","    \n","2. Hacer Analysis de los tweets del segundo dataset. Que temas aparecen? Como se representan estos temas? De que hablan unos y otros?\n","\n","3. Escoged a uno de los dos presidentes, y escribid tweets como ellos, usando un Modelo Generativo.\n","\n","En cada ejercicio, espero explicaciones y razonamientos del porque una arquitectura y no otra, por ejemplo en Deep Learning, porque usar Convolutionals en lugar de recurrentes, o en Machine Learning, Bayes en lugar de SVM. Hay que explicar el pipeline, sobretodo el preproceso de datos, con lo que habrá que hacer un pequeño estudio de que datos tenemos, y si hay cosas que se pueden ignorar, si hacéis stemming, o no, etc, etc...\n","\n","Acordaros de que objetivo final no es que obtengáis una accuracy brutal, es que comprendais que pasa cuando usais un algoritmo u otro, y que problemas o beneficios nos dan.\n","\n","![](https://i.pinimg.com/736x/19/63/8c/19638c0b33e2f7822d6806ce31d89d84--funny-cartoons-funny-jokes.jpg =400x)\n","\n","Mucha suerte y ánimo!\n","\n"]},{"metadata":{"id":"Vv5r61Xb7HI4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Instalaciones necesarias\n","!pip install spacy\n","!python -m spacy download en_core_web_md\n","!pip install networkx==1.11 # para instala hyperopt correctamente, si no, da errores\n","!pip install hyperopt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iS_2mYfn7T4K","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import spacy\n","from google.colab import files\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from keras.layers import Conv1D, Conv2D, SimpleRNN, LSTM, Dense, Dropout\n","from keras.models import Sequential\n","from keras.layers import Embedding\n","from keras.layers import Flatten, Input\n","from keras.models import Model\n","from keras.layers import Input, Average, average, Lambda\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from keras.callbacks import EarlyStopping\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","import sys\n","import time\n","from keras.layers import MaxPooling1D, GlobalMaxPooling1D\n","from keras.layers import Input, Embedding, Concatenate\n","from keras.models import Model\n","from collections import Counter\n","\n","\n","\n","nlp = spacy.load('en_core_web_md')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WMESTLF1YMyO","colab_type":"text"},"cell_type":"markdown","source":["# Dataset\n","\n","Breve explicación del dataset"]},{"metadata":{"id":"nHZSaUfsYM0z","colab_type":"text"},"cell_type":"markdown","source":["# Práctica/Código a entregar"]},{"metadata":{"id":"jPw8jkZDYvqx","colab_type":"text"},"cell_type":"markdown","source":["## Pre-train Sentiment Analysis Model"]},{"metadata":{"id":"Evszh16eYvxF","colab_type":"text"},"cell_type":"markdown","source":["## Sentiment Analysis with Politics"]},{"metadata":{"id":"bvMjfdw5ZrUN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"outputId":"d1985d2a-2af1-42dc-a42a-1ae782de1298","executionInfo":{"status":"ok","timestamp":1532095966341,"user_tz":-120,"elapsed":69424,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-51e3fc4b-15d8-4a59-8444-6762f2a31e9e\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-51e3fc4b-15d8-4a59-8444-6762f2a31e9e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving train_sentiment_utf8.csv to train_sentiment_utf8.csv\n"],"name":"stdout"}]},{"metadata":{"id":"A1mZnRMZ74KH","colab_type":"text"},"cell_type":"markdown","source":["### Realizamos un primer análisis de los textos sin procesarlos"]},{"metadata":{"id":"H4QzdsKCcjJv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Cargamos el fichero en un dataframe de pandas para analizarlo\n","df = pd.read_csv('train_sentiment_utf8.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yEY_ULy2eisM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":359},"outputId":"9627ebd8-c1fd-4751-fcec-63ab839cfd75","executionInfo":{"status":"ok","timestamp":1532023473673,"user_tz":-120,"elapsed":379,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["#Revisamos visualmente el conteniddo del fichero\n","df.head(10)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ItemID</th>\n","      <th>Sentiment</th>\n","      <th>SentimentText</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>is so sad for my APL frie...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>I missed the New Moon trail...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>omg its already 7:30 :O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>i think mi bf is cheating on me!!!   ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>or i just worry too much?</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>Sunny Again        Work Tomorrow  :-|  ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>handed in my uniform today . i miss you ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>hmmmm.... i wonder how she my number @-)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ItemID  Sentiment                                      SentimentText\n","0       1          0                       is so sad for my APL frie...\n","1       2          0                     I missed the New Moon trail...\n","2       3          1                            omg its already 7:30 :O\n","3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n","4       5          0           i think mi bf is cheating on me!!!   ...\n","5       6          0                  or i just worry too much?        \n","6       7          1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n","7       8          0         Sunny Again        Work Tomorrow  :-|  ...\n","8       9          1        handed in my uniform today . i miss you ...\n","9      10          1           hmmmm.... i wonder how she my number @-)"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"_XTSbKKGfW9p","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":68},"outputId":"5c78ae9f-11c1-468d-d385-adc3508b009e","executionInfo":{"status":"ok","timestamp":1532023474125,"user_tz":-120,"elapsed":366,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["df['Sentiment'].value_counts()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    56457\n","0    43532\n","Name: Sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"fsltYaT4f0lJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["words = set()\n","for x in df['SentimentText']:\n","  for w in x.strip().split(' '):\n","    words.add(w.strip())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oiPkZze-ox3O","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"947badbc-90ef-46dd-cdf7-64be4dcaa533","executionInfo":{"status":"ok","timestamp":1532023476109,"user_tz":-120,"elapsed":419,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["len(words)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["183641"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"ZzYJU7068T7Y","colab_type":"text"},"cell_type":"markdown","source":["### Primeras observaciones\n","\n","Los datos estan balanceados   \n","Sentiment  \n","1    56457  \n","0    43532  \n","\n","ItemID no nos aporta nada\n","\n","El lenguaje es ingles, podremos utilizar un modelo de spacy en ingles para procesarlo\n","\n","Podemos ver que hay muchos caracteres y simbolos de puntuació que eliminaremos para hacerle el trabajo mas facil al algoritmo\n","\n","Tamaño de nuestro vocabulario 183641 palabras antes de limpiarlo\n"]},{"metadata":{"id":"BPrAr5rKpnO5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["wordsP = []\n","for x in df[df['Sentiment']==1]['SentimentText']:\n","  for w in x.strip().split(' '):\n","    wordsP.append(w.strip())\n","    \n","wordsN = []\n","for x in df[df['Sentiment']==0]['SentimentText']:\n","  for w in x.strip().split(' '):\n","    wordsN.append(w.strip())\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cAJIklMwpnFy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":669},"outputId":"0db7c270-4bed-49bc-d103-dd061373132c","executionInfo":{"status":"ok","timestamp":1532023477905,"user_tz":-120,"elapsed":783,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["# revisamos las palabras mas repetidas en los sentimientos positivos, las que mas aparecen son palabras \n","# muy comunes en ambos casos que no nos van a ayudar a diferenciar por eso inspeccionamos un poco mas abajo \n","pd.DataFrame(wordsP)[0].value_counts().to_frame()[30:50]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>love</th>\n","      <td>2636</td>\n","    </tr>\n","    <tr>\n","      <th>at</th>\n","      <td>2395</td>\n","    </tr>\n","    <tr>\n","      <th>u</th>\n","      <td>2365</td>\n","    </tr>\n","    <tr>\n","      <th>get</th>\n","      <td>2318</td>\n","    </tr>\n","    <tr>\n","      <th>not</th>\n","      <td>2311</td>\n","    </tr>\n","    <tr>\n","      <th>all</th>\n","      <td>2168</td>\n","    </tr>\n","    <tr>\n","      <th>do</th>\n","      <td>2123</td>\n","    </tr>\n","    <tr>\n","      <th>can</th>\n","      <td>2058</td>\n","    </tr>\n","    <tr>\n","      <th>will</th>\n","      <td>2037</td>\n","    </tr>\n","    <tr>\n","      <th>this</th>\n","      <td>1972</td>\n","    </tr>\n","    <tr>\n","      <th>up</th>\n","      <td>1931</td>\n","    </tr>\n","    <tr>\n","      <th>know</th>\n","      <td>1871</td>\n","    </tr>\n","    <tr>\n","      <th>we</th>\n","      <td>1798</td>\n","    </tr>\n","    <tr>\n","      <th>if</th>\n","      <td>1675</td>\n","    </tr>\n","    <tr>\n","      <th>about</th>\n","      <td>1660</td>\n","    </tr>\n","    <tr>\n","      <th>what</th>\n","      <td>1654</td>\n","    </tr>\n","    <tr>\n","      <th>as</th>\n","      <td>1643</td>\n","    </tr>\n","    <tr>\n","      <th>see</th>\n","      <td>1628</td>\n","    </tr>\n","    <tr>\n","      <th>out</th>\n","      <td>1621</td>\n","    </tr>\n","    <tr>\n","      <th>it's</th>\n","      <td>1619</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0\n","love   2636\n","at     2395\n","u      2365\n","get    2318\n","not    2311\n","all    2168\n","do     2123\n","can    2058\n","will   2037\n","this   1972\n","up     1931\n","know   1871\n","we     1798\n","if     1675\n","about  1660\n","what   1654\n","as     1643\n","see    1628\n","out    1621\n","it's   1619"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"1QqJm7YDveAm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":669},"outputId":"5449d9c1-3a32-432b-8303-f5163a926bbb","executionInfo":{"status":"ok","timestamp":1532023478695,"user_tz":-120,"elapsed":741,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["pd.DataFrame(wordsN)[0].value_counts().to_frame()[30:50]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>are</th>\n","      <td>2022</td>\n","    </tr>\n","    <tr>\n","      <th>this</th>\n","      <td>1956</td>\n","    </tr>\n","    <tr>\n","      <th>u</th>\n","      <td>1829</td>\n","    </tr>\n","    <tr>\n","      <th>all</th>\n","      <td>1826</td>\n","    </tr>\n","    <tr>\n","      <th>don't</th>\n","      <td>1822</td>\n","    </tr>\n","    <tr>\n","      <th>your</th>\n","      <td>1816</td>\n","    </tr>\n","    <tr>\n","      <th>go</th>\n","      <td>1760</td>\n","    </tr>\n","    <tr>\n","      <th>up</th>\n","      <td>1733</td>\n","    </tr>\n","    <tr>\n","      <th>out</th>\n","      <td>1729</td>\n","    </tr>\n","    <tr>\n","      <th>do</th>\n","      <td>1629</td>\n","    </tr>\n","    <tr>\n","      <th>-</th>\n","      <td>1629</td>\n","    </tr>\n","    <tr>\n","      <th>know</th>\n","      <td>1601</td>\n","    </tr>\n","    <tr>\n","      <th>too</th>\n","      <td>1567</td>\n","    </tr>\n","    <tr>\n","      <th>miss</th>\n","      <td>1503</td>\n","    </tr>\n","    <tr>\n","      <th>about</th>\n","      <td>1499</td>\n","    </tr>\n","    <tr>\n","      <th>got</th>\n","      <td>1458</td>\n","    </tr>\n","    <tr>\n","      <th>we</th>\n","      <td>1458</td>\n","    </tr>\n","    <tr>\n","      <th>now</th>\n","      <td>1425</td>\n","    </tr>\n","    <tr>\n","      <th>had</th>\n","      <td>1399</td>\n","    </tr>\n","    <tr>\n","      <th>can't</th>\n","      <td>1390</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0\n","are    2022\n","this   1956\n","u      1829\n","all    1826\n","don't  1822\n","your   1816\n","go     1760\n","up     1733\n","out    1729\n","do     1629\n","-      1629\n","know   1601\n","too    1567\n","miss   1503\n","about  1499\n","got    1458\n","we     1458\n","now    1425\n","had    1399\n","can't  1390"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"JElDtoA68p-S","colab_type":"text"},"cell_type":"markdown","source":["En un primer vistazo rapido vemos que palabras componen cada uno de los grupos"]},{"metadata":{"id":"xJ-IRxev9GmW","colab_type":"text"},"cell_type":"markdown","source":["### Procesamiento de la entrada\n","En primer lugar vamos a procesar con spaCy los textos para dividirlo en Tokens, vamos a sacar los lemas para reducir el vocabulario y eiminar signos de puntuación\n","\n","En este caso vamos a optar por eliminar todas las palabras que no esten en el vocabulario de spacy, la mayoría siguen los siguienes patrones de palabras\n","* http://myloc.me/27hx   \n","* @shaunamanu  \n","* Palabras mal escritas  \n","* Palabras inexistentes  \n","\n","Para el caso de las palabras mal scritas se podría utilizar un corrector ortografico tipo hunspell para obtener la palabra mas cercana.\n","\n","\n","\n","\n"]},{"metadata":{"id":"Z9TOaZZU70HE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def f(row):\n","  doc_t = nlp(row['SentimentText'])\n","  text = \"\"\n","  for t in doc_t:\n","    if not t.is_punct and not t.is_oov:\n","      text = text + \" \" + t.lemma_\n","  return text\n","\n","df['cleanText'] = df.apply(f, axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ntXfc3dJHnhB","colab_type":"text"},"cell_type":"markdown","source":["Volvemos a estudiar el texto resultado"]},{"metadata":{"id":"dre97LREHmoJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":669},"outputId":"fd3098e7-1ee7-4ddf-e946-b51388fbfb03","executionInfo":{"status":"ok","timestamp":1532099376438,"user_tz":-120,"elapsed":1544,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["df.head(20)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ItemID</th>\n","      <th>Sentiment</th>\n","      <th>SentimentText</th>\n","      <th>cleanText</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>is so sad for my APL frie...</td>\n","      <td>be so sad for -PRON- ap...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>I missed the New Moon trail...</td>\n","      <td>-PRON- miss the new moon ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>omg its already 7:30 :O</td>\n","      <td>omg -PRON- already 7:30 :o</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n","      <td>-PRON- be sooo   -PRON- be gunna -...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>i think mi bf is cheating on me!!!   ...</td>\n","      <td>i think mi bf be cheat on -PRON-   ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>or i just worry too much?</td>\n","      <td>or i just worry too much</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n","      <td>chillin</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>Sunny Again        Work Tomorrow  :-|  ...</td>\n","      <td>sunny again         work tomorrow   :...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>handed in my uniform today . i miss you ...</td>\n","      <td>hand in -PRON- uniform today i miss -P...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>hmmmm.... i wonder how she my number @-)</td>\n","      <td>hmmmm i wonder how -PRON- -PRON-</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>I must think about positive..</td>\n","      <td>-PRON- must think about positive</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>thanks to all the haters up in my face a...</td>\n","      <td>thank to all the hater up in -PRON- fa...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>this weekend has sucked so far</td>\n","      <td>this weekend have suck so far</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>jb isnt showing in australia any more!</td>\n","      <td>jb be not show in australia any more</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>ok thats it you win.</td>\n","      <td>ok that s -PRON- -PRON- win</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>&amp;lt;-------- This is the way i feel right ...</td>\n","      <td>this be the way i feel right now</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>awhhe man.... I'm completely useless rt no...</td>\n","      <td>man -PRON- be completely useless rt now ...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>Feeling strangely fine. Now I'm gonna go l...</td>\n","      <td>feel strangely fine now -PRON- be go to ...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>HUGE roll of thunder just now...SO scary!!!!</td>\n","      <td>huge roll of thunder just now so scary</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>I just cut my beard off. It's only been gr...</td>\n","      <td>-PRON- just cut -PRON- beard off -PRON- ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    ItemID  Sentiment                                      SentimentText  \\\n","0        1          0                       is so sad for my APL frie...   \n","1        2          0                     I missed the New Moon trail...   \n","2        3          1                            omg its already 7:30 :O   \n","3        4          0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n","4        5          0           i think mi bf is cheating on me!!!   ...   \n","5        6          0                  or i just worry too much?           \n","6        7          1                 Juuuuuuuuuuuuuuuuussssst Chillin!!   \n","7        8          0         Sunny Again        Work Tomorrow  :-|  ...   \n","8        9          1        handed in my uniform today . i miss you ...   \n","9       10          1           hmmmm.... i wonder how she my number @-)   \n","10      11          0                      I must think about positive..   \n","11      12          1        thanks to all the haters up in my face a...   \n","12      13          0                     this weekend has sucked so far   \n","13      14          0             jb isnt showing in australia any more!   \n","14      15          0                               ok thats it you win.   \n","15      16          0      &lt;-------- This is the way i feel right ...   \n","16      17          0      awhhe man.... I'm completely useless rt no...   \n","17      18          1      Feeling strangely fine. Now I'm gonna go l...   \n","18      19          0       HUGE roll of thunder just now...SO scary!!!!   \n","19      20          0      I just cut my beard off. It's only been gr...   \n","\n","                                            cleanText  \n","0                          be so sad for -PRON- ap...  \n","1                        -PRON- miss the new moon ...  \n","2                          omg -PRON- already 7:30 :o  \n","3               -PRON- be sooo   -PRON- be gunna -...  \n","4              i think mi bf be cheat on -PRON-   ...  \n","5                    or i just worry too much          \n","6                                             chillin  \n","7            sunny again         work tomorrow   :...  \n","8           hand in -PRON- uniform today i miss -P...  \n","9                    hmmmm i wonder how -PRON- -PRON-  \n","10                   -PRON- must think about positive  \n","11          thank to all the hater up in -PRON- fa...  \n","12                      this weekend have suck so far  \n","13               jb be not show in australia any more  \n","14                        ok that s -PRON- -PRON- win  \n","15                   this be the way i feel right now  \n","16        man -PRON- be completely useless rt now ...  \n","17        feel strangely fine now -PRON- be go to ...  \n","18             huge roll of thunder just now so scary  \n","19        -PRON- just cut -PRON- beard off -PRON- ...  "]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"HW-rxk0Q70D3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"973784b6-49ec-42f2-9f7d-eeb9a427a53d","executionInfo":{"status":"ok","timestamp":1532099463447,"user_tz":-120,"elapsed":1067,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["words = set()\n","for x in df['cleanText']:\n","  for w in x.strip().split(' '):\n","    words.add(w.strip())\n","len(words)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33925"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"9uVaMcvSW-XI","colab_type":"text"},"cell_type":"markdown","source":["Podemos ver que el vocabulario es mucho menor que era"]},{"metadata":{"id":"gWs5qLjrM08B","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Guardo y descargo el texto generado para no tener que volver a ejecutarlo\n","df.to_csv('sentiment.csv')\n","files.download('sentiment.csv') \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mVBQppWqX9P6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"outputId":"10125950-6bfd-41e3-95c2-413ac692dede","executionInfo":{"status":"ok","timestamp":1532155251521,"user_tz":-120,"elapsed":141010,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["uploaded = files.upload()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-38925477-3c95-41b3-943e-8dd882e357d5\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-38925477-3c95-41b3-943e-8dd882e357d5\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving sentiment.csv to sentiment.csv\n"],"name":"stdout"}]},{"metadata":{"id":"vxH9h2dzkEEu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["df = pd.read_csv('sentiment.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BzsO6k14X88U","colab_type":"text"},"cell_type":"markdown","source":["### Dividimos los datos de entrenamiento en train y test"]},{"metadata":{"id":"mEzJhStaX_Sr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def split_train_val_test(dataset, split=0.2):\n","\n","    x, y = zip(*dataset)\n","    x = np.array(list(x))\n","    y = np.array(list(y))\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=split, random_state=1337) #l33t seed\n","    for train_index, test_index in sss.split(x, y):\n","        x_train, x_val = x[train_index], x[test_index]\n","        y_train, y_val = y[train_index], y[test_index]\n","    splits = {'train':(x_train, y_train), 'test':(x_val, y_val)}\n","    return splits\n","\n","subset = df[['cleanText','Sentiment']]\n","tuples = [tuple(x) for x in subset.values]\n","split = split_train_val_test(tuples)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q-YLDMXNXU7X","colab_type":"text"},"cell_type":"markdown","source":["## Entrenamiento de algoritmos\n","\n","A continuación pasamos a entrenar los algoritmos con los textos procesados  \n","Vamos a probar 2 algoritmos, Bayes y SVM y trataremos de optimizarlos a ver cual da mejores resultados.\n","\n","Comenzamos por Bayes"]},{"metadata":{"id":"ZXhNrO0wxBjI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Preparamos el pipeline de procesamiento\n","pipeline = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('clf', MultinomialNB())\n","])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"el0vFfyff0T5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["parameters = {\n","    'vect__strip_accents': ['ascii'], #Tartamos los acentos\n","    'vect__analyzer': ['word'], # Analizamos a nivel de palabra\n","    'vect__ngram_range': ((1, 3), (2,3) , (1,4)), # Probamos diferentes randos de n-grams\n","    'vect__stop_words': [None], #Probamos con las stop words por defecto en ingles o sin stop words\n","    'vect__lowercase': [True], # Se pasa todo a minusculas\n","    'vect__max_df': (0.80, 0.9, 0.95), # Probamos en un caso a quitar las palabras mas repetidas para hacer un stopr words especifico de este dataset\n","    'clf__alpha': (1.0, 0.95, 0.90)\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KW7Jwot2Y4Cj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"e5a65a89-7763-4f0e-e546-d22a1e63a04f","executionInfo":{"status":"ok","timestamp":1532102762378,"user_tz":-120,"elapsed":729616,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["grid_search = GridSearchCV(pipeline, parameters, verbose=1)\n","grid_search.fit(split['train'][0], split['train'][1])\n","best_parameters = grid_search.best_estimator_.get_params()\n","for param_name in sorted(parameters.keys()):\n","    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n","print(\"Best score: %0.3f\" % grid_search.best_score_)\n","\n","# evaluamos en test\n","pipeline.set_params(**best_parameters)\n","predictions = pipeline.score(split['test'][0], split['test'][1])\n","print('TEST SCORE: {}'.format(predictions))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed: 12.0min finished\n"],"name":"stderr"},{"output_type":"stream","text":["\tclf__alpha: 1.0\n","\tvect__analyzer: 'word'\n","\tvect__lowercase: True\n","\tvect__max_df: 0.8\n","\tvect__ngram_range: (1, 3)\n","\tvect__stop_words: None\n","\tvect__strip_accents: 'ascii'\n","Best score: 0.759\n","TEST SCORE: 0.7608260826082608\n"],"name":"stdout"}]},{"metadata":{"id":"JfNeg12ndaZT","colab_type":"text"},"cell_type":"markdown","source":["[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed: 12.0min finished   \n","\n","\tclf__alpha: 1.0\n","\tvect__analyzer: 'word'\n","\tvect__lowercase: True\n","\tvect__max_df: 0.8\n","\tvect__ngram_range: (1, 3)\n","\tvect__stop_words: None\n","\tvect__strip_accents: 'ascii'\n","Best train score: 0.759  \n","TEST SCORE: 0.7608260826082608"]},{"metadata":{"id":"8kuxVXXX6vsj","colab_type":"text"},"cell_type":"markdown","source":["A continuación pasamos a evaluar SVM a ver como se comporta para este caso.   \n","Incorporamos al pipe un scaler que es recomendable para este algoritmo.  \n","El problema de SVM es que tarda mucho en entrenarse, por lo que no podemos hacer gran numero de pruebas, por lo que dejamos el kernel rbf, dejamos los mejores parametros obtenidos con el otro algoritmo y probamos con parámetros especificos de este algoritmo"]},{"metadata":{"id":"FKZPDlq71NH3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","\n","pipeline = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('scaler', StandardScaler(with_mean=False)),\n","    ('svc', SVC())\n","])\n","\n","parameters = {\n","    'vect__strip_accents': ['ascii'], #Tartamos los acentos\n","    'vect__analyzer': ['word'], # Analizamos a nivel de palabra\n","    'vect__ngram_range': [(1, 3)], # Probamos diferentes randos de n-grams\n","    'vect__stop_words': [None], #Probamos con las stop words por defecto en ingles o sin stop words\n","    'vect__lowercase': [True], # Se pasa todo a minusculas\n","    'vect__max_df': [0.80], # Probamos en un caso a quitar las palabras mas repetidas para hacer un stopr words especifico de este dataset\n","    'svc__max_iter': [150, 300],\n","    'svc__C': np.logspace(-2, 1, 4),\n","    'svc__gamma':np.logspace(-2, 1, 4),\n","}\n","\n","grid_search = GridSearchCV(pipeline, parameters, verbose=1)\n","\n","grid_search.fit(split['train'][0], split['train'][1])\n","best_parameters = grid_search.best_estimator_.get_params()\n","for param_name in sorted(parameters.keys()):\n","    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n","print(\"Best score: %0.3f\" % grid_search.best_score_)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gVw9Z0yGGBcA","colab_type":"text"},"cell_type":"markdown","source":["\n","El resultado es bastante peor al menos con estos parámetros\n","\n","\tsvc__C: 0.01\n","\tsvc__gamma: 10.0\n","\tsvc__max_iter: 300\n","\tvect__analyzer: 'word'\n","\tvect__lowercase: True\n","\tvect__max_df: 0.8\n","\tvect__ngram_range: (1, 3)\n","\tvect__stop_words: None\n","\tvect__strip_accents: 'ascii'\n","Best score: 0.565"]},{"metadata":{"id":"3IwEJUNDbb-R","colab_type":"text"},"cell_type":"markdown","source":["## Modelos deep learning\n","\n","A continuación pasamos a intentar resolver el problema con modelos de deep learning\n","\n","Comenzamos preparando las frases, vamos a filtrar las que tengan una logitud grande, que son pocas y provocan una distorsion (outliers)"]},{"metadata":{"id":"9z4DdlvgqUsI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"566b4638-6203-4806-86a4-1760911fbd5d","executionInfo":{"status":"ok","timestamp":1532106776497,"user_tz":-120,"elapsed":525,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["maxlen = max([len(x.strip()) for x in subset['cleanText']])\n","maxlen"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["589"]},"metadata":{"tags":[]},"execution_count":40}]},{"metadata":{"id":"N55PP9PQrnIE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"6e9746bf-55e9-4db2-e6f6-b188128eb098","executionInfo":{"status":"ok","timestamp":1532106823375,"user_tz":-120,"elapsed":512,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["lens = [len(x.strip()) for x in subset['cleanText']]\n","median = np.median(np.array(lens))\n","mean = np.mean(np.array(lens))\n","maxlen = int(median)*2\n","print(median, mean, maxlen)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["59.0 63.5953054836032 118\n"],"name":"stdout"}]},{"metadata":{"id":"3blSLU30tDnr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["dataset = subset[['cleanText','Sentiment']].values.tolist()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZiQa0H83sKyS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"9059ee29-f20f-46c7-af6d-95ac98ae013c","executionInfo":{"status":"ok","timestamp":1532108128576,"user_tz":-120,"elapsed":729,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["tokenized_filtered = [(x, y) for x, y in dataset if len(x) < maxlen]\n","len(tokenized_filtered)"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["89049"]},"metadata":{"tags":[]},"execution_count":51}]},{"metadata":{"id":"s94FnQElt3iz","colab_type":"text"},"cell_type":"markdown","source":["A continuación pasamo a obtener el vocabulario y preparar los input para las redes neuronales"]},{"metadata":{"id":"7HvR9uYjwv-m","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"a3db1ac6-1eb2-4f52-846a-741d6a70073f","executionInfo":{"status":"ok","timestamp":1532108490291,"user_tz":-120,"elapsed":29502,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["nlp = spacy.load('en_core_web_md', disable=['parser', 'tagger', 'ner', 'textcat'])\n","tokens = []\n","tokenized = []\n","for x, y in tokenized_filtered:\n","    x_t = nlp(x)\n","    toks = [t.text for t in x_t]\n","    tokens+= toks\n","    tokenized.append((toks, y))\n","    \n","vocab_counter = Counter(tokens)\n","vocab = set(tokens)\n","print('Num de features a usar: ', len(vocab))  \n","print(len(tokenized))  \n","\n","# Construir el vocabulario como siempre\n","w2id = {k:i for i, k in enumerate(vocab)}\n","w2id['<UNK>'] = len(w2id)\n","labels = ['Negative','Positive']\n","l2id = {label:i for i, label in enumerate(labels)}\n","# Preparar Input. Padding. Conversión a input\n","# maxlen = min(maxlen, 50)\n","input_ready = []\n","for x, y in tokenized_filtered:\n","    sentence = np.zeros((maxlen))\n","    label = np.zeros((len(labels)))\n","    label[int(y)-1] = 1\n","    for i, t in enumerate(x):\n","        sentence[i] = w2id[t] if t in vocab_counter and vocab_counter[t]>=5 else w2id['<UNK>']\n","    input_ready.append((sentence,label))"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Num de features a usar:  30385\n","89049\n"],"name":"stdout"}]},{"metadata":{"id":"svz-PNAtutVR","colab_type":"text"},"cell_type":"markdown","source":["Dividimos en train y test"]},{"metadata":{"id":"-FTmWeFizD6J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":170},"outputId":"4bd8fe29-3dfb-450e-e929-c243b2331ce5","executionInfo":{"status":"ok","timestamp":1532109020052,"user_tz":-120,"elapsed":1313,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["splits = split_train_val_test(input_ready)\n","print(splits['train'][0].shape)\n","print(splits['train'][1].shape)\n","splits['train'][1]"],"execution_count":77,"outputs":[{"output_type":"stream","text":["(71239, 118)\n","(71239, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[1., 0.],\n","       [0., 1.],\n","       [0., 1.],\n","       ...,\n","       [1., 0.],\n","       [1., 0.],\n","       [1., 0.]])"]},"metadata":{"tags":[]},"execution_count":77}]},{"metadata":{"id":"bvQZhv9zux_v","colab_type":"text"},"cell_type":"markdown","source":["### Modelo Deep Learning simple\n","En primer lugar vamos a probar el rendimienno de un modelo simple, solo con capas densas y de drop out a ver como se comporta"]},{"metadata":{"id":"zYTvq3Ra3EkL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":272},"outputId":"36574a51-0d4d-429e-bad0-380268467547","executionInfo":{"status":"ok","timestamp":1532110147514,"user_tz":-120,"elapsed":1625,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["model = Sequential()\n","model.add(Dense(500, input_dim=maxlen, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(300, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(l2id), activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":90,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_13 (Dense)             (None, 50)                5950      \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 50)                0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 30)                1530      \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 2)                 62        \n","=================================================================\n","Total params: 7,542\n","Trainable params: 7,542\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"eGFLvvLV27m7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":224},"outputId":"08bac333-4a6c-4c71-93d0-eb5c4137c660","executionInfo":{"status":"ok","timestamp":1532110186659,"user_tz":-120,"elapsed":36627,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["model.fit(splits['train'][0], splits['train'][1],\n","          epochs=5,\n","          batch_size=64)"],"execution_count":91,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","71239/71239 [==============================] - 7s 98us/step - loss: 7.0787 - acc: 0.5588\n","Epoch 2/5\n","71239/71239 [==============================] - 7s 95us/step - loss: 6.8105 - acc: 0.5756\n","Epoch 3/5\n","71239/71239 [==============================] - 7s 95us/step - loss: 6.8021 - acc: 0.5761\n","Epoch 4/5\n","37568/71239 [==============>...............] - ETA: 3s - loss: 6.8138 - acc: 0.5754"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 94us/step - loss: 6.7970 - acc: 0.5764\n","Epoch 5/5\n","71239/71239 [==============================] - 7s 95us/step - loss: 6.7975 - acc: 0.5764\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f55cd48b780>"]},"metadata":{"tags":[]},"execution_count":91}]},{"metadata":{"id":"MN9FW7Q527jK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"cb8a2d70-9978-4fb6-faf6-4bc9baf6bb31","executionInfo":{"status":"ok","timestamp":1532110110057,"user_tz":-120,"elapsed":2793,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["score_basic = model.evaluate(splits['test'][0], splits['test'][1], batch_size=16)\n","score_basic"],"execution_count":89,"outputs":[{"output_type":"stream","text":["17810/17810 [==============================] - 2s 128us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[6.790860308133639, 0.5765300393037619]"]},"metadata":{"tags":[]},"execution_count":89}]},{"metadata":{"id":"72K-RE_ZvqpC","colab_type":"text"},"cell_type":"markdown","source":["Podemos observar que este modelo no da un gran rendimiento, vamos a probar con modelos mas complejos"]},{"metadata":{"id":"3ERuoDXjvSVH","colab_type":"text"},"cell_type":"markdown","source":["### Modelo basado en Deep Averaging Networks\n","La primera opción elegida es intentar solucionar el problema con este modelo de red neuronal. Vamos a usar hyperopts para intentar encontrar los mejores parámetros de la red."]},{"metadata":{"id":"T8u4r4vr27fe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def mask_aware_mean(x):\n","    # recreate the masks - all zero rows have been masked\n","    mask = K.not_equal(K.sum(K.abs(x), axis=2, keepdims=True), 0)\n","    # number of that rows are not all zeros\n","    n = K.sum(K.cast(mask, 'float32'), axis=1, keepdims=False)\n","    # compute mask-aware mean of x\n","    x_mean = K.sum(x, axis=1, keepdims=False) / n\n","    return x_mean\n","\n","def mask_aware_mean_output_shape(input_shape):\n","    shape = list(input_shape)\n","    assert len(shape) == 3\n","    return (shape[0], shape[2])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5k2UvlcA5dxC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","\n","space = {\n","    'dropout': hp.uniform('dropout', 0.0, 0.5),\n","    'neurons_dense': hp.choice('neurons_dense', [64, 128, 256]), \n","    'embeding_dim': hp.choice('embeding_dim', [50, 100, 150]),\n","    'lr': hp.choice('lr', [0.001, 0.01, 0.1]),\n","    'act_func' : hp.choice('act_func', ['relu','tanh'])\n","}\n","\n","X_train = splits['train'][0]\n","y_train = splits['train'][1]\n","## Soy consciente de que debería tener unos datos de validación aparte de los de test, pero por falta de tiempo no o he realizado\n","X_val = splits['test'][0]\n","y_val = splits['test'][1]\n","\n","\n","\n","def\tget_callbacks(pars):\n","  callbacks\t= [EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=0, mode='auto')]\n","  return callbacks\n","\n","def mi_cnn(pars):\n","  print ('Parameters: ', pars)\n","  input_layer = Input(shape=(maxlen,) )\n","  embedding = Embedding(output_dim=pars['embeding_dim'], input_dim=len(w2id), input_length=maxlen)(input_layer)\n","  doc_representation = Lambda(mask_aware_mean, mask_aware_mean_output_shape, name='embedding_average')(embedding)\n","  dense_1 = Dense(pars['neurons_dense'], activation=pars['act_func'])(doc_representation)\n","  drop_1 = Dropout(pars['dropout'])(dense_1)\n","  dense_2 = Dense(pars['neurons_dense'], activation=pars['act_func'])(drop_1)\n","  drop_2 = Dropout(pars['dropout'])(dense_2)\n","  out = Dense(len(l2id), activation='softmax')(drop_2)\n","\n","  model = Model(inputs=input_layer, outputs=out)\n","\n","  model.compile(loss='categorical_crossentropy',\n","                optimizer=Adam(lr=pars['lr'], decay=1e-6),\n","                metrics=['accuracy'])\n","  # Entrenamos el modelo\n","  history = model.fit(X_train, \n","                      y_train,\n","                      batch_size=128,\n","                      shuffle=True,\n","                      epochs=5,\n","                      validation_data=(X_val, y_val),\n","                      verbose = 1)\n","\n","  best_epoch_loss = np.argmin(history.history['val_loss'])\n","  best_val_loss = np.min(history.history['val_loss'])\n","  best_val_acc = np.max(history.history['val_acc'])\n","  \n","  print('Epoch {} - val acc: {} - val loss: {}'.format(best_epoch_loss, best_val_acc, best_val_loss))\n","  sys.stdout.flush()\n","  \n","  return {'Accuracy': best_val_acc,'loss': best_val_loss, 'best_epoch': best_epoch_loss, 'eval_time': time.time(), 'status': STATUS_OK, 'model': model, 'history': history}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZPuOc53I4nCK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":2264},"outputId":"f5f096ea-e886-4084-808f-68633a193756","executionInfo":{"status":"ok","timestamp":1532115075604,"user_tz":-120,"elapsed":371128,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["trials = Trials()\n","best = fmin(mi_cnn, space, algo=tpe.suggest, max_evals=10, trials=trials)\n","print(best)"],"execution_count":134,"outputs":[{"output_type":"stream","text":["Parameters:  {'act_func': 'relu', 'dropout': 0.03949876009208708, 'embeding_dim': 50, 'lr': 0.001, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 8s 106us/step - loss: 0.6715 - acc: 0.5893 - val_loss: 0.6685 - val_acc: 0.5906\n","Epoch 2/5\n","71239/71239 [==============================] - 6s 85us/step - loss: 0.6589 - acc: 0.6062 - val_loss: 0.6579 - val_acc: 0.6062\n","Epoch 3/5\n","33664/71239 [=============>................] - ETA: 3s - loss: 0.6576 - acc: 0.6092"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 86us/step - loss: 0.6570 - acc: 0.6093 - val_loss: 0.6598 - val_acc: 0.5999\n","Epoch 4/5\n","71239/71239 [==============================] - 6s 85us/step - loss: 0.6552 - acc: 0.6104 - val_loss: 0.6533 - val_acc: 0.6099\n","Epoch 5/5\n","71239/71239 [==============================] - 6s 85us/step - loss: 0.6536 - acc: 0.6120 - val_loss: 0.6552 - val_acc: 0.6098\n","Epoch 3 - val acc: 0.609882088740979 - val loss: 0.6533223645128875\n","Parameters:  {'act_func': 'tanh', 'dropout': 0.11984438975016393, 'embeding_dim': 100, 'lr': 0.001, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","24960/71239 [=========>....................] - ETA: 7s - loss: 0.6771 - acc: 0.5803"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 9s 123us/step - loss: 0.6696 - acc: 0.5922 - val_loss: 0.6646 - val_acc: 0.6006\n","Epoch 2/5\n","71239/71239 [==============================] - 7s 100us/step - loss: 0.6633 - acc: 0.6018 - val_loss: 0.6618 - val_acc: 0.6042\n","Epoch 3/5\n","71239/71239 [==============================] - 7s 100us/step - loss: 0.6629 - acc: 0.6006 - val_loss: 0.6608 - val_acc: 0.6047\n","Epoch 4/5\n","29440/71239 [===========>..................] - ETA: 3s - loss: 0.6602 - acc: 0.6067"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 100us/step - loss: 0.6620 - acc: 0.6031 - val_loss: 0.6607 - val_acc: 0.6053\n","Epoch 5/5\n","71239/71239 [==============================] - 7s 99us/step - loss: 0.6620 - acc: 0.6027 - val_loss: 0.6607 - val_acc: 0.6012\n","Epoch 3 - val acc: 0.6053340819764177 - val loss: 0.6606554592612887\n","Parameters:  {'act_func': 'relu', 'dropout': 0.4166948837224789, 'embeding_dim': 50, 'lr': 0.1, 'neurons_dense': 256}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 8s 111us/step - loss: 0.7023 - acc: 0.5747 - val_loss: 0.6835 - val_acc: 0.5765\n","Epoch 2/5\n","  128/71239 [..............................] - ETA: 7s - loss: 0.6777 - acc: 0.6094"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 85us/step - loss: 0.6835 - acc: 0.5757 - val_loss: 0.6824 - val_acc: 0.5765\n","Epoch 3/5\n","71239/71239 [==============================] - 6s 86us/step - loss: 0.6834 - acc: 0.5756 - val_loss: 0.6831 - val_acc: 0.5765\n","Epoch 4/5\n","71239/71239 [==============================] - 6s 86us/step - loss: 0.6835 - acc: 0.5766 - val_loss: 0.6815 - val_acc: 0.5765\n","Epoch 5/5\n","36608/71239 [==============>...............] - ETA: 2s - loss: 0.6831 - acc: 0.5767"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 86us/step - loss: 0.6828 - acc: 0.5766 - val_loss: 0.6818 - val_acc: 0.5765\n","Epoch 3 - val acc: 0.5765300393071087 - val loss: 0.6815322689900299\n","Parameters:  {'act_func': 'tanh', 'dropout': 0.4687619305925205, 'embeding_dim': 100, 'lr': 0.01, 'neurons_dense': 256}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 9s 128us/step - loss: 0.6818 - acc: 0.5766 - val_loss: 0.6780 - val_acc: 0.5723\n","Epoch 2/5\n","37376/71239 [==============>...............] - ETA: 3s - loss: 0.6816 - acc: 0.5821"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 101us/step - loss: 0.6817 - acc: 0.5820 - val_loss: 0.6599 - val_acc: 0.6087\n","Epoch 3/5\n","71239/71239 [==============================] - 7s 102us/step - loss: 0.6851 - acc: 0.5772 - val_loss: 0.6798 - val_acc: 0.5870\n","Epoch 4/5\n","71239/71239 [==============================] - 7s 101us/step - loss: 0.6829 - acc: 0.5822 - val_loss: 0.6959 - val_acc: 0.5992\n","Epoch 5/5\n","29312/71239 [===========>..................] - ETA: 4s - loss: 0.6866 - acc: 0.5764"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 101us/step - loss: 0.6871 - acc: 0.5760 - val_loss: 0.6670 - val_acc: 0.6068\n","Epoch 1 - val acc: 0.6087029758562605 - val loss: 0.65990365810571\n","Parameters:  {'act_func': 'relu', 'dropout': 0.29855189043319413, 'embeding_dim': 50, 'lr': 0.1, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 8s 112us/step - loss: 0.6954 - acc: 0.5748 - val_loss: 0.6823 - val_acc: 0.5765\n","Epoch 2/5\n","46208/71239 [==================>...........] - ETA: 2s - loss: 0.6828 - acc: 0.5784"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 86us/step - loss: 0.6831 - acc: 0.5766 - val_loss: 0.6834 - val_acc: 0.5765\n","Epoch 3/5\n","71239/71239 [==============================] - 6s 86us/step - loss: 0.6833 - acc: 0.5766 - val_loss: 0.6890 - val_acc: 0.5765\n","Epoch 4/5\n","71239/71239 [==============================] - 6s 87us/step - loss: 0.6839 - acc: 0.5743 - val_loss: 0.6814 - val_acc: 0.5765\n","Epoch 5/5\n","42752/71239 [=================>............] - ETA: 2s - loss: 0.6838 - acc: 0.5727"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 87us/step - loss: 0.6832 - acc: 0.5754 - val_loss: 0.6835 - val_acc: 0.5765\n","Epoch 3 - val acc: 0.5765300393071087 - val loss: 0.68138897012687\n","Parameters:  {'act_func': 'relu', 'dropout': 0.019778751974348807, 'embeding_dim': 100, 'lr': 0.001, 'neurons_dense': 256}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 9s 131us/step - loss: 0.6699 - acc: 0.5899 - val_loss: 0.6611 - val_acc: 0.6002\n","Epoch 2/5\n","37120/71239 [==============>...............] - ETA: 3s - loss: 0.6603 - acc: 0.6061"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 102us/step - loss: 0.6597 - acc: 0.6061 - val_loss: 0.6580 - val_acc: 0.6039\n","Epoch 3/5\n","71239/71239 [==============================] - 7s 101us/step - loss: 0.6561 - acc: 0.6102 - val_loss: 0.6550 - val_acc: 0.6102\n","Epoch 4/5\n","71239/71239 [==============================] - 7s 102us/step - loss: 0.6538 - acc: 0.6119 - val_loss: 0.6568 - val_acc: 0.6072\n","Epoch 5/5\n","28544/71239 [===========>..................] - ETA: 4s - loss: 0.6544 - acc: 0.6142"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 102us/step - loss: 0.6534 - acc: 0.6133 - val_loss: 0.6538 - val_acc: 0.6116\n","Epoch 4 - val acc: 0.6115665356474335 - val loss: 0.6538323769001797\n","Parameters:  {'act_func': 'tanh', 'dropout': 0.13781948117955228, 'embeding_dim': 50, 'lr': 0.1, 'neurons_dense': 256}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 8s 114us/step - loss: 5.6947 - acc: 0.5596 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 2/5\n","45312/71239 [==================>...........] - ETA: 2s - loss: 6.8436 - acc: 0.5754"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 86us/step - loss: 6.8252 - acc: 0.5766 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 3/5\n","71239/71239 [==============================] - 6s 86us/step - loss: 6.8252 - acc: 0.5766 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 4/5\n","71239/71239 [==============================] - 6s 87us/step - loss: 6.8252 - acc: 0.5766 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 5/5\n","43008/71239 [=================>............] - ETA: 2s - loss: 6.8242 - acc: 0.5766"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 87us/step - loss: 6.8252 - acc: 0.5766 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 0 - val acc: 0.5765300393071087 - val loss: 6.8255292845334585\n","Parameters:  {'act_func': 'relu', 'dropout': 0.2938412697082032, 'embeding_dim': 100, 'lr': 0.1, 'neurons_dense': 256}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 9s 132us/step - loss: 6.8080 - acc: 0.5759 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 2/5\n","37760/71239 [==============>...............] - ETA: 3s - loss: 6.7951 - acc: 0.5784"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 103us/step - loss: 6.8252 - acc: 0.5766 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 3/5\n","71239/71239 [==============================] - 7s 102us/step - loss: 6.8252 - acc: 0.5766 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 4/5\n","71239/71239 [==============================] - 7s 102us/step - loss: 6.8252 - acc: 0.5766 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 5/5\n","26752/71239 [==========>...................] - ETA: 4s - loss: 6.8661 - acc: 0.5740"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 102us/step - loss: 6.8252 - acc: 0.5766 - val_loss: 6.8255 - val_acc: 0.5765\n","Epoch 0 - val acc: 0.5765300393071087 - val loss: 6.8255292845334585\n","Parameters:  {'act_func': 'relu', 'dropout': 0.14992775094124322, 'embeding_dim': 150, 'lr': 0.1, 'neurons_dense': 64}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 10s 147us/step - loss: 0.6944 - acc: 0.5752 - val_loss: 0.6814 - val_acc: 0.5765\n","Epoch 2/5\n","23680/71239 [========>.....................] - ETA: 5s - loss: 0.6821 - acc: 0.5793"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 113us/step - loss: 0.6829 - acc: 0.5766 - val_loss: 0.6835 - val_acc: 0.5765\n","Epoch 3/5\n","71239/71239 [==============================] - 8s 113us/step - loss: 0.6831 - acc: 0.5766 - val_loss: 0.6820 - val_acc: 0.5765\n","Epoch 4/5\n","71239/71239 [==============================] - 8s 112us/step - loss: 0.6829 - acc: 0.5749 - val_loss: 0.6826 - val_acc: 0.5765\n","Epoch 5/5\n","10880/71239 [===>..........................] - ETA: 6s - loss: 0.6845 - acc: 0.5797"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 112us/step - loss: 0.6836 - acc: 0.5759 - val_loss: 0.6829 - val_acc: 0.5765\n","Epoch 0 - val acc: 0.5765300393071087 - val loss: 0.681387596234788\n","Parameters:  {'act_func': 'relu', 'dropout': 0.1604723930901929, 'embeding_dim': 100, 'lr': 0.01, 'neurons_dense': 64}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/5\n","71239/71239 [==============================] - 10s 134us/step - loss: 0.6720 - acc: 0.5843 - val_loss: 0.6654 - val_acc: 0.5779\n","Epoch 2/5\n","32640/71239 [============>.................] - ETA: 3s - loss: 0.6648 - acc: 0.5969"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 102us/step - loss: 0.6631 - acc: 0.5991 - val_loss: 0.6654 - val_acc: 0.6002\n","Epoch 3/5\n","71239/71239 [==============================] - 7s 102us/step - loss: 0.6613 - acc: 0.6039 - val_loss: 0.6622 - val_acc: 0.6062\n","Epoch 4/5\n","71239/71239 [==============================] - 7s 102us/step - loss: 0.6597 - acc: 0.6040 - val_loss: 0.6566 - val_acc: 0.6058\n","Epoch 5/5\n","26752/71239 [==========>...................] - ETA: 4s - loss: 0.6595 - acc: 0.6041"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 102us/step - loss: 0.6584 - acc: 0.6051 - val_loss: 0.6602 - val_acc: 0.6054\n","Epoch 3 - val acc: 0.606176305439685 - val loss: 0.6566270524902601\n","{'act_func': 0, 'dropout': 0.03949876009208708, 'embeding_dim': 0, 'lr': 0, 'neurons_dense': 1}\n"],"name":"stdout"}]},{"metadata":{"id":"-yxNSzoh4m_2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":493},"outputId":"4b960f55-eaea-4639-b4aa-ad396f674659","executionInfo":{"status":"ok","timestamp":1532116087928,"user_tz":-120,"elapsed":525,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["i=0\n","max = 0\n","for c, x in enumerate(trials.results):\n","  if(x['Accuracy'] > max):\n","    max = x['Accuracy']\n","    i = c\n","(i, max)\n","trials.trials[i]  \n","\n"],"execution_count":153,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'book_time': datetime.datetime(2018, 7, 20, 19, 28, 0, 259000),\n"," 'exp_key': None,\n"," 'misc': {'cmd': ('domain_attachment', 'FMinIter_Domain'),\n","  'idxs': {'act_func': [5],\n","   'dropout': [5],\n","   'embeding_dim': [5],\n","   'lr': [5],\n","   'neurons_dense': [5]},\n","  'tid': 5,\n","  'vals': {'act_func': [0],\n","   'dropout': [0.019778751974348807],\n","   'embeding_dim': [1],\n","   'lr': [0],\n","   'neurons_dense': [2]},\n","  'workdir': None},\n"," 'owner': None,\n"," 'refresh_time': datetime.datetime(2018, 7, 20, 19, 28, 39, 278000),\n"," 'result': {'Accuracy': 0.6115665356474335,\n","  'best_epoch': 4,\n","  'eval_time': 1532114919.2780857,\n","  'history': <keras.callbacks.History at 0x7f55c47bba90>,\n","  'loss': 0.6538323769001797,\n","  'model': <keras.engine.training.Model at 0x7f55c51c1c50>,\n","  'status': 'ok'},\n"," 'spec': None,\n"," 'state': 2,\n"," 'tid': 5,\n"," 'version': 0}"]},"metadata":{"tags":[]},"execution_count":153}]},{"metadata":{"id":"el3DVUNowTyD","colab_type":"text"},"cell_type":"markdown","source":["Estos son los mejores resultados optenidos y los parametros utilizados para ello\n","\n","   >('dropout', 0.03),  \n","   >('neurons_dense', [128]),   \n","   >('embeding_dim', [50,]),  \n","   >('lr', [0.001]),   \n","   >('act_func', ['relu'])  \n","   \n","   'Accuracy': 0.6115665356474335\n","   \n","   Hemos mejorado el rendimiento respecto a la red neuronal simple, pero aun esta lejos de los resultados obtenidos con bayes."]},{"metadata":{"id":"gWjm2WDFwlJX","colab_type":"text"},"cell_type":"markdown","source":["### Modelo basado en redes neuronales convolucionales\n","A continuación vamos a probar un modelos de este tipo, tambien vamos a usar hyperopt para intenar optimizar los parámetros de la red."]},{"metadata":{"id":"4h_yR23l4m9b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["space = {\n","    'dropout': hp.uniform('dropout', 0.0, 0.5),\n","    'neurons_dense': hp.choice('neurons_dense', [64, 128, 256]), \n","    'embeding_dim': hp.choice('embeding_dim', [50, 100, 150]),\n","    'filters': hp.choice('filters', [50, 100, 150]),\n","}\n","\n","X_train = splits['train'][0]\n","y_train = splits['train'][1]\n","## Soy consciente de que debería tener unos datos de validación aparte de los de test, pero por falta de tiempo no o he realizado\n","X_val = splits['test'][0]\n","y_val = splits['test'][1]\n","\n","\n","\n","def\tget_callbacks(pars):\n","  callbacks\t= [EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=0, mode='auto')]\n","  return callbacks\n","\n","def mi_cnn(pars):\n","  print ('Parameters: ', pars)\n","\n","  input_layer = Input(shape=(maxlen,) )# maxlen\n","  embedding = Embedding(output_dim=pars['embeding_dim'], input_dim=len(w2id), input_length=maxlen)(input_layer)#w2id maxlen\n","\n","  conv_1 = Conv1D(filters=pars['filters'], kernel_size=1, strides=1, activation='relu', padding='valid')(embedding)\n","  mp_1 = GlobalMaxPooling1D()(conv_1)\n","\n","  conv_2 = Conv1D(filters=pars['filters'], kernel_size=2, strides=1, activation='relu', padding='valid')(embedding)\n","  mp_2 = GlobalMaxPooling1D()(conv_2)\n","\n","  conv_5 = Conv1D(filters=pars['filters'], kernel_size=5, strides=1, activation='relu', padding='valid')(embedding)\n","  mp_5 = GlobalMaxPooling1D()(conv_5)\n","\n","  doc_representation = Concatenate()([mp_1, mp_2, mp_5])\n","\n","  dense_1 = Dense(pars['neurons_dense'], activation='relu')(doc_representation)\n","  drop_1 = Dropout(pars['dropout'])(dense_1)\n","  dense_2 = Dense(pars['neurons_dense'], activation='relu')(drop_1)\n","  drop_2 = Dropout(pars['dropout'])(dense_2)\n","  out = Dense(len(l2id), activation='softmax')(drop_2)\n","\n","  model = Model(inputs=input_layer, outputs=out)\n","\n","  model.compile(loss='categorical_crossentropy',\n","                optimizer='rmsprop',\n","                metrics=['accuracy'])\n","\n","  # Entrenamos el modelo\n","  history = model.fit(X_train, \n","                      y_train,\n","                      batch_size=256,\n","                      shuffle=True,\n","                      epochs=10,\n","                      validation_data=(X_val, y_val),\n","                      verbose = 1)\n","\n","  best_epoch_loss = np.argmin(history.history['val_loss'])\n","  best_val_loss = np.min(history.history['val_loss'])\n","  best_val_acc = np.max(history.history['val_acc'])\n","  \n","  print('Epoch {} - val acc: {} - val loss: {}'.format(best_epoch_loss, best_val_acc, best_val_loss))\n","  sys.stdout.flush()\n","  \n","  return {'Accuracy': best_val_acc,'loss': best_val_loss, 'best_epoch': best_epoch_loss, 'eval_time': time.time(), 'status': STATUS_OK, 'model': model, 'history': history}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gUADp6lp4m5X","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3964},"outputId":"0ce84a82-e554-484c-a297-5e9068f0450c","executionInfo":{"status":"ok","timestamp":1532117349518,"user_tz":-120,"elapsed":832965,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["trials = Trials()\n","best = fmin(mi_cnn, space, algo=tpe.suggest, max_evals=10, trials=trials)\n","print(best)"],"execution_count":162,"outputs":[{"output_type":"stream","text":["Parameters:  {'dropout': 0.2573870381619406, 'embeding_dim': 50, 'filters': 100, 'neurons_dense': 256}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","71239/71239 [==============================] - 13s 177us/step - loss: 0.6209 - acc: 0.6471 - val_loss: 0.7337 - val_acc: 0.6147\n","Epoch 2/10\n","71239/71239 [==============================] - 8s 106us/step - loss: 0.5581 - acc: 0.7068 - val_loss: 0.5383 - val_acc: 0.7289\n","Epoch 3/10\n","16896/71239 [======>.......................] - ETA: 5s - loss: 0.5374 - acc: 0.7225"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 107us/step - loss: 0.5328 - acc: 0.7270 - val_loss: 0.5393 - val_acc: 0.7358\n","Epoch 4/10\n","71239/71239 [==============================] - 8s 107us/step - loss: 0.5159 - acc: 0.7398 - val_loss: 0.5027 - val_acc: 0.7525\n","Epoch 5/10\n","71239/71239 [==============================] - 8s 106us/step - loss: 0.5050 - acc: 0.7478 - val_loss: 0.5079 - val_acc: 0.7518\n","Epoch 6/10\n","17152/71239 [======>.......................] - ETA: 5s - loss: 0.4993 - acc: 0.7561"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 106us/step - loss: 0.4959 - acc: 0.7545 - val_loss: 0.5398 - val_acc: 0.7207\n","Epoch 7/10\n","71239/71239 [==============================] - 8s 107us/step - loss: 0.4865 - acc: 0.7606 - val_loss: 0.5374 - val_acc: 0.7323\n","Epoch 8/10\n","71239/71239 [==============================] - 8s 106us/step - loss: 0.4793 - acc: 0.7660 - val_loss: 0.4945 - val_acc: 0.7568\n","Epoch 9/10\n","15104/71239 [=====>........................] - ETA: 5s - loss: 0.4704 - acc: 0.7719"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 106us/step - loss: 0.4730 - acc: 0.7689 - val_loss: 0.5439 - val_acc: 0.7423\n","Epoch 10/10\n","71239/71239 [==============================] - 8s 106us/step - loss: 0.4673 - acc: 0.7739 - val_loss: 0.4978 - val_acc: 0.7595\n","Epoch 7 - val acc: 0.7595171253176501 - val loss: 0.4944729449607093\n","Parameters:  {'dropout': 0.11644216231957516, 'embeding_dim': 50, 'filters': 50, 'neurons_dense': 64}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","71239/71239 [==============================] - 11s 156us/step - loss: 0.6209 - acc: 0.6499 - val_loss: 0.6491 - val_acc: 0.6034\n","Epoch 2/10\n"," 5632/71239 [=>............................] - ETA: 5s - loss: 0.5754 - acc: 0.6955"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 83us/step - loss: 0.5645 - acc: 0.7026 - val_loss: 0.5375 - val_acc: 0.7229\n","Epoch 3/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.5414 - acc: 0.7208 - val_loss: 0.5217 - val_acc: 0.7367\n","Epoch 4/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.5248 - acc: 0.7335 - val_loss: 0.5752 - val_acc: 0.6876\n","Epoch 5/10\n","58624/71239 [=======================>......] - ETA: 0s - loss: 0.5126 - acc: 0.7422"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 83us/step - loss: 0.5133 - acc: 0.7418 - val_loss: 0.5103 - val_acc: 0.7415\n","Epoch 6/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.5060 - acc: 0.7488 - val_loss: 0.5104 - val_acc: 0.7453\n","Epoch 7/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.4980 - acc: 0.7531 - val_loss: 0.5310 - val_acc: 0.7273\n","Epoch 8/10\n","67840/71239 [===========================>..] - ETA: 0s - loss: 0.4933 - acc: 0.7558"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 83us/step - loss: 0.4934 - acc: 0.7559 - val_loss: 0.5339 - val_acc: 0.7262\n","Epoch 9/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.4862 - acc: 0.7608 - val_loss: 0.5464 - val_acc: 0.7161\n","Epoch 10/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.4828 - acc: 0.7633 - val_loss: 0.5190 - val_acc: 0.7380\n","Epoch 4 - val acc: 0.7453116225767912 - val loss: 0.5103025434928822\n","Parameters:  {'dropout': 0.4305750314410428, 'embeding_dim': 100, 'filters': 100, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","29440/71239 [===========>..................] - ETA: 9s - loss: 0.6486 - acc: 0.6166"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 14s 192us/step - loss: 0.6155 - acc: 0.6547 - val_loss: 0.6295 - val_acc: 0.6591\n","Epoch 2/10\n","71239/71239 [==============================] - 10s 139us/step - loss: 0.5582 - acc: 0.7078 - val_loss: 0.5318 - val_acc: 0.7263\n","Epoch 3/10\n","71239/71239 [==============================] - 10s 137us/step - loss: 0.5359 - acc: 0.7269 - val_loss: 0.5263 - val_acc: 0.7395\n","Epoch 4/10\n"," 4352/71239 [>.............................] - ETA: 8s - loss: 0.5194 - acc: 0.7438"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 137us/step - loss: 0.5201 - acc: 0.7388 - val_loss: 0.5181 - val_acc: 0.7389\n","Epoch 5/10\n","71239/71239 [==============================] - 10s 137us/step - loss: 0.5083 - acc: 0.7468 - val_loss: 0.5096 - val_acc: 0.7435\n","Epoch 6/10\n","71239/71239 [==============================] - 10s 137us/step - loss: 0.4974 - acc: 0.7541 - val_loss: 0.5217 - val_acc: 0.7381\n","Epoch 7/10\n"," 3840/71239 [>.............................] - ETA: 8s - loss: 0.4941 - acc: 0.7568"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 137us/step - loss: 0.4893 - acc: 0.7594 - val_loss: 0.5368 - val_acc: 0.7367\n","Epoch 8/10\n","71239/71239 [==============================] - 10s 137us/step - loss: 0.4817 - acc: 0.7646 - val_loss: 0.5391 - val_acc: 0.7371\n","Epoch 9/10\n","71239/71239 [==============================] - 10s 138us/step - loss: 0.4749 - acc: 0.7694 - val_loss: 0.5037 - val_acc: 0.7613\n","Epoch 10/10\n"," 1792/71239 [..............................] - ETA: 8s - loss: 0.4641 - acc: 0.7684"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 137us/step - loss: 0.4657 - acc: 0.7747 - val_loss: 0.5109 - val_acc: 0.7583\n","Epoch 8 - val acc: 0.7613138684725774 - val loss: 0.5036781453102376\n","Parameters:  {'dropout': 0.4683081324008332, 'embeding_dim': 50, 'filters': 50, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","71239/71239 [==============================] - 9s 128us/step - loss: 0.6344 - acc: 0.6342 - val_loss: 0.5740 - val_acc: 0.6958\n","Epoch 2/10\n","58624/71239 [=======================>......] - ETA: 0s - loss: 0.5776 - acc: 0.6936"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 84us/step - loss: 0.5743 - acc: 0.6965 - val_loss: 0.5435 - val_acc: 0.7198\n","Epoch 3/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.5511 - acc: 0.7160 - val_loss: 0.5362 - val_acc: 0.7284\n","Epoch 4/10\n","71239/71239 [==============================] - 6s 84us/step - loss: 0.5364 - acc: 0.7274 - val_loss: 0.5519 - val_acc: 0.7199\n","Epoch 5/10\n","67072/71239 [===========================>..] - ETA: 0s - loss: 0.5234 - acc: 0.7367"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 83us/step - loss: 0.5238 - acc: 0.7365 - val_loss: 0.5239 - val_acc: 0.7323\n","Epoch 6/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.5133 - acc: 0.7449 - val_loss: 0.5122 - val_acc: 0.7418\n","Epoch 7/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.5082 - acc: 0.7464 - val_loss: 0.5154 - val_acc: 0.7372\n","Epoch 8/10\n","69376/71239 [============================>.] - ETA: 0s - loss: 0.4976 - acc: 0.7546"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 83us/step - loss: 0.4983 - acc: 0.7538 - val_loss: 0.5123 - val_acc: 0.7470\n","Epoch 9/10\n","71239/71239 [==============================] - 6s 84us/step - loss: 0.4931 - acc: 0.7572 - val_loss: 0.5073 - val_acc: 0.7467\n","Epoch 10/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.4891 - acc: 0.7596 - val_loss: 0.5120 - val_acc: 0.7492\n","Epoch 8 - val acc: 0.7491858506590915 - val loss: 0.5073485701958294\n","Parameters:  {'dropout': 0.4717708852949422, 'embeding_dim': 50, 'filters': 150, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","28928/71239 [===========>..................] - ETA: 9s - loss: 0.6612 - acc: 0.6034"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 15s 214us/step - loss: 0.6290 - acc: 0.6409 - val_loss: 0.5682 - val_acc: 0.6979\n","Epoch 2/10\n","71239/71239 [==============================] - 10s 142us/step - loss: 0.5653 - acc: 0.7024 - val_loss: 0.5617 - val_acc: 0.7010\n","Epoch 3/10\n","71239/71239 [==============================] - 10s 142us/step - loss: 0.5402 - acc: 0.7230 - val_loss: 0.5189 - val_acc: 0.7350\n","Epoch 4/10\n"," 4352/71239 [>.............................] - ETA: 8s - loss: 0.5268 - acc: 0.7335"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 141us/step - loss: 0.5231 - acc: 0.7377 - val_loss: 0.5368 - val_acc: 0.7270\n","Epoch 5/10\n","71239/71239 [==============================] - 10s 142us/step - loss: 0.5091 - acc: 0.7461 - val_loss: 0.5051 - val_acc: 0.7537\n","Epoch 6/10\n","70912/71239 [============================>.] - ETA: 0s - loss: 0.4989 - acc: 0.7524"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 141us/step - loss: 0.4987 - acc: 0.7524 - val_loss: 0.5144 - val_acc: 0.7510\n","Epoch 7/10\n","71239/71239 [==============================] - 10s 142us/step - loss: 0.4900 - acc: 0.7598 - val_loss: 0.4917 - val_acc: 0.7565\n","Epoch 8/10\n","71239/71239 [==============================] - 10s 141us/step - loss: 0.4794 - acc: 0.7670 - val_loss: 0.5090 - val_acc: 0.7491\n","Epoch 9/10\n","13568/71239 [====>.........................] - ETA: 7s - loss: 0.4670 - acc: 0.7718"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 141us/step - loss: 0.4748 - acc: 0.7681 - val_loss: 0.5041 - val_acc: 0.7588\n","Epoch 10/10\n","71239/71239 [==============================] - 10s 141us/step - loss: 0.4674 - acc: 0.7725 - val_loss: 0.5385 - val_acc: 0.7377\n","Epoch 6 - val acc: 0.7587871980626953 - val loss: 0.4917265796848792\n","Parameters:  {'dropout': 0.30522583462570435, 'embeding_dim': 100, 'filters': 50, 'neurons_dense': 256}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","46592/71239 [==================>...........] - ETA: 5s - loss: 0.6296 - acc: 0.6379"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 14s 199us/step - loss: 0.6148 - acc: 0.6537 - val_loss: 0.5846 - val_acc: 0.6830\n","Epoch 2/10\n","71239/71239 [==============================] - 8s 109us/step - loss: 0.5547 - acc: 0.7096 - val_loss: 0.5606 - val_acc: 0.7106\n","Epoch 3/10\n","71239/71239 [==============================] - 8s 108us/step - loss: 0.5323 - acc: 0.7268 - val_loss: 0.5205 - val_acc: 0.7341\n","Epoch 4/10\n","14080/71239 [====>.........................] - ETA: 5s - loss: 0.5228 - acc: 0.7347"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 109us/step - loss: 0.5195 - acc: 0.7372 - val_loss: 0.5553 - val_acc: 0.7228\n","Epoch 5/10\n","71239/71239 [==============================] - 8s 109us/step - loss: 0.5093 - acc: 0.7461 - val_loss: 0.5064 - val_acc: 0.7476\n","Epoch 6/10\n","71239/71239 [==============================] - 8s 109us/step - loss: 0.5002 - acc: 0.7507 - val_loss: 0.5168 - val_acc: 0.7355\n","Epoch 7/10\n"," 8960/71239 [==>...........................] - ETA: 6s - loss: 0.4826 - acc: 0.7652"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 108us/step - loss: 0.4942 - acc: 0.7564 - val_loss: 0.5042 - val_acc: 0.7490\n","Epoch 8/10\n","71239/71239 [==============================] - 8s 109us/step - loss: 0.4871 - acc: 0.7604 - val_loss: 0.5173 - val_acc: 0.7484\n","Epoch 9/10\n","71239/71239 [==============================] - 8s 109us/step - loss: 0.4820 - acc: 0.7639 - val_loss: 0.5021 - val_acc: 0.7556\n","Epoch 10/10\n"," 7936/71239 [==>...........................] - ETA: 6s - loss: 0.4831 - acc: 0.7658"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 109us/step - loss: 0.4761 - acc: 0.7685 - val_loss: 0.5070 - val_acc: 0.7546\n","Epoch 8 - val acc: 0.7556428972018829 - val loss: 0.5020820390736367\n","Parameters:  {'dropout': 0.0797999876956792, 'embeding_dim': 50, 'filters': 50, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","71239/71239 [==============================] - 9s 130us/step - loss: 0.6213 - acc: 0.6469 - val_loss: 0.5611 - val_acc: 0.7061\n","Epoch 2/10\n","60928/71239 [========================>.....] - ETA: 0s - loss: 0.5635 - acc: 0.6998"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 82us/step - loss: 0.5610 - acc: 0.7027 - val_loss: 0.6074 - val_acc: 0.6753\n","Epoch 3/10\n","71239/71239 [==============================] - 6s 83us/step - loss: 0.5368 - acc: 0.7244 - val_loss: 0.5219 - val_acc: 0.7355\n","Epoch 4/10\n","71239/71239 [==============================] - 6s 82us/step - loss: 0.5228 - acc: 0.7342 - val_loss: 0.5803 - val_acc: 0.7105\n","Epoch 5/10\n","67840/71239 [===========================>..] - ETA: 0s - loss: 0.5105 - acc: 0.7424"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 82us/step - loss: 0.5105 - acc: 0.7425 - val_loss: 0.5770 - val_acc: 0.7144\n","Epoch 6/10\n","71239/71239 [==============================] - 6s 82us/step - loss: 0.5029 - acc: 0.7496 - val_loss: 0.5188 - val_acc: 0.7390\n","Epoch 7/10\n","71239/71239 [==============================] - 6s 82us/step - loss: 0.4955 - acc: 0.7539 - val_loss: 0.5018 - val_acc: 0.7516\n","Epoch 8/10\n","69376/71239 [============================>.] - ETA: 0s - loss: 0.4889 - acc: 0.7587"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 6s 83us/step - loss: 0.4891 - acc: 0.7586 - val_loss: 0.5047 - val_acc: 0.7485\n","Epoch 9/10\n","71239/71239 [==============================] - 6s 82us/step - loss: 0.4834 - acc: 0.7620 - val_loss: 0.5528 - val_acc: 0.7208\n","Epoch 10/10\n","71239/71239 [==============================] - 6s 82us/step - loss: 0.4783 - acc: 0.7666 - val_loss: 0.5085 - val_acc: 0.7443\n","Epoch 6 - val acc: 0.7516002245460716 - val loss: 0.5017533256156199\n","Parameters:  {'dropout': 0.4822729813002124, 'embeding_dim': 100, 'filters': 50, 'neurons_dense': 256}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","29952/71239 [===========>..................] - ETA: 8s - loss: 0.6511 - acc: 0.6135"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 12s 164us/step - loss: 0.6169 - acc: 0.6521 - val_loss: 0.5772 - val_acc: 0.6958\n","Epoch 2/10\n","71239/71239 [==============================] - 8s 109us/step - loss: 0.5554 - acc: 0.7073 - val_loss: 0.5813 - val_acc: 0.6920\n","Epoch 3/10\n","71239/71239 [==============================] - 8s 109us/step - loss: 0.5346 - acc: 0.7245 - val_loss: 0.5249 - val_acc: 0.7304\n","Epoch 4/10\n","11520/71239 [===>..........................] - ETA: 6s - loss: 0.5199 - acc: 0.7377"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 109us/step - loss: 0.5193 - acc: 0.7368 - val_loss: 0.5990 - val_acc: 0.6775\n","Epoch 5/10\n","71239/71239 [==============================] - 8s 108us/step - loss: 0.5071 - acc: 0.7467 - val_loss: 0.5052 - val_acc: 0.7471\n","Epoch 6/10\n","71239/71239 [==============================] - 8s 109us/step - loss: 0.4981 - acc: 0.7525 - val_loss: 0.5093 - val_acc: 0.7518\n","Epoch 7/10\n"," 8960/71239 [==>...........................] - ETA: 6s - loss: 0.4907 - acc: 0.7604"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 108us/step - loss: 0.4909 - acc: 0.7595 - val_loss: 0.5253 - val_acc: 0.7353\n","Epoch 8/10\n","71239/71239 [==============================] - 8s 108us/step - loss: 0.4857 - acc: 0.7632 - val_loss: 0.5007 - val_acc: 0.7549\n","Epoch 9/10\n","71239/71239 [==============================] - 8s 108us/step - loss: 0.4792 - acc: 0.7671 - val_loss: 0.6353 - val_acc: 0.6907\n","Epoch 10/10\n"," 8704/71239 [==>...........................] - ETA: 6s - loss: 0.4631 - acc: 0.7763"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 8s 108us/step - loss: 0.4734 - acc: 0.7693 - val_loss: 0.5138 - val_acc: 0.7464\n","Epoch 7 - val acc: 0.7549129701945837 - val loss: 0.5006994814500589\n","Parameters:  {'dropout': 0.13002987644758734, 'embeding_dim': 50, 'filters': 100, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","71239/71239 [==============================] - 12s 163us/step - loss: 0.6192 - acc: 0.6513 - val_loss: 0.5887 - val_acc: 0.6865\n","Epoch 2/10\n","32512/71239 [============>.................] - ETA: 3s - loss: 0.5664 - acc: 0.7011"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 104us/step - loss: 0.5583 - acc: 0.7073 - val_loss: 0.5299 - val_acc: 0.7266\n","Epoch 3/10\n","71239/71239 [==============================] - 7s 105us/step - loss: 0.5317 - acc: 0.7272 - val_loss: 0.5439 - val_acc: 0.7163\n","Epoch 4/10\n","71239/71239 [==============================] - 7s 104us/step - loss: 0.5162 - acc: 0.7389 - val_loss: 0.5068 - val_acc: 0.7455\n","Epoch 5/10\n","28416/71239 [==========>...................] - ETA: 4s - loss: 0.5026 - acc: 0.7483"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 105us/step - loss: 0.5042 - acc: 0.7480 - val_loss: 0.5177 - val_acc: 0.7467\n","Epoch 6/10\n","71239/71239 [==============================] - 7s 105us/step - loss: 0.4937 - acc: 0.7571 - val_loss: 0.5906 - val_acc: 0.6964\n","Epoch 7/10\n","71239/71239 [==============================] - 7s 105us/step - loss: 0.4855 - acc: 0.7607 - val_loss: 0.5176 - val_acc: 0.7451\n","Epoch 8/10\n","25856/71239 [=========>....................] - ETA: 4s - loss: 0.4811 - acc: 0.7633"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 7s 105us/step - loss: 0.4779 - acc: 0.7653 - val_loss: 0.5045 - val_acc: 0.7534\n","Epoch 9/10\n","71239/71239 [==============================] - 7s 105us/step - loss: 0.4714 - acc: 0.7690 - val_loss: 0.5132 - val_acc: 0.7526\n","Epoch 10/10\n","71239/71239 [==============================] - 7s 105us/step - loss: 0.4663 - acc: 0.7740 - val_loss: 0.5207 - val_acc: 0.7432\n","Epoch 7 - val acc: 0.7533969680088949 - val loss: 0.5045455954571509\n","Parameters:  {'dropout': 0.2808516902502133, 'embeding_dim': 100, 'filters': 100, 'neurons_dense': 128}\n","Train on 71239 samples, validate on 17810 samples\n","Epoch 1/10\n","12544/71239 [====>.........................] - ETA: 23s - loss: 0.6701 - acc: 0.5910"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 14s 190us/step - loss: 0.6154 - acc: 0.6557 - val_loss: 0.6444 - val_acc: 0.6145\n","Epoch 2/10\n","71239/71239 [==============================] - 10s 137us/step - loss: 0.5534 - acc: 0.7126 - val_loss: 0.5363 - val_acc: 0.7357\n","Epoch 3/10\n","71239/71239 [==============================] - 10s 137us/step - loss: 0.5323 - acc: 0.7280 - val_loss: 0.5199 - val_acc: 0.7337\n","Epoch 4/10\n"," 2816/71239 [>.............................] - ETA: 8s - loss: 0.4989 - acc: 0.7429"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 138us/step - loss: 0.5161 - acc: 0.7411 - val_loss: 0.5035 - val_acc: 0.7516\n","Epoch 5/10\n","71239/71239 [==============================] - 10s 137us/step - loss: 0.5055 - acc: 0.7494 - val_loss: 0.5654 - val_acc: 0.6979\n","Epoch 6/10\n","71239/71239 [==============================] - 10s 136us/step - loss: 0.4948 - acc: 0.7550 - val_loss: 0.4967 - val_acc: 0.7492\n","Epoch 7/10\n"," 1792/71239 [..............................] - ETA: 8s - loss: 0.4674 - acc: 0.7684"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 136us/step - loss: 0.4864 - acc: 0.7612 - val_loss: 0.5107 - val_acc: 0.7514\n","Epoch 8/10\n","71239/71239 [==============================] - 10s 136us/step - loss: 0.4765 - acc: 0.7667 - val_loss: 0.5871 - val_acc: 0.6967\n","Epoch 9/10\n","71239/71239 [==============================] - 10s 136us/step - loss: 0.4700 - acc: 0.7734 - val_loss: 0.5328 - val_acc: 0.7349\n","Epoch 10/10\n","  256/71239 [..............................] - ETA: 10s - loss: 0.5009 - acc: 0.7617"],"name":"stdout"},{"output_type":"stream","text":["71239/71239 [==============================] - 10s 136us/step - loss: 0.4642 - acc: 0.7761 - val_loss: 0.4951 - val_acc: 0.7583\n","Epoch 9 - val acc: 0.758281863980719 - val loss: 0.4950568249625881\n","{'dropout': 0.4717708852949422, 'embeding_dim': 0, 'filters': 2, 'neurons_dense': 1}\n"],"name":"stdout"}]},{"metadata":{"id":"GcjNFBlo4m3Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":71},"outputId":"bc358e51-dfee-4361-9674-a8765495185f","executionInfo":{"status":"ok","timestamp":1532117363566,"user_tz":-120,"elapsed":2236,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["i=0\n","max = 0\n","for c, x in enumerate(trials.results):\n","  if(x['Accuracy'] > max):\n","    max = x['Accuracy']\n","    i = c\n","print((i, max))\n","print(trials.trials[i])  "],"execution_count":163,"outputs":[{"output_type":"stream","text":["(2, 0.7613138684725774)\n","{'state': 2, 'tid': 2, 'spec': None, 'result': {'Accuracy': 0.7613138684725774, 'loss': 0.5036781453102376, 'best_epoch': 8, 'eval_time': 1532116766.3420596, 'status': 'ok', 'model': <keras.engine.training.Model object at 0x7f55b3b0af98>, 'history': <keras.callbacks.History object at 0x7f55b3b1e128>}, 'misc': {'tid': 2, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'dropout': [2], 'embeding_dim': [2], 'filters': [2], 'neurons_dense': [2]}, 'vals': {'dropout': [0.4305750314410428], 'embeding_dim': [1], 'filters': [1], 'neurons_dense': [1]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2018, 7, 20, 19, 57, 43, 720000), 'refresh_time': datetime.datetime(2018, 7, 20, 19, 59, 26, 342000)}\n"],"name":"stdout"}]},{"metadata":{"id":"_GHCyxQmUGEO","colab_type":"text"},"cell_type":"markdown","source":["Los resultados obtenidos con esta red son ya mejores, muy similares a los obtenidos con bayes. Se presentan tambien los parametros utilizados para obtener estos resultados\n","\n","'Accuracy': 0.7613138684725774,\n","\n","{'dropout': 0.4717708852949422, 'embeding_dim': 50, 'filters': 100, 'neurons_dense': 128}\n"," \n"," \n"]},{"metadata":{"id":"Wmg-oaVOlQgi","colab_type":"text"},"cell_type":"markdown","source":["## Conclusiones\n","Se ha intentado optimizar 4 algoritmos, 2 clásicos y 2 basados en redes neuronales.\n","\n","Entre os algoritmos clásicos, hemos utilizado Bayes y SVM, en ambos casos hemos utilizado grid search para intentar encontrar los parámetros optimos. para este caso, se comporta claramente mejor bayes llegando a un accuracy en test del 76%  \n","TEST SCORE: 0.7608260826082608\n","\n","Entre los algoritmos de deep learning, hemos probado 2 arquitecturas diferentes, una basada en Deep Averaging network, y a otra basada en convolutional neural networks. En ambos casos se han seguido las estructuras construidas en clase, y se han intentado optimizar los parámetros utilizando hyperopts. Entre estas 2 redes, la que mejor se comporta es la basada en CNN, donde se ha llegado a un accuracy del 76%  para el conjunto de test  \n","'TEST SCORE:': 0.7613138684725774\n","\n","Hay muy poca diferencia entre el comportamiento de ambos algoritmos.\n","\n"]},{"metadata":{"id":"WKAIH4nkZvid","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}