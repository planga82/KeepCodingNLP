{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PracticaNLP-Problema3.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"pRJ7fiaDYMqo","colab_type":"text"},"cell_type":"markdown","source":["# Introducción \n","\n","La idea de la práctica es visitar aquellos temas que en cierta manera nos permitan ver más contenido del curso.\n","\n","La práctica esta dividida en 4 o 5 subapartados, que ya tenéis en este mismo Notebook. Estos subapartados estan aquí para que rellenéis el código que hace falta para la realización de la práctica. Obviamente podéis usar tantas celdas como os hagan falta, es más es de agradecer si el código final esta algo \"limpio\". Usar funciones, algo de comentario, etc, etc...\n","\n","Usaremos 2 datasets, uno para el primer ejercicio, y otro para el resto de ejercicios.\n","\n","Ejercicios:\n","\n","\n","1.   Machine Learning vs Deep Learning (Acordaros que hay que implementar el pipeline visto en clase entero)\n","\n","    1.1. Implementación de un modelo de Sentiment Analysis con algún algoritmo de Machine Learning Clásico.\n","    \n","    1.2. Implementación de un modelo de Sentiment Analysis con alguna arquitectura de Deep Learning.\n","    \n","    1.3. Breve Comparación de resultados. Confusion Matrix.\n","    \n","2. Hacer Analysis de los tweets del segundo dataset. Que temas aparecen? Como se representan estos temas? De que hablan unos y otros?\n","\n","3. Escoged a uno de los dos presidentes, y escribid tweets como ellos, usando un Modelo Generativo.\n","\n","En cada ejercicio, espero explicaciones y razonamientos del porque una arquitectura y no otra, por ejemplo en Deep Learning, porque usar Convolutionals en lugar de recurrentes, o en Machine Learning, Bayes en lugar de SVM. Hay que explicar el pipeline, sobretodo el preproceso de datos, con lo que habrá que hacer un pequeño estudio de que datos tenemos, y si hay cosas que se pueden ignorar, si hacéis stemming, o no, etc, etc...\n","\n","Acordaros de que objetivo final no es que obtengáis una accuracy brutal, es que comprendais que pasa cuando usais un algoritmo u otro, y que problemas o beneficios nos dan.\n","\n","![](https://i.pinimg.com/736x/19/63/8c/19638c0b33e2f7822d6806ce31d89d84--funny-cartoons-funny-jokes.jpg =400x)\n","\n","Mucha suerte y ánimo!\n","\n"]},{"metadata":{"id":"7a-7Bl8nGm7K","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download en_core_web_md"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ihz3ciWhzVYY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"56102aa6-17c3-47dc-b7bc-098c5855b333","executionInfo":{"status":"ok","timestamp":1532178735937,"user_tz":-120,"elapsed":565,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["import spacy\n","import numpy as np\n","import pickle\n","import json\n","import os\n","import csv\n","import pprint as pp\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from random import shuffle, choice, sample\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from copy import copy\n","import warnings\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import pylab as pl\n","from IPython import display\n","from keras.models import Model, Sequential\n","from keras.layers import Input, CuDNNLSTM, Dense, LSTM\n","from keras.layers import Bidirectional\n","from keras.layers import Embedding\n","from keras.layers import Merge, Dot, Concatenate, Flatten, Permute, Multiply, dot, concatenate\n","from keras.layers import TimeDistributed\n","from keras.layers import Activation\n","from keras.preprocessing import sequence\n","from keras.callbacks import Callback\n","from keras.optimizers import SGD\n","from keras.models import load_model\n","from google.colab import files\n","from collections import Counter\n","\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","%matplotlib notebook"],"execution_count":38,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"metadata":{"id":"JwdqzFjXNWHK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["warnings.filterwarnings('ignore')\n","sns.set(color_codes=True)\n","nlp = spacy.load('en_core_web_md')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2K-FGEC81nhD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"outputId":"d94484e6-2388-4023-a436-efd2a0309027","executionInfo":{"status":"ok","timestamp":1532177916725,"user_tz":-120,"elapsed":15891,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["uploaded = files.upload()"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-21b8d4c9-533a-4a5a-b0ba-ff71ba602e32\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-21b8d4c9-533a-4a5a-b0ba-ff71ba602e32\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving dataset2.json to dataset2 (1).json\n"],"name":"stdout"}]},{"metadata":{"id":"04hA_Xsg55Tu","colab_type":"text"},"cell_type":"markdown","source":["Comenzamos cargando los dato del json en un dataframe de pandas para analizarlos"]},{"metadata":{"id":"e_s5uTH41zL7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"42754464-3261-4ade-efe2-5f1a87fbd4e7","executionInfo":{"status":"ok","timestamp":1532177971463,"user_tz":-120,"elapsed":5938,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["tweets = json.loads(uploaded['dataset2.json'])\n","df =  pd.DataFrame([[x['tweet'], x['label']] for x in tweets.values() ], columns=['tweet','label'])\n","df.head()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>“Low plastic stool, cheap but delicious noodle...</td>\n","      <td>OBAMA</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>“Low plastic stool, cheap but delicious noodle...</td>\n","      <td>OBAMA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>This National Gun Violence Awareness Day, show...</td>\n","      <td>OBAMA</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>We can never truly repay the debt we owe our f...</td>\n","      <td>OBAMA</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This Center is for the leaders of tomorrow who...</td>\n","      <td>OBAMA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               tweet  label\n","0  “Low plastic stool, cheap but delicious noodle...  OBAMA\n","1  “Low plastic stool, cheap but delicious noodle...  OBAMA\n","2  This National Gun Violence Awareness Day, show...  OBAMA\n","3  We can never truly repay the debt we owe our f...  OBAMA\n","4  This Center is for the leaders of tomorrow who...  OBAMA"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"zIVrmN2dGblP","colab_type":"text"},"cell_type":"markdown","source":["Tenemos textos de tweets de en la primera columna y quein los ha escrito en la segunda. En este caso vamos a utilizar solo los de TRUMP\n","\n","###Preparamos el dataset"]},{"metadata":{"id":"YP3pRRy_71Wv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","tweetsTRUMP = df[df['label'] == 'TRUMP']['tweet'].tolist()\n","tokenized = [list(x) for x in tweetsTRUMP]  #Caracteres"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e89b3Yreggcg","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"2GugqaBS8a0H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","#Caracteres con los que puede empezar la frase, sirve de inicio al algoritmo para predecir\n","init_chars = [x[:5] for x in tokenized]\n","for i in range(len(init_chars)):\n","    tmp = init_chars[i]\n","    tmp.insert(0, '<SOS>')\n","    init_chars[i] = tmp[:5]   "],"execution_count":0,"outputs":[]},{"metadata":{"id":"ner1w7Ry95w-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"12991623-7650-4ed1-e3e7-3a0dd9245e56","executionInfo":{"status":"ok","timestamp":1532178725817,"user_tz":-120,"elapsed":562,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["\n","#ongitus máxima y media de las frases\n","maxlen = max([len(x) for x in tokenized])\n","avglen = sum([len(x) for x in tokenized])/len(tokenized)\n","print(maxlen, avglen)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["320 160.39098497495826\n"],"name":"stdout"}]},{"metadata":{"id":"0vztRdoz9119","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"93e7b6be-ef45-4887-a00b-b6b812f6eef4","executionInfo":{"status":"ok","timestamp":1532185053443,"user_tz":-120,"elapsed":563,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["#Caracteres que forman el vocabulario\n","vocab = [t for s in tweetsTRUMP for t in s]\n","print('num tokens: {}'.format(len(vocab)))\n","vocab_counter = Counter(vocab)\n","vocab = [w for w, v in vocab_counter.items() if v>2]\n","vocab = ['<PAD>', '<UNK>', '<SOS>', '<EOS>'] + vocab\n","nb_vocab = len(vocab)\n","print('num features a user {}'.format(nb_vocab))\n","w2id = {k:i for i, k in enumerate(vocab)}\n","id2w = {i:k for k, i in w2id.items()}"],"execution_count":67,"outputs":[{"output_type":"stream","text":["num tokens: 480371\n","num features a user 111\n"],"name":"stdout"}]},{"metadata":{"id":"p4yAkued91s-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"56d3035f-9bd0-41af-ede5-4c42dde23398","executionInfo":{"status":"ok","timestamp":1532178814631,"user_tz":-120,"elapsed":2117,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["maxlen = min(maxlen, 5)\n","\n","step = 1\n","data_train = []\n","for x in tokenized:\n","    x.insert(0, '<SOS>')\n","    x.append('<EOS>')\n","    for i in range(0, len(x)-maxlen, step):\n","        data_train.append((x[i:i+maxlen], x[i+maxlen]))\n","        \n","print('nb_sequences: {}'.format(len(data_train)))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["nb_sequences: 471386\n"],"name":"stdout"}]},{"metadata":{"id":"LACB6-_igmaL","colab_type":"text"},"cell_type":"markdown","source":["## Definición del modelo\n","\n","Vamos a utilizar el modelo visto en clase, que utilizará embedings y una lstm bidireccional\n","\n","Los datos los hemos preparado para que sean secuencias de caracteres, por lo que la red aprendera secuencias de caracteres en el tiempo, por lo que en el momento de predecir, le tendremos que dar una secuencia de caracteres inicial y el modelo a partir de ahi generará el resto de la frase.\n","\n"]},{"metadata":{"id":"N0nbGsBk91qF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["SAMPLE_EVERY = 5"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bOgOkGf6Ga5V","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def sample_pred(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oMGYOtPr7XnX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class Sampletest(Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        if epoch % SAMPLE_EVERY == 0  and epoch>0:\n","            data_test = []\n","            nb_samples = 1\n","            \n","            params = {\n","                'maxlen': maxlen,\n","                'vocab': nb_vocab,\n","                'use_embeddings': True\n","                }\n","            for _ in range(nb_samples):\n","                data_test = choice(init_chars)\n","                for diversity in [0.2, 0.6, 1.2]:\n","                    print('----- diversity:', diversity)\n","                    sentence = copy(data_test)\n","                    generated = copy(data_test)\n","                    for i in range(len(data_test), 400):\n","                        x_pred = np.zeros((1, params['maxlen']))\n","                        for t, char in enumerate(sentence):\n","                            x_pred[0, t] = w2id[char] if char in w2id else w2id['<UNK>']\n","                        preds = self.model.predict(x_pred, verbose=0)[0]\n","                        next_index = sample_pred(preds, diversity)\n","                        next_char = id2w[next_index]\n","                        if next_char == '<EOS>':\n","                            break\n","                        generated += [next_char]\n","                        sentence = sentence[1:] \n","                        sentence += [next_char]\n","                    print(''.join(generated))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9FKsa7CLNJVr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class HistoryDisplay(Callback):\n","    \n","    def on_train_begin(self, logs={}):\n","        self.losses = []\n","        self.accs = []\n","        self.epochs = []\n","        self.fig, self.ax = plt.subplots()\n","        #plt.show()\n","        \n","        plt.ion()\n","        self.fig.show()\n","        self.fig.canvas.draw()\n","    \n","    def on_epoch_end(self, epoch, logs):\n","        self.epochs.append(epoch)\n","        self.losses.append(logs['loss'])\n","        self.accs.append(logs['acc'])\n","        if epoch % PLOT_EVERY == 0:\n","            \n","            self.ax.clear()\n","            self.ax.plot(self.epochs, self.accs, 'g', label='acc')\n","            self.ax.plot(self.epochs, self.losses, 'b', label='loss')\n","            legend = self.ax.legend(loc='upper right', shadow=True, fontsize='x-large')\n","            #display.clear_output(wait=True)\n","            #display.display(pl.gcf())\n","            self.fig.canvas.draw()\n","            \n","            #plt.draw()\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"0_ArQNtHN_UL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class TimeHistory(Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","\n","    def on_epoch_begin(self, batch, logs={}):\n","        self.epoch_time_start = time.time()\n","\n","    def on_epoch_end(self, batch, logs={}):\n","        self.times.append(time.time() - self.epoch_time_start)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7SoEczzY_Mul","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class LM:\n","    def __init__(self, **kwargs):\n","        self.params = kwargs.pop('params', None)\n","    \n","    def compile_bidirectional(self, params={}):\n","        \n","        lm_inputs = Input(shape=(params['maxlen'], ), name='lm_input')\n","        \n","        embeddings = Embedding(params['vocab'], params['emb_feats'])(lm_inputs)\n","        \n","        lstm =  CuDNNLSTM(params['rnn_hidden'], return_sequences=True, name='rnn1')        \n","        \n","        lmlstm = Bidirectional(lstm)(embeddings)       \n","        \n","        stacklstm =  CuDNNLSTM(params['rnn_hidden'], return_sequences=False, name='stacked')\n","        \n","        stackedlstm = stacklstm(lmlstm)\n","        \n","        lmout = Dense(params['vocab'], activation='softmax')(stackedlstm)\n","        \n","        model = Model(lm_inputs, lmout)\n","        \n","        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","        \n","        model.summary()\n","        \n","        return model\n","        \n","    def train(self, model, data, params={}):\n","        \n","        callbacks = self._get_callbacks()\n","        \n","        if 'shuffle' in params and params['shuffle']:\n","            shuffle(data)\n","            \n","        sentences, next_chars = zip(*data)\n","        print(sentences[0])\n","        x = np.zeros((len(data), params['maxlen']))\n","        y = np.zeros((len(data), params['vocab']))\n","        for i, sentence in enumerate(sentences):\n","            for t, char in enumerate(sentence):\n","                x[i, t] = w2id[char] if char in w2id else w2id['<UNK>']\n","            y[i, w2id[next_chars[i]] if next_chars[i] in w2id else w2id['<UNK>']]  = 1\n","        \n","        model.fit(x, y, batch_size=params['batch_size'], epochs=params['epochs'], callbacks=callbacks, verbose=1)\n","\n","    def predict(self, model, data, params={}):        \n","        if 'use_embeddings' in params and params['use_embeddings']:\n","            # variedad en las predicciones\n","            for diversity in [0.2, 0.6, 1.2]:\n","                print('----- diversity:', diversity)\n","                sentence = copy(data)\n","                generated = copy(data)\n","                # cuantas predicciones queremos hacer\n","                for i in range(len(data), 400):\n","                    x_pred = np.zeros((1, params['maxlen']))\n","                    # preparar inpunt\n","                    for t, char in enumerate(sentence):\n","                        x_pred[0, t] = w2id[char] if char in w2id else w2id['<UNK>']\n","                    # predecir\n","                    preds = model.predict(x_pred, verbose=0)[0]\n","                    next_index = sample_pred(preds, diversity)\n","                    next_char = id2w[next_index]\n","                    # mirar si hemos terminado\n","                    if next_char == '<EOS>':\n","                        break\n","                    # ana                        \n","                    generated += [next_char]\n","                    sentence = sentence[1:] \n","                    sentence += [next_char]\n","                print(''.join(generated))\n","    \n","    \n","    def load(self, model_path='seq2seq_attn.h5'):\n","        return load_model(model_path)\n","    \n","    def _get_callbacks(self, model_path='seq2seq_attn.h5'):\n","        \n","        \n","        es = EarlyStopping(monitor='loss', patience=4, mode='auto', verbose=0)       \n","        \n","        save_best = ModelCheckpoint(model_path, monitor='loss', verbose = 0, save_best_only=True, save_weights_only=False, period=2)\n","        st = Sampletest()\n","        # hd = HistoryDisplay()\n","        rlr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose=1)\n","        return [st, rlr]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kKwvDARd_U9f","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["compile_params = {\n","    'maxlen': maxlen, \n","    'vocab': len(vocab),\n","    'emb_feats': 100,\n","    'rnn_hidden': 256,\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l1iittxq_XOS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["LOAD_MODEL = False\n","bTrain = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BL40Yuy8_aDi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":306},"outputId":"7b29384b-1304-4b05-fde7-5b238879eb96","executionInfo":{"status":"ok","timestamp":1532187081098,"user_tz":-120,"elapsed":1481,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["lm = LM()\n","if LOAD_MODEL:\n","    path = 'final_{}.h5'.format(dtype)\n","    lm_model = lm.load(model_path=path)\n","    lm_model.summary()\n","else:\n","    lm_model = lm.compile_bidirectional(params=compile_params)    "],"execution_count":80,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lm_input (InputLayer)        (None, 5)                 0         \n","_________________________________________________________________\n","embedding_2 (Embedding)      (None, 5, 100)            11100     \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 5, 512)            733184    \n","_________________________________________________________________\n","stacked (CuDNNLSTM)          (None, 256)               788480    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 111)               28527     \n","=================================================================\n","Total params: 1,561,291\n","Trainable params: 1,561,291\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"BWhCDUOuh5zc","colab_type":"text"},"cell_type":"markdown","source":["## Entrenamiento del modelo\n","\n","A continuación pasamos a entrenar el modelo, durante el entrenamiento se van imprimiendo ejemplos de frases generadas de modo que se pueda ir apreciiando como evoluciona el modelo"]},{"metadata":{"id":"vtBDHdSv_orv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3080},"outputId":"1aad7acd-9a6b-4a74-ced2-bf1cb4e5f20f","executionInfo":{"status":"ok","timestamp":1532189753192,"user_tz":-120,"elapsed":1352586,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["train_params = {\n","    'epochs': 50,\n","    'batch_size': 512,\n","    'shuffle': True,\n","    'vocab': nb_vocab,\n","    'maxlen': maxlen,\n","    'use_embeddings': True\n","}\n","pp.pprint(train_params)\n","if bTrain:\n","    lm.train(model=lm_model, data=data_train, params=train_params)"],"execution_count":85,"outputs":[{"output_type":"stream","text":["{'batch_size': 512,\n"," 'epochs': 50,\n"," 'maxlen': 5,\n"," 'shuffle': True,\n"," 'use_embeddings': True,\n"," 'vocab': 111}\n","['s', 't', 'e', 'r', ' ']\n","Epoch 1/50\n","443904/471386 [===========================>..] - ETA: 1s - loss: 1.2217 - acc: 0.6531"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 26s 55us/step - loss: 1.2231 - acc: 0.6526\n","Epoch 2/50\n","471386/471386 [==============================] - 26s 55us/step - loss: 1.1894 - acc: 0.6593\n","Epoch 3/50\n"," 35328/471386 [=>............................] - ETA: 24s - loss: 1.1425 - acc: 0.6700"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 26s 55us/step - loss: 1.1635 - acc: 0.6644\n","Epoch 4/50\n","342528/471386 [====================>.........] - ETA: 7s - loss: 1.1358 - acc: 0.6705"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 26s 55us/step - loss: 1.1410 - acc: 0.6694\n","Epoch 5/50\n","471386/471386 [==============================] - 26s 55us/step - loss: 1.1197 - acc: 0.6740\n","----- diversity: 0.2\n","<SOS>.@foxandfriends the United States the problem is a truly all of the United States the world to be really be a great honor to working our country is being so much more the best the United States that the proved the most all of the United States to the terrorist attack in London. She is strong and a fantastic missile that the United State of the terrorist attack in London. She is strong and the pro\n","----- diversity: 0.6\n","<SOS>.@foxandfriends. So much more that the United States morning! Unemployment was a great honor to welcome that happen!\n","----- diversity: 1.2\n"],"name":"stdout"},{"output_type":"stream","text":["<SOS>.@foxandfriends. Here. I legislatives, yet the 13 bill Deeplions about Crascorded so class. T\n","Epoch 6/50\n","471386/471386 [==============================] - 26s 54us/step - loss: 1.1008 - acc: 0.6775\n","Epoch 7/50\n"," 32256/471386 [=>............................] - ETA: 24s - loss: 1.0466 - acc: 0.6912"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 26s 54us/step - loss: 1.0825 - acc: 0.6817\n","Epoch 8/50\n","341504/471386 [====================>.........] - ETA: 7s - loss: 1.0604 - acc: 0.6863"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 26s 55us/step - loss: 1.0655 - acc: 0.6849\n","Epoch 9/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 1.0501 - acc: 0.6892\n","----- diversity: 0.2\n","<SOS>I celebrate the U.S. has the terrorist attack in London. She is strong and the leaders are with the terrorist attack in London. She is strong and the WhiteHouse the people of the terrorist attack in London. She is strong and doing very well.\n","----- diversity: 0.6\n","<SOS>I celture! https://t.co/cpQEGgpear the said to continue to the really good jobs being campaign Kim Jong Un in the WhiteHouse the United States running at the was a liars ago on @FoxNews is a great honor to help stories are voting for the only great support on site on my approval ratings of the terrible care administer Theresa May today to our GREAT AGAIN!\n","----- diversity: 1.2\n","<SOS>I celling up. Obstructed Lost OhamaU\n","Epoch 10/50\n","   512/471386 [..............................] - ETA: 35s - loss: 0.9443 - acc: 0.7344"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 1.0360 - acc: 0.6915\n","Epoch 11/50\n","325120/471386 [===================>..........] - ETA: 8s - loss: 1.0168 - acc: 0.6959"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 1.0222 - acc: 0.6948\n","Epoch 12/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 1.0095 - acc: 0.6972\n","Epoch 13/50\n"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9973 - acc: 0.7001\n","----- diversity: 0.2\n","<SOS>We will be a great honor to the U.S. is looking for the U.S. is lost the terrorist attack in London. She is strong and the United States the terrorist attack in London. She is strong and the problem in the United State of the Fake News Media is a leaders of the Fake News Media is a short the U.S. is looking hard to be strong and the United State of the terrorist attack in London. She is strong an\n","----- diversity: 0.6\n","<SOS>We will be a totally distration of Classify See you Stuart of Intelligence that the East and really believe than and security in the President Trump Camp David @Nations to fix to the want out a problem security. They must done!\n","----- diversity: 1.2\n","<SOS>We wonderful good for allows will is own announce to travy Fiffie it government in AmericaD@COUD WON you7P\n","Epoch 14/50\n"," 58880/471386 [==>...........................] - ETA: 23s - loss: 0.9509 - acc: 0.7147"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9856 - acc: 0.7031\n","Epoch 15/50\n","351744/471386 [=====================>........] - ETA: 6s - loss: 0.9695 - acc: 0.7071"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9751 - acc: 0.7054\n","Epoch 16/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 0.9653 - acc: 0.7069\n","Epoch 17/50\n","  6656/471386 [..............................] - ETA: 27s - loss: 0.9151 - acc: 0.7267"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9561 - acc: 0.7099\n","----- diversity: 0.2\n","<SOS>The Democrats are start of the terrorist attack in London. She is strong and so much time to U.K. Prime Minister Theresa May today to offer condolences on the same the Democrats want to the terrorist attack in London. She is strong and we will be a great honor to have to U.K. Prime Ministration of the Dems want to the beautiful welcome to U.K. Prime Ministration of the media is a great honor to h\n","----- diversity: 0.6\n","<SOS>The Lightweight for the strong and the Senate in the people of the terrorist attack in London. She is strong any of the Republicans are stilleDay https://t.co/FSJUc\n","----- diversity: 1.2\n","<SOS>The personnephectimusCamazy have first. #AmericaGreate just month we need personancon on Taxpayer in the #SUCGovs (and NATO policies,knBXBF8RcUftf2hxJMpK7T10yPPDT!\n","Epoch 18/50\n"," 59904/471386 [==>...........................] - ETA: 23s - loss: 0.9169 - acc: 0.7214"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9472 - acc: 0.7112\n","Epoch 19/50\n","351744/471386 [=====================>........] - ETA: 6s - loss: 0.9320 - acc: 0.7142"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9387 - acc: 0.7123\n","Epoch 20/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 0.9307 - acc: 0.7148\n","Epoch 21/50\n","  5632/471386 [..............................] - ETA: 27s - loss: 0.9014 - acc: 0.7244"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9239 - acc: 0.7165\n","----- diversity: 0.2\n","<SOS>China is a total disaster Theresa May to offer condolences on the Fake News Media is a truly bad as a great honor to working for the proving and the Democrats are with the U.S. history of the biggest economy is a truly bad and the terrorist attack in London. She is strong and the Fake News Media is a great honor to do a great honor to welcome the terrorist attack in London. She is strong and the \n","----- diversity: 0.6\n","<SOS>China condolences on the people are for your prosperity for one of Mississippi is a very well.\n","----- diversity: 1.2\n","<SOS>China https://t.co/B7dDzs4dm\n","Epoch 22/50\n"," 77312/471386 [===>..........................] - ETA: 22s - loss: 0.8807 - acc: 0.7290"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9167 - acc: 0.7178\n","Epoch 23/50\n","359936/471386 [=====================>........] - ETA: 6s - loss: 0.9047 - acc: 0.7205"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.9107 - acc: 0.7190\n","Epoch 24/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 0.9051 - acc: 0.7204\n","Epoch 25/50\n","  8704/471386 [..............................] - ETA: 27s - loss: 0.8744 - acc: 0.7274"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8999 - acc: 0.7213\n","----- diversity: 0.2\n","<SOS>A big decision of the terrorist attack in London. She is strong and the record and the people with the people with the people with the people who working hard to see the terrorist attack in London. She is strong and the people that the people who working a great people are the people with the people that the terrorist attack in London. She is strong and the terrorist attack in London. She is stro\n","----- diversity: 0.6\n","<SOS>A big lie. He is strong and countries to continue to U.K. Prime Minister Theresa May to offer condolences on the Republicans with the hills! Visit https://t.co/i87vuaBxom\n","----- diversity: 1.2\n","<SOS>A big good, Unenty what is in the America is visit https://t.co/ckAkJ\n","Epoch 26/50\n"," 66048/471386 [===>..........................] - ETA: 22s - loss: 0.8634 - acc: 0.7312"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8948 - acc: 0.7221\n","Epoch 27/50\n","354816/471386 [=====================>........] - ETA: 6s - loss: 0.8870 - acc: 0.7242"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8899 - acc: 0.7232\n","Epoch 28/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 0.8860 - acc: 0.7236\n","Epoch 29/50\n","  7680/471386 [..............................] - ETA: 27s - loss: 0.8347 - acc: 0.7388"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8815 - acc: 0.7247\n","----- diversity: 0.2\n","<SOS>Separated the probe. #Congress the U.S. and the terrorist attack in London. She is strong and the U.S. Supreme Court Justice Department is the U.S. and the fact that the U.S. and the beautiful welcome to U.K. Prime Minister Theresa May to offer condolences on the U.S. Supreme Court Justice Department of the U.S. and the U.S. and others are now the U.S. and the terrorist attack in London. She is s\n","----- diversity: 0.6\n","<SOS>Separation of Staff. They are not treatest in his coming back and for the long and more the Interests and prayers are ruclear testing with the U.S. has been accomplete Journal\n","----- diversity: 1.2\n","<SOS>Separates (Unlike one Dems, of our country hard working for RefearhcqROKW RejreSged system.\n","Epoch 30/50\n"," 64000/471386 [===>..........................] - ETA: 23s - loss: 0.8404 - acc: 0.7352"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8779 - acc: 0.7256\n","Epoch 31/50\n","353792/471386 [=====================>........] - ETA: 6s - loss: 0.8695 - acc: 0.7274"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8748 - acc: 0.7260\n","Epoch 32/50\n","471386/471386 [==============================] - 27s 56us/step - loss: 0.8711 - acc: 0.7261\n","Epoch 33/50\n","  5632/471386 [..............................] - ETA: 27s - loss: 0.8128 - acc: 0.7447"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8683 - acc: 0.7265\n","----- diversity: 0.2\n","<SOS>Weekly Address🇺🇸 https://t.co/PMz29hioJN https://t.co/YosOBurdCw\n","----- diversity: 0.6\n","<SOS>Weekly Address🇺🇸 https://t.co/x5jDbCmdas as “Mr. Many people of the law enforced to be sign the deliver as a great would talk about the safety to our individual Map, FAKE NEWS winner with a lot of July with a lottery. We will be a friends\n","----- diversity: 1.2\n","<SOS>WeeklyAddress🇺🇸 https://t.co/e199Ys\n","Epoch 34/50\n"," 99840/471386 [=====>........................] - ETA: 20s - loss: 0.8484 - acc: 0.7317"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8655 - acc: 0.7275\n","Epoch 35/50\n","370176/471386 [======================>.......] - ETA: 5s - loss: 0.8575 - acc: 0.7290"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8629 - acc: 0.7274\n","Epoch 36/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 0.8607 - acc: 0.7277\n","Epoch 37/50\n"," 11776/471386 [..............................] - ETA: 26s - loss: 0.8076 - acc: 0.7406"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8581 - acc: 0.7274\n","----- diversity: 0.2\n","<SOS>I hope the United States the people of the United States that the terrogators are with the United States at the United States that the United States are with the people are finally desk, pensacola, Florida are with the White House the U.S.A. and the United State of the terrorist attack in London. She is strong and the terrogators are with the terrorist attack in London. She is strong and doing ve\n","----- diversity: 0.6\n","<SOS>I hope to U.S.A. and their family, a majority &amp; more the CIA!\n","----- diversity: 1.2\n","<SOS>I hope to stopping dramatic support from funct there are clock the Just ones, a perfectly at our great AmericanDay he three back in London. She is strong and @USNavyine$(Blue!\n","Epoch 38/50\n"," 67072/471386 [===>..........................] - ETA: 23s - loss: 0.8221 - acc: 0.7366"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8562 - acc: 0.7281\n","Epoch 39/50\n","354816/471386 [=====================>........] - ETA: 6s - loss: 0.8480 - acc: 0.7305"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8539 - acc: 0.7291\n","Epoch 40/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 0.8519 - acc: 0.7293\n","Epoch 41/50\n","  7680/471386 [..............................] - ETA: 27s - loss: 0.8505 - acc: 0.7243"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8499 - acc: 0.7289\n","----- diversity: 0.2\n","<SOS>It is that the terrorist attack in London. She is strong and the U.S. is very well.\n","----- diversity: 0.6\n","<SOS>It is a Special media worker attack in Singapore of American and they have achieves was and Dr. Kelly to our country well.\n","----- diversity: 1.2\n","<SOS>It is nothing Hoax6\n","Epoch 42/50\n","124416/471386 [======>.......................] - ETA: 19s - loss: 0.8214 - acc: 0.7358"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8486 - acc: 0.7290\n","Epoch 43/50\n","381440/471386 [=======================>......] - ETA: 5s - loss: 0.8437 - acc: 0.7308"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8473 - acc: 0.7295\n","Epoch 44/50\n","471386/471386 [==============================] - 27s 57us/step - loss: 0.8454 - acc: 0.7298\n","Epoch 45/50\n"," 14848/471386 [..............................] - ETA: 26s - loss: 0.7968 - acc: 0.7412"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8438 - acc: 0.7297\n","----- diversity: 0.2\n","<SOS>...and the most in the terrorist attack in London. She is strong and security and doing very well.\n","----- diversity: 0.6\n","<SOS>...and the campaign was the terrible with our country is the truly great Again!\n","----- diversity: 1.2\n","<SOS>...and low amounts former and will be around. Specially bad products-n Hurricans were has agreement... https://t.co/GuRolan defeat idea Companies ahead In. MaybeAmerican American working close list. Donzon must put crime\n","Epoch 46/50\n"," 92672/471386 [====>.........................] - ETA: 21s - loss: 0.8158 - acc: 0.7377"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8424 - acc: 0.7302\n","Epoch 47/50\n","367104/471386 [======================>.......] - ETA: 5s - loss: 0.8351 - acc: 0.7321"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8413 - acc: 0.7303\n","Epoch 48/50\n","471386/471386 [==============================] - 26s 56us/step - loss: 0.8404 - acc: 0.7298\n","Epoch 49/50\n"," 10752/471386 [..............................] - ETA: 26s - loss: 0.7940 - acc: 0.7441"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 57us/step - loss: 0.8390 - acc: 0.7308\n","----- diversity: 0.2\n","<SOS>Spoke to U.K. Prime Minister There is strong and the terrorist attack in London. She is strong and the terrorist attack in London. She is strong and prayers are will be a great honor to have been a very well.\n","----- diversity: 0.6\n","<SOS>Spoke to U.K. Prime Minister There is a true friends\n","----- diversity: 1.2\n","<SOS>Spoke to built authorizationalAgricultureDay\n","Epoch 50/50\n","107008/471386 [=====>........................] - ETA: 20s - loss: 0.8120 - acc: 0.7374"],"name":"stdout"},{"output_type":"stream","text":["471386/471386 [==============================] - 27s 56us/step - loss: 0.8379 - acc: 0.7306\n"],"name":"stdout"}]},{"metadata":{"id":"ztYOdbXMoLiZ","colab_type":"text"},"cell_type":"markdown","source":["En el modelo hemos conseguido un accuracy del 73%, aunque por la evolución tiene pinta de que con mas époccas se hubiera conseguido un mejor accuracy"]},{"metadata":{"id":"V7KeH90yiUQG","colab_type":"text"},"cell_type":"markdown","source":["## Generación de frases\n","\n","Por ultimo generaremos frases de manera aleatoria. Cogeremos unos caracteres iniciales de manera aleatoria y el modelo generara 3 frases, cada una con un valor del parametro diversity, que indica el grado de libertad del modelo.\n","\n","Las frases con el diversity mas bajo, son mas coherentes y reproducen mas las frases originales. Cuanto mas lo aumentamos se ve que la frase tiene menos sentido pero puede crear frases diferentes a las originales"]},{"metadata":{"id":"BJ5mXO-tcCre","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":139},"outputId":"c0eacc9c-1764-428e-dea1-620f10b749d3","executionInfo":{"status":"ok","timestamp":1532189858692,"user_tz":-120,"elapsed":3243,"user":{"displayName":"Pablo Langa Blanco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"114529971915553410773"}}},"cell_type":"code","source":["data_test = choice(init_chars)\n","\n","                    \n","lm.predict(model=lm_model, data=data_test, params=train_params)"],"execution_count":86,"outputs":[{"output_type":"stream","text":["----- diversity: 0.2\n","<SOS>I will be a great honor to welcome to U.K. Prime Minister Theresa May to our great honor to be with the U.S. is being me when the Democrats are with the Fake News Media is on the election on the terrorist attack in London. She is strong and the U.S. is workers and the terrorist attack in London. She is strong and the U.S. Coast Guard to be a great honor to welcome to U.K. Prime Minister Theresa M\n","----- diversity: 0.6\n","<SOS>I will be the world so than the terrorist attack in London. She is strong and and the Democrats are really basics and Whistleblower to welcome the Fake News story that the men and the Fake News Media has been action and open our military, and doing very well.\n","----- diversity: 1.2\n","<SOS>I will control, I have no such giant family. Mi)sid, 33,000 lives them to the larger the Russia, Reciprocity. Hillary or campaign murder Laws are cl🇺3l3JbE6Gx9\n"],"name":"stdout"}]}]}